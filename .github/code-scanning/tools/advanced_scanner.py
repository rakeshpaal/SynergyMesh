#!/usr/bin/env python3
"""
é«˜éšæ·±åº¦ä»£ç¢¼æƒæå·¥å…·
Advanced Deep Code Scanner

åŠŸèƒ½ï¼š
1. å¤šå±¤æ¬¡æƒæ (å®‰å…¨ã€ä¾è³´ã€è³ªé‡ã€æ€§èƒ½ã€åˆè¦)
2. æ™ºèƒ½æ¼æ´æª¢æ¸¬
3. çµæœèšåˆèˆ‡åˆ†æ
"""

import os
import sys
import json
import subprocess
import tempfile
from typing import Dict, List
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path

@dataclass
class VulnerabilityReport:
    """æ¼æ´å ±å‘Šæ•¸æ“šçµæ§‹"""
    severity: str
    type: str
    location: str
    file_path: str
    line_number: int
    code_snippet: str
    cwe_id: str
    description: str
    recommendation: str
    tool: str
    confidence: float

class AdvancedCodeScanner:
    """
    é«˜éšä»£ç¢¼æƒæå™¨
    
    æä¾›å…¨é¢çš„ä»£ç¢¼å®‰å…¨ã€ä¾è³´ã€è³ªé‡ã€æ€§èƒ½å’Œåˆè¦æ€§æƒæåŠŸèƒ½ã€‚
    
    Attributes:
        repo_path: å¾…æƒæçš„å„²å­˜åº«è·¯å¾‘
        output_dir: æƒæå ±å‘Šè¼¸å‡ºç›®éŒ„
        findings: æƒæç™¼ç¾çš„å•é¡Œåˆ—è¡¨
        scan_results: æƒæçµæœçš„å®Œæ•´æ•¸æ“šçµæ§‹
    """
    
    def __init__(self, repo_path: str = ".", output_dir: str = ".github/code-scanning/reports") -> None:
        """
        åˆå§‹åŒ–ä»£ç¢¼æƒæå™¨
        
        Args:
            repo_path: å„²å­˜åº«æ ¹ç›®éŒ„è·¯å¾‘ï¼Œé»˜èªç‚ºç•¶å‰ç›®éŒ„
            output_dir: æƒæå ±å‘Šè¼¸å‡ºç›®éŒ„è·¯å¾‘
        """
        self.repo_path = Path(repo_path).resolve()
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.findings = []
        self.scan_results = {
            "metadata": {
                "scan_time": datetime.utcnow().isoformat(),
                "repo_path": str(self.repo_path),
                "scanner_version": "1.0.0"
            },
            "security": [],
            "dependencies": [],
            "code_quality": [],
            "performance": [],
            "compliance": [],
            "summary": {}
        }
    
    def deep_scan(self) -> Dict:
        """
        åŸ·è¡Œå¤šå±¤æ¬¡æ·±åº¦æƒæ
        
        Returns:
            åŒ…å«æ‰€æœ‰æƒæçµæœçš„å­—å…¸ï¼ŒåŒ…æ‹¬å®‰å…¨ã€ä¾è³´ã€è³ªé‡ã€æ€§èƒ½å’Œåˆè¦æ€§ç­‰é¡åˆ¥
        """
        print("ğŸ” é–‹å§‹é«˜éšæ·±åº¦æƒæ...")
        
        # 1. å®‰å…¨æƒæ
        print("\nğŸ›¡ï¸ åŸ·è¡Œå®‰å…¨æƒæ...")
        self.scan_results["security"] = self._security_scan()
        
        # 2. ä¾è³´æƒæ
        print("\nğŸ“¦ åŸ·è¡Œä¾è³´æƒæ...")
        self.scan_results["dependencies"] = self._dependency_scan()
        
        # 3. ä»£ç¢¼è³ªé‡æƒæ
        print("\nâ­ åŸ·è¡Œä»£ç¢¼è³ªé‡æƒæ...")
        self.scan_results["code_quality"] = self._quality_scan()
        
        # 4. æ€§èƒ½æƒæ
        print("\nâš¡ åŸ·è¡Œæ€§èƒ½æƒæ...")
        self.scan_results["performance"] = self._performance_scan()
        
        # 5. åˆè¦æ€§æƒæ
        print("\nâœ… åŸ·è¡Œåˆè¦æ€§æƒæ...")
        self.scan_results["compliance"] = self._compliance_scan()
        
        # 6. ç”Ÿæˆæ‘˜è¦
        self._generate_summary()
        
        # 7. ä¿å­˜çµæœ
        self._save_results()
        
        print("\nâœ… æƒæå®Œæˆ!")
        return self.scan_results
    
    def _security_scan(self) -> List[Dict]:
        """å®‰å…¨æ¼æ´æƒæ"""
        findings = []
        
        # Python å®‰å…¨æƒæ (Bandit)
        bandit_output_path = None
        try:
            print("  - åŸ·è¡Œ Bandit æƒæ...")
            # ä½¿ç”¨è‡¨æ™‚æ–‡ä»¶ä¾†å­˜å„² Bandit è¼¸å‡º
            with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as tmp_file:
                bandit_output_path = tmp_file.name
            
            subprocess.run(
                ["bandit", "-r", str(self.repo_path), "-f", "json", "-o", bandit_output_path],
                capture_output=True,
                text=True,
                timeout=300
            )
            
            if os.path.exists(bandit_output_path):
                with open(bandit_output_path) as f:
                    bandit_data = json.load(f)
                
                for issue in bandit_data.get("results", []):
                    findings.append({
                        "severity": self._map_severity(issue.get("issue_severity")),
                        "type": issue.get("issue_text"),
                        "location": f"{issue.get('filename')}:{issue.get('line_number')}",
                        "file_path": issue.get("filename"),
                        "line_number": issue.get("line_number"),
                        "code_snippet": issue.get("code", ""),
                        "cwe_id": str(issue.get("test_id", "Unknown")),
                        "description": issue.get("issue_text"),
                        "recommendation": f"åƒè€ƒ CWE-{issue.get('test_id')} ä¿®å¾©å»ºè­°",
                        "tool": "bandit",
                        "confidence": issue.get("issue_confidence", "Medium")
                    })
        except Exception as e:
            print(f"  âš ï¸ Bandit æƒæå¤±æ•—: {e}")
        finally:
            # ç¢ºä¿è‡¨æ™‚æ–‡ä»¶ç¸½æ˜¯è¢«æ¸…ç†
            if bandit_output_path and os.path.exists(bandit_output_path):
                try:
                    os.unlink(bandit_output_path)
                except Exception:
                    pass  # å¿½ç•¥æ¸…ç†éŒ¯èª¤
        
        
        # è‡ªå®šç¾©å®‰å…¨è¦å‰‡æª¢æŸ¥
        print("  - åŸ·è¡Œè‡ªå®šç¾©å®‰å…¨è¦å‰‡...")
        findings.extend(self._custom_security_rules())
        
        return findings
    
    def _custom_security_rules(self) -> List[Dict]:
        """è‡ªå®šç¾©å®‰å…¨è¦å‰‡æª¢æŸ¥"""
        findings = []
        
        # æª¢æŸ¥ç¡¬ç·¨ç¢¼å¯†ç¢¼
        patterns = {
            "password": ["password", "passwd", "pwd"],
            "api_key": ["api_key", "apikey", "api-key"],
            "secret": ["secret", "private_key", "private-key"],
            "token": ["token", "access_token", "auth_token"]
        }
        
        # Test file patterns to filter out
        test_file_patterns = [
            "/test/", "/tests/", "/test_", "_test.py",
            "/example/", "/examples/", "/demo/", "/demos/",
            "/mock/", "/mocks/", "/fixture/", "/fixtures/"
        ]
        
        # Placeholder patterns that indicate non-real credentials
        placeholder_patterns = [
            "todo", "replace", "change", "example", "sample",
            "placeholder", "your_", "my_", "xxx", "yyy",
            "test", "dummy", "fake", "mock", "<", ">"
        ]
        
        python_files = list(self.repo_path.rglob("*.py"))
        
        for file_path in python_files:
            # Skip test files and example files
            file_path_str = str(file_path).lower()
            if any(pattern in file_path_str for pattern in test_file_patterns):
                continue
            
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                
                for line_num, line in enumerate(lines, 1):
                    line_lower = line.lower()
                    
                    # Skip comment lines (both full-line and inline comments)
                    stripped_line = line.strip()
                    if stripped_line.startswith("#"):
                        continue
                    
                    # Remove inline comments for analysis
                    code_part = line.split('#')[0] if '#' in line else line
                    code_part_lower = code_part.lower()
                    # Skip comments
                    stripped = line.strip()
                    if stripped.startswith("#"):
                        continue
                    
                    # Skip test files
                    if any(test_marker in str(file_path).lower() for test_marker in ['test_', '_test.', 'tests/']):
                        continue
                    
                    # æª¢æŸ¥ç¡¬ç·¨ç¢¼æ†‘è­‰
                    for key_type, keywords in patterns.items():
                        for keyword in keywords:
                            # Check for both assignment and dictionary patterns
                            has_assignment = f"{keyword} = " in code_part_lower
                            has_dict_double_quotes = f'"{keyword}": ' in code_part_lower
                            has_dict_single_quotes = f"'{keyword}': " in code_part_lower
                            
                            if has_assignment or has_dict_double_quotes or has_dict_single_quotes:
                                # Must have quotes to be a potential hardcoded credential
                                if not any(c in code_part for c in ['"', "'"]):
                                    continue
                                
                                # Extract the value part based on pattern type
                                if has_assignment and '=' in code_part:
                                    value_part = code_part.split('=', 1)[1].strip()
                                elif (has_dict_double_quotes or has_dict_single_quotes) and ':' in code_part:
                                    value_part = code_part.split(':', 1)[1].strip()
                                else:
                                    continue
                                
                                value_part_lower = value_part.lower()
                                
                                # Filter out false positives
                                # 1. Empty strings or null values
                                # Check if value is empty quotes or None/null
                                stripped_value = value_part.strip().strip('"').strip("'").strip()
                                if not stripped_value or stripped_value.lower() in ['none', 'null']:
                                    continue
                                
                                # 2. Environment variable references
                                if any(env_ref in value_part for env_ref in ['os.getenv', 'os.environ', 'env.get', 'ENV["', "ENV['"]):
                                    continue
                                
                                # 3. Placeholder values
                                if any(placeholder in value_part_lower for placeholder in placeholder_patterns):
                                    continue
                                
                                findings.append({
                                    "severity": "high",
                                    "type": "Hardcoded Credential",
                                    "location": f"{file_path}:{line_num}",
                                    "file_path": str(file_path),
                                    "line_number": line_num,
                                    "code_snippet": line.strip(),
                                    "cwe_id": "CWE-798",
                                    "description": f"æª¢æ¸¬åˆ°å¯èƒ½çš„ç¡¬ç·¨ç¢¼ {key_type}",
                                    "recommendation": "ä½¿ç”¨ç’°å¢ƒè®Šé‡æˆ–å¯†é‘°ç®¡ç†æœå‹™å­˜å„²æ•æ„Ÿä¿¡æ¯",
                                    "tool": "custom",
                                    "confidence": 0.7
                                })
                            if f"{keyword} = " in line_lower or f'"{keyword}": ' in line_lower:
                                if '=' in line and any(c in line for c in ['"', "'"]):
                                    # Extract the value to check for placeholders
                                    value_match = re.search(r'["\']([^"\']+)["\']', line)
                                    if value_match:
                                        value = value_match.group(1)
                                        # Skip placeholders and environment variables
                                        if value in ['', 'your_password_here', 'your_api_key_here', 'changeme', 'TODO', 'FIXME']:
                                            continue
                                        if value.startswith(('$', 'os.environ', 'os.getenv', 'env.')):
                                            continue
                                    
                                    findings.append({
                                        "severity": "high",
                                        "type": "Hardcoded Credential",
                                        "location": f"{file_path}:{line_num}",
                                        "file_path": str(file_path),
                                        "line_number": line_num,
                                        "code_snippet": line.strip(),
                                        "cwe_id": "CWE-798",
                                        "description": f"æª¢æ¸¬åˆ°å¯èƒ½çš„ç¡¬ç·¨ç¢¼ {key_type}",
                                        "recommendation": "ä½¿ç”¨ç’°å¢ƒè®Šé‡æˆ–å¯†é‘°ç®¡ç†æœå‹™å­˜å„²æ•æ„Ÿä¿¡æ¯",
                                        "tool": "custom",
                                        "confidence": 0.7
                                    })
            
            except Exception as e:
                continue
        
        return findings
    
    def _dependency_scan(self) -> List[Dict]:
        """ä¾è³´é …æƒæ"""
        findings = []
        
        # æª¢æŸ¥ requirements.txt
        req_files = list(self.repo_path.rglob("requirements*.txt"))
        
        for req_file in req_files:
            try:
                with open(req_file, 'r') as f:
                    requirements = f.readlines()
                
                for line_num, line in enumerate(requirements, 1):
                    line = line.strip()
                    if not line or line.startswith('#'):
                        continue
                    
                    # æª¢æŸ¥æœªå›ºå®šç‰ˆæœ¬
                    if not any(c in line for c in ['==', '>=', '<=', '~=', '===']):
                        findings.append({
                            "severity": "medium",
                            "type": "Unpinned Dependency Version",
                            "location": f"{req_file}:{line_num}",
                            "file_path": str(req_file),
                            "line_number": line_num,
                            "code_snippet": line,
                            "cwe_id": "CWE-1390",
                            "description": f"ä¾è³´ {line} æ²’æœ‰å›ºå®šç‰ˆæœ¬è™Ÿ",
                            "recommendation": "å›ºå®šä¾è³´ç‰ˆæœ¬è™Ÿä»¥ç¢ºä¿å¯é‡è¤‡æ€§",
                            "tool": "dependency",
                            "confidence": 0.9
                        })
            
            except (IOError, OSError, UnicodeDecodeError) as e:
                print(f"  âš ï¸ è®€å– {req_file} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            except FileNotFoundError as e:
                print(f"  âš ï¸ æ‰¾ä¸åˆ°ä¾è³´æ–‡ä»¶ {req_file}: {e}")
                continue
            except PermissionError as e:
                print(f"  âš ï¸ æ²’æœ‰æ¬Šé™è®€å–ä¾è³´æ–‡ä»¶ {req_file}: {e}")
                continue
            except UnicodeDecodeError as e:
                print(f"  âš ï¸ ä¾è³´æ–‡ä»¶ {req_file} åŒ…å«ç„¡æ•ˆçš„ç·¨ç¢¼: {e}")
                continue
            except OSError as e:
                print(f"  âš ï¸ è¨ªå•ä¾è³´æ–‡ä»¶ {req_file} æ™‚ç™¼ç”Ÿç³»çµ±éŒ¯èª¤: {e}")
                continue
            except Exception as e:
                print(f"  âš ï¸ è™•ç†ä¾è³´æ–‡ä»¶ {req_file} æ™‚ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤: {e}")
                continue
        
        return findings
    
    def _quality_scan(self) -> List[Dict]:
        """ä»£ç¢¼è³ªé‡æƒæ"""
        findings = []
        
        # æª¢æŸ¥å¤§æ–‡ä»¶
        for file_path in self.repo_path.rglob("*.py"):
            try:
                file_size = file_path.stat().st_size
                if file_size > 50000:  # 50KB
                    findings.append({
                        "severity": "low",
                        "type": "Large File",
                        "location": str(file_path),
                        "file_path": str(file_path),
                        "line_number": 1,
                        "code_snippet": f"æ–‡ä»¶å¤§å°: {file_size} bytes",
                        "cwe_id": "N/A",
                        "description": "æ–‡ä»¶éå¤§ï¼Œå»ºè­°æ‹†åˆ†",
                        "recommendation": "å°‡å¤§å‹æ–‡ä»¶æ‹†åˆ†ç‚ºå¤šå€‹æ¨¡å¡Š",
                        "tool": "quality",
                        "confidence": 1.0
                    })
            
            except Exception:
                continue
        
        # æª¢æŸ¥éé•·å‡½æ•¸
        for file_path in self.repo_path.rglob("*.py"):
            try:
                with open(file_path, 'r') as f:
                    lines = f.readlines()
                
                for line_num, line in enumerate(lines, 1):
                    if len(line) > 120:
                        findings.append({
                            "severity": "low",
                            "type": "Long Line",
                            "location": f"{file_path}:{line_num}",
                            "file_path": str(file_path),
                            "line_number": line_num,
                            "code_snippet": line.strip()[:80] + "...",
                            "cwe_id": "N/A",
                            "description": f"è¡Œé•·åº¦ {len(line)} å­—ç¬¦è¶…é 120",
                            "recommendation": "å°‡é•·è¡Œæ‹†åˆ†ç‚ºå¤šè¡Œ",
                            "tool": "quality",
                            "confidence": 1.0
                        })
            
            except (IOError, OSError, UnicodeDecodeError) as e:
                print(f"  âš ï¸ è®€å– {file_path} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                continue
        
        return findings
    
    def _performance_scan(self) -> List[Dict]:
        """æ€§èƒ½æƒæ"""
        findings = []
        
        # æª¢æŸ¥æ½›åœ¨æ€§èƒ½å•é¡Œ
        for file_path in self.repo_path.rglob("*.py"):
            try:
                with open(file_path, 'r') as f:
                    content = f.read()
                
                # æª¢æŸ¥å…¨å±€è®Šé‡
                if "global " in content:
                    findings.append({
                        "severity": "low",
                        "type": "Global Variable Usage",
                        "location": str(file_path),
                        "file_path": str(file_path),
                        "line_number": 1,
                        "code_snippet": "global keyword detected",
                        "cwe_id": "N/A",
                        "description": "æª¢æ¸¬åˆ°å…¨å±€è®Šé‡ä½¿ç”¨",
                        "recommendation": "é¿å…ä½¿ç”¨å…¨å±€è®Šé‡ï¼Œä½¿ç”¨é¡æˆ–å‡½æ•¸åƒæ•¸ä»£æ›¿",
                        "tool": "performance",
                        "confidence": 0.6
                    })
            
            except Exception:
                continue
        
        return findings
    
    def _compliance_scan(self) -> List[Dict]:
        """åˆè¦æ€§æƒæ"""
        findings = []
        
        # æª¢æŸ¥ README å­˜åœ¨
        if not (self.repo_path / "README.md").exists():
            findings.append({
                "severity": "low",
                "type": "Missing Documentation",
                "location": "repository root",
                "file_path": "README.md",
                "line_number": 1,
                "code_snippet": "N/A",
                "cwe_id": "N/A",
                "description": "ç¼ºå°‘ README.md æ–‡ä»¶",
                "recommendation": "æ·»åŠ  README.md æ–‡ä»¶èªªæ˜é …ç›®ç”¨é€”",
                "tool": "compliance",
                "confidence": 1.0
            })
        
        # æª¢æŸ¥ LICENSE
        if not (self.repo_path / "LICENSE").exists():
            findings.append({
                "severity": "medium",
                "type": "Missing License",
                "location": "repository root",
                "file_path": "LICENSE",
                "line_number": 1,
                "code_snippet": "N/A",
                "cwe_id": "N/A",
                "description": "ç¼ºå°‘ LICENSE æ–‡ä»¶",
                "recommendation": "æ·»åŠ é©ç•¶çš„é–‹æºè¨±å¯è­‰",
                "tool": "compliance",
                "confidence": 1.0
            })
        
        return findings
    
    def _map_severity(self, severity: str) -> str:
        """æ˜ å°„åš´é‡æ€§ç´šåˆ¥"""
        mapping = {
            "HIGH": "critical",
            "MEDIUM": "high",
            "LOW": "medium"
        }
        return mapping.get(severity.upper(), "low")
    
    def _generate_summary(self):
        """ç”Ÿæˆæƒææ‘˜è¦"""
        all_findings = (
            self.scan_results["security"] +
            self.scan_results["dependencies"] +
            self.scan_results["code_quality"] +
            self.scan_results["performance"] +
            self.scan_results["compliance"]
        )
        
        severity_counts = {
            "critical": 0,
            "high": 0,
            "medium": 0,
            "low": 0
        }
        
        for finding in all_findings:
            severity = finding.get("severity", "low").lower()
            severity_counts[severity] = severity_counts.get(severity, 0) + 1
        
        self.scan_results["summary"] = {
            "total_findings": len(all_findings),
            "critical": severity_counts["critical"],
            "high": severity_counts["high"],
            "medium": severity_counts["medium"],
            "low": severity_counts["low"],
            "findings_by_category": {
                "security": len(self.scan_results["security"]),
                "dependencies": len(self.scan_results["dependencies"]),
                "code_quality": len(self.scan_results["code_quality"]),
                "performance": len(self.scan_results["performance"]),
                "compliance": len(self.scan_results["compliance"])
            }
        }
    
    def _save_results(self):
        """ä¿å­˜æƒæçµæœ"""
        output_file = self.output_dir / f"scan-results-{datetime.now().strftime('%Y%m%d-%H%M%S')}.json"
        
        with open(output_file, 'w') as f:
            json.dump(self.scan_results, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ“Š æƒæçµæœå·²ä¿å­˜è‡³: {output_file}")
        print(f"\nğŸ“ˆ æƒææ‘˜è¦:")
        print(f"  - ç¸½è¨ˆç™¼ç¾: {self.scan_results['summary']['total_findings']} å€‹å•é¡Œ")
        print(f"  - åš´é‡: {self.scan_results['summary']['critical']} å€‹")
        print(f"  - é«˜: {self.scan_results['summary']['high']} å€‹")
        print(f"  - ä¸­: {self.scan_results['summary']['medium']} å€‹")
        print(f"  - ä½: {self.scan_results['summary']['low']} å€‹")

def main() -> None:
    """
    ä¸»åŸ·è¡Œå‡½æ•¸
    
    å¾å‘½ä»¤è¡Œåƒæ•¸è®€å–å„²å­˜åº«è·¯å¾‘ä¸¦åŸ·è¡Œæƒæã€‚
    å¦‚æœç™¼ç¾åš´é‡æˆ–é«˜åš´é‡æ€§å•é¡Œï¼Œå°‡ä»¥éé›¶ç‹€æ…‹ç¢¼é€€å‡ºã€‚
    """
    import argparse
    
    parser = argparse.ArgumentParser(description='é«˜éšæ·±åº¦ä»£ç¢¼æƒæå·¥å…·')
    parser.add_argument('--repo', default='.', help='å¾…æƒæçš„å„²å­˜åº«è·¯å¾‘')
    parser.add_argument('--output-dir', default='.github/code-scanning/reports', 
                        help='æƒæå ±å‘Šè¼¸å‡ºç›®éŒ„')
    parser.add_argument('repo_path', nargs='?', default=None,
                        help='å¾…æƒæçš„å„²å­˜åº«è·¯å¾‘ï¼ˆä½ç½®åƒæ•¸ï¼Œèˆ‡ --repo æ“‡ä¸€ä½¿ç”¨ï¼‰')
    
    args = parser.parse_args()
    
    # å„ªå…ˆä½¿ç”¨ä½ç½®åƒæ•¸ï¼Œå¦‚æœæ²’æœ‰å‰‡ä½¿ç”¨å‘½ååƒæ•¸
    repo_path = args.repo_path if args.repo_path is not None else args.repo
    output_dir = args.output_dir
    
    scanner = AdvancedCodeScanner(repo_path, output_dir)
    results = scanner.deep_scan()
    
    # è¿”å›é©ç•¶çš„é€€å‡ºä»£ç¢¼
    if results["summary"]["critical"] > 0 or results["summary"]["high"] > 0:
        sys.exit(1)
    
    sys.exit(0)

if __name__ == "__main__":
    main()