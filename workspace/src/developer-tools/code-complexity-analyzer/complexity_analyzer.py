# ==============================================================================
# ä»£ç¢¼è¤‡é›œåº¦åˆ†æå·¥å…· - é«˜éšé–‹ç™¼è€…å·¥å…·
# Code Complexity Analyzer - Advanced Developer Tool
# ==============================================================================

import os
import ast
import json
import time
import hashlib
from typing import Dict, List, Optional, Any, Tuple, Set
from dataclasses import dataclass, asdict
from enum import Enum
from pathlib import Path
from collections import defaultdict
import numpy as np
import pandas as pd
from datetime import datetime

import radon.cli as radon_cli
import radon.complexity as radon_cc
import radon.metrics as radon_metrics
from vprof import runner
import lizard


class ComplexityMetric(Enum):
    """è¤‡é›œåº¦åº¦é‡é¡å‹"""
    CYCLOMATIC = "cyclomatic"
    COGNITIVE = "cognitive"
    HALSTEAD = "halstead"
    MAINTAINABILITY = "maintainability"
    LINES_OF_CODE = "loc"


class RiskLevel(Enum):
    """é¢¨éšªç­‰ç´š"""
    LOW = "low"
    MODERATE = "moderate"
    HIGH = "high"
    VERY_HIGH = "very_high"


@dataclass
class FunctionComplexity:
    """å‡½æ•¸è¤‡é›œåº¦æ•¸æ“š"""
    name: str
    file_path: str
    line_start: int
    line_end: int
    cyclomatic_complexity: int
    cognitive_complexity: int
    halstead_metrics: Dict[str, float]
    maintainability_index: float
    lines_of_code: int
    parameters_count: int
    nesting_depth: int
    risk_level: RiskLevel
    recommendations: List[str]


@dataclass
class FileComplexity:
    """æ–‡ä»¶è¤‡é›œåº¦æ•¸æ“š"""
    file_path: str
    total_lines: int
    code_lines: int
    comment_lines: int
    blank_lines: int
    functions: List[FunctionComplexity]
    average_complexity: float
    maintainability_index: float
    risk_level: RiskLevel
    technical_debt: float


@dataclass
class ProjectComplexity:
    """é …ç›®è¤‡é›œåº¦æ•¸æ“š"""
    project_name: str
    total_files: int
    total_functions: int
    total_lines: int
    average_complexity: float
    complexity_distribution: Dict[str, int]
    most_complex_files: List[str]
    technical_debt_summary: Dict[str, float]
    trends: List[Dict[str, Any]]
    recommendations: List[str]


class CodeComplexityAnalyzer:
    """ä»£ç¢¼è¤‡é›œåº¦åˆ†æå™¨æ ¸å¿ƒé¡"""
    
    def __init__(self, config_path: str = "config/complexity-analyzer-config.yaml"):
        self.config = self._load_config(config_path)
        self.complexity_cache = {}
        self.historical_data = []
        
    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """è¼‰å…¥é…ç½®æ–‡ä»¶"""
        try:
            import yaml
            with open(config_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        except FileNotFoundError:
            # é»˜èªé…ç½®
            return {
                'thresholds': {
                    'cyclomatic': {
                        'low': 5,
                        'moderate': 10,
                        'high': 15,
                        'very_high': 20
                    },
                    'cognitive': {
                        'low': 8,
                        'moderate': 15,
                        'high': 25,
                        'very_high': 40
                    },
                    'maintainability': {
                        'excellent': 85,
                        'good': 70,
                        'moderate': 50,
                        'poor': 30
                    }
                },
                'exclude_patterns': [
                    'test_*.py',
                    '*_test.py',
                    '__pycache__/',
                    '.git/',
                    'node_modules/',
                    'venv/',
                    'env/'
                ],
                'output_directory': 'reports/complexity',
                'enable_historical_tracking': True,
                'enable_trend_analysis': True
            }
    
    def analyze_project(self, project_path: str) -> ProjectComplexity:
        """åˆ†ææ•´å€‹é …ç›®çš„è¤‡é›œåº¦"""
        project_path = Path(project_path)
        
        if not project_path.exists():
            raise FileNotFoundError(f"é …ç›®è·¯å¾‘ä¸å­˜åœ¨: {project_path}")
        
        print(f"é–‹å§‹åˆ†æé …ç›®: {project_path}")
        
        # æ”¶é›†æ‰€æœ‰ Python æ–‡ä»¶
        python_files = self._collect_python_files(project_path)
        
        if not python_files:
            raise ValueError("æœªæ‰¾åˆ° Python æ–‡ä»¶")
        
        print(f"æ‰¾åˆ° {len(python_files)} å€‹ Python æ–‡ä»¶")
        
        # åˆ†ææ¯å€‹æ–‡ä»¶
        file_complexities = []
        total_functions = []
        all_function_data = []
        
        for file_path in python_files:
            try:
                file_complexity = self.analyze_file(file_path)
                file_complexities.append(file_complexity)
                total_functions.extend(file_complexity.functions)
                all_function_data.extend([asdict(f) for f in file_complexity.functions])
                
            except Exception as e:
                print(f"åˆ†ææ–‡ä»¶å¤±æ•— {file_path}: {e}")
                continue
        
        # è¨ˆç®—é …ç›®ç´šåˆ¥çµ±è¨ˆ
        project_complexity = self._calculate_project_metrics(
            project_path.name,
            file_complexities,
            total_functions
        )
        
        # ä¿å­˜æ­·å²æ•¸æ“š
        if self.config.get('enable_historical_tracking', True):
            self._save_historical_data(project_complexity)
        
        # ç”Ÿæˆè¶¨å‹¢åˆ†æ
        if self.config.get('enable_trend_analysis', True):
            project_complexity.trends = self._analyze_trends()
        
        return project_complexity
    
    def _collect_python_files(self, project_path: Path) -> List[Path]:
        """æ”¶é›† Python æ–‡ä»¶"""
        exclude_patterns = self.config.get('exclude_patterns', [])
        python_files = []
        
        for file_path in project_path.rglob('*.py'):
            # æª¢æŸ¥æ˜¯å¦æ‡‰è©²æ’é™¤
            if self._should_exclude_file(file_path, exclude_patterns):
                continue
            
            python_files.append(file_path)
        
        return python_files
    
    def _should_exclude_file(self, file_path: Path, exclude_patterns: List[str]) -> bool:
        """åˆ¤æ–·æ–‡ä»¶æ˜¯å¦æ‡‰è©²è¢«æ’é™¤"""
        file_str = str(file_path)
        
        for pattern in exclude_patterns:
            if pattern in file_str:
                return True
        
        return False
    
    def analyze_file(self, file_path: Path) -> FileComplexity:
        """åˆ†æå–®å€‹æ–‡ä»¶çš„è¤‡é›œåº¦"""
        print(f"åˆ†ææ–‡ä»¶: {file_path}")
        
        # è®€å–æ–‡ä»¶å…§å®¹
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # ä½¿ç”¨ radon åˆ†æ
        cc_results = radon_cc.cc_visit(content)
        mi_results = radon_metrics.mi_visit(content, True)
        halstead_results = radon_metrics.h_visit(content)
        
        # ä½¿ç”¨ lizard åˆ†æ
        lizard_result = lizard.analyze_file.analyze_source_code(
            str(file_path), content
        )
        
        # åˆ†æå‡½æ•¸
        functions = []
        for func in cc_results:
            function_complexity = self._analyze_function(
                func, file_path, content, halstead_results
            )
            functions.append(function_complexity)
        
        # è¨ˆç®—æ–‡ä»¶ç´šåˆ¥æŒ‡æ¨™
        total_lines = len(content.splitlines())
        code_lines = lizard_result.nloc
        comment_lines = len([line for line in content.splitlines() if line.strip().startswith('#')])
        blank_lines = total_lines - code_lines - comment_lines
        
        # è¨ˆç®—å¹³å‡è¤‡é›œåº¦
        avg_complexity = np.mean([f.cyclomatic_complexity for f in functions]) if functions else 0
        
        # ç²å–å¯ç¶­è­·æ€§æŒ‡æ•¸
        maintainability_index = mi_results if isinstance(mi_results, (int, float)) else 70.0
        
        # è¨ˆç®—é¢¨éšªç­‰ç´š
        risk_level = self._calculate_file_risk_level(functions)
        
        # è¨ˆç®—æŠ€è¡“å‚µå‹™
        technical_debt = self._calculate_technical_debt(functions)
        
        return FileComplexity(
            file_path=str(file_path),
            total_lines=total_lines,
            code_lines=code_lines,
            comment_lines=comment_lines,
            blank_lines=blank_lines,
            functions=functions,
            average_complexity=avg_complexity,
            maintainability_index=maintainability_index,
            risk_level=risk_level,
            technical_debt=technical_debt
        )
    
    def _analyze_function(self, func, file_path: Path, content: str, halstead_results) -> FunctionComplexity:
        """åˆ†æå–®å€‹å‡½æ•¸çš„è¤‡é›œåº¦"""
        # åŸºæœ¬è¤‡é›œåº¦åº¦é‡
        cyclomatic = func.complexity
        cognitive = self._calculate_cognitive_complexity(func)
        
        # Halstead æŒ‡æ¨™
        halstead_metrics = self._get_halstead_metrics(func, halstead_results)
        
        # å¯ç¶­è­·æ€§æŒ‡æ•¸
        maintainability = self._calculate_function_maintainability(func, halstead_metrics)
        
        # ä»£ç¢¼è¡Œæ•¸
        lines_of_code = func.endlineno - func.lineno + 1
        
        # åƒæ•¸æ•¸é‡
        parameters_count = len(func.arguments) if func.arguments else 0
        
        # åµŒå¥—æ·±åº¦
        nesting_depth = self._calculate_nesting_depth(func)
        
        # é¢¨éšªç­‰ç´š
        risk_level = self._calculate_function_risk_level(cyclomatic, cognitive)
        
        # ç”Ÿæˆå»ºè­°
        recommendations = self._generate_function_recommendations(
            cyclomatic, cognitive, parameters_count, nesting_depth
        )
        
        return FunctionComplexity(
            name=func.name,
            file_path=str(file_path),
            line_start=func.lineno,
            line_end=func.endlineno,
            cyclomatic_complexity=cyclomatic,
            cognitive_complexity=cognitive,
            halstead_metrics=halstead_metrics,
            maintainability_index=maintainability,
            lines_of_code=lines_of_code,
            parameters_count=parameters_count,
            nesting_depth=nesting_depth,
            risk_level=risk_level,
            recommendations=recommendations
        )
    
    def _calculate_cognitive_complexity(self, func) -> int:
        """è¨ˆç®—èªçŸ¥è¤‡é›œåº¦"""
        # é€™æ˜¯ä¸€å€‹ç°¡åŒ–çš„å¯¦ç¾ï¼Œå¯¦éš›å¯èƒ½éœ€è¦æ›´è¤‡é›œçš„åˆ†æ
        complexity = 1  # åŸºç¤è¤‡é›œåº¦
        
        # é€™è£¡éœ€è¦éæ­· AST ä¾†è¨ˆç®—èªçŸ¥è¤‡é›œåº¦
        # æš«æ™‚è¿”å›ä¸€å€‹åŸºæ–¼åœˆè¤‡é›œåº¦çš„ä¼°ç®—å€¼
        return int(func.complexity * 1.5)
    
    def _get_halstead_metrics(self, func, halstead_results) -> Dict[str, float]:
        """ç²å– Halstead æŒ‡æ¨™"""
        # ç°¡åŒ–å¯¦ç¾ï¼Œå¯¦éš›æ‡‰è©²æ ¹æ“šå‡½æ•¸ç¯„åœæå–
        return {
            'difficulty': 10.0,
            'effort': 1000.0,
            'time': 50.0,
            'bugs': 0.5,
            'vocabulary': 20.0,
            'length': 100.0,
            'volume': 500.0
        }
    
    def _calculate_function_maintainability(self, func, halstead_metrics: Dict[str, float]) -> float:
        """è¨ˆç®—å‡½æ•¸å¯ç¶­è­·æ€§æŒ‡æ•¸"""
        # ç°¡åŒ–çš„å¯ç¶­è­·æ€§æŒ‡æ•¸è¨ˆç®—
        base_mi = 171 - 5.2 * np.log(func.complexity) - 0.23 * func.complexity - 16.2 * np.log(func.endlineno - func.lineno + 1)
        
        # æ ¹æ“š Halstead æŒ‡æ¨™èª¿æ•´
        if halstead_metrics.get('volume', 0) > 1000:
            base_mi -= 10
        
        return max(0, min(100, base_mi))
    
    def _calculate_nesting_depth(self, func) -> int:
        """è¨ˆç®—åµŒå¥—æ·±åº¦"""
        # ç°¡åŒ–å¯¦ç¾
        return min(5, func.complexity // 3)
    
    def _calculate_function_risk_level(self, cyclomatic: int, cognitive: int) -> RiskLevel:
        """è¨ˆç®—å‡½æ•¸é¢¨éšªç­‰ç´š"""
        thresholds = self.config['thresholds']['cyclomatic']
        
        # ä½¿ç”¨åœˆè¤‡é›œåº¦ä½œç‚ºä¸»è¦æŒ‡æ¨™ï¼ŒèªçŸ¥è¤‡é›œåº¦ä½œç‚ºè¼”åŠ©
        if cyclomatic <= thresholds['low'] and cognitive <= self.config['thresholds']['cognitive']['low']:
            return RiskLevel.LOW
        elif cyclomatic <= thresholds['moderate'] and cognitive <= self.config['thresholds']['cognitive']['moderate']:
            return RiskLevel.MODERATE
        elif cyclomatic <= thresholds['high'] and cognitive <= self.config['thresholds']['cognitive']['high']:
            return RiskLevel.HIGH
        else:
            return RiskLevel.VERY_HIGH
    
    def _generate_function_recommendations(self, cyclomatic: int, cognitive: int, params: int, nesting: int) -> List[str]:
        """ç”Ÿæˆå‡½æ•¸æ”¹é€²å»ºè­°"""
        recommendations = []
        
        if cyclomatic > self.config['thresholds']['cyclomatic']['moderate']:
            recommendations.append("è€ƒæ…®é‡æ§‹æ­¤å‡½æ•¸ä»¥é™ä½åœˆè¤‡é›œåº¦")
        
        if cognitive > self.config['thresholds']['cognitive']['moderate']:
            recommendations.append("å‡½æ•¸é‚è¼¯éæ–¼è¤‡é›œï¼Œå»ºè­°æ‹†åˆ†ç‚ºæ›´å°çš„å‡½æ•¸")
        
        if params > 7:
            recommendations.append("åƒæ•¸æ•¸é‡éå¤šï¼Œè€ƒæ…®ä½¿ç”¨é…ç½®å°è±¡æˆ–æ¸›å°‘åƒæ•¸")
        
        if nesting > 4:
            recommendations.append("åµŒå¥—å±¤æ•¸éæ·±ï¼Œè€ƒæ…®ä½¿ç”¨æ—©æœŸè¿”å›æˆ–æå–å‡½æ•¸")
        
        if cyclomatic > 20 or cognitive > 40:
            recommendations.append("æ­¤å‡½æ•¸éœ€è¦ç«‹å³é‡æ§‹")
        
        return recommendations
    
    def _calculate_file_risk_level(self, functions: List[FunctionComplexity]) -> RiskLevel:
        """è¨ˆç®—æ–‡ä»¶é¢¨éšªç­‰ç´š"""
        if not functions:
            return RiskLevel.LOW
        
        # åŸºæ–¼æœ€è¤‡é›œçš„å‡½æ•¸ç¢ºå®šæ–‡ä»¶é¢¨éšª
        risk_scores = {
            RiskLevel.LOW: 1,
            RiskLevel.MODERATE: 2,
            RiskLevel.HIGH: 3,
            RiskLevel.VERY_HIGH: 4
        }
        
        max_risk = max(functions, key=lambda f: risk_scores[f.risk_level])
        return max_risk.risk_level
    
    def _calculate_technical_debt(self, functions: List[FunctionComplexity]) -> float:
        """è¨ˆç®—æŠ€è¡“å‚µå‹™ï¼ˆå°æ™‚ï¼‰"""
        total_debt = 0.0
        
        for func in functions:
            # åŸºæ–¼è¤‡é›œåº¦è¨ˆç®—é‡æ§‹æ™‚é–“
            if func.risk_level == RiskLevel.VERY_HIGH:
                total_debt += 8.0  # 8å°æ™‚
            elif func.risk_level == RiskLevel.HIGH:
                total_debt += 4.0  # 4å°æ™‚
            elif func.risk_level == RiskLevel.MODERATE:
                total_debt += 2.0  # 2å°æ™‚
            # LOW é¢¨éšªä¸è¨ˆå…¥æŠ€è¡“å‚µå‹™
        
        return total_debt
    
    def _calculate_project_metrics(self, project_name: str, file_complexities: List[FileComplexity], total_functions: List[FunctionComplexity]) -> ProjectComplexity:
        """è¨ˆç®—é …ç›®ç´šåˆ¥æŒ‡æ¨™"""
        # åŸºæœ¬çµ±è¨ˆ
        total_files = len(file_complexities)
        total_func_count = len(total_functions)
        total_lines = sum(f.total_lines for f in file_complexities)
        
        # å¹³å‡è¤‡é›œåº¦
        avg_complexity = np.mean([f.cyclomatic_complexity for f in total_functions]) if total_functions else 0
        
        # è¤‡é›œåº¦åˆ†ä½ˆ
        complexity_dist = self._calculate_complexity_distribution(total_functions)
        
        # æœ€è¤‡é›œçš„æ–‡ä»¶
        most_complex_files = sorted(
            file_complexities,
            key=lambda f: f.average_complexity,
            reverse=True
        )[:10]
        
        # æŠ€è¡“å‚µå‹™ç¸½çµ
        tech_debt_summary = {
            'total_hours': sum(f.technical_debt for f in file_complexities),
            'files_with_debt': len([f for f in file_complexities if f.technical_debt > 0]),
            'functions_requiring_refactor': len([f for f in total_functions if f.risk_level in [RiskLevel.HIGH, RiskLevel.VERY_HIGH]])
        }
        
        # é …ç›®å»ºè­°
        recommendations = self._generate_project_recommendations(file_complexities, total_functions)
        
        return ProjectComplexity(
            project_name=project_name,
            total_files=total_files,
            total_functions=total_func_count,
            total_lines=total_lines,
            average_complexity=avg_complexity,
            complexity_distribution=complexity_dist,
            most_complex_files=[f.file_path for f in most_complex_files],
            technical_debt_summary=tech_debt_summary,
            trends=[],
            recommendations=recommendations
        )
    
    def _calculate_complexity_distribution(self, functions: List[FunctionComplexity]) -> Dict[str, int]:
        """è¨ˆç®—è¤‡é›œåº¦åˆ†ä½ˆ"""
        distribution = {
            'low': 0,
            'moderate': 0,
            'high': 0,
            'very_high': 0
        }
        
        for func in functions:
            distribution[func.risk_level.value] += 1
        
        return distribution
    
    def _generate_project_recommendations(self, file_complexities: List[FileComplexity], total_functions: List[FunctionComplexity]) -> List[str]:
        """ç”Ÿæˆé …ç›®ç´šåˆ¥å»ºè­°"""
        recommendations = []
        
        # çµ±è¨ˆé«˜è¤‡é›œåº¦å‡½æ•¸
        high_complexity_funcs = [f for f in total_functions if f.risk_level in [RiskLevel.HIGH, RiskLevel.VERY_HIGH]]
        
        if len(high_complexity_funcs) > len(total_functions) * 0.2:  # è¶…é20%çš„å‡½æ•¸æ˜¯é«˜è¤‡é›œåº¦
            recommendations.append("é …ç›®ä¸­æœ‰å¤ªå¤šé«˜è¤‡é›œåº¦å‡½æ•¸ï¼Œå»ºè­°åˆ¶å®šé‡æ§‹è¨ˆåŠƒ")
        
        # çµ±è¨ˆæŠ€è¡“å‚µå‹™
        total_debt = sum(f.technical_debt for f in file_complexities)
        if total_debt > 40:  # è¶…é40å°æ™‚
            recommendations.append(f"æŠ€è¡“å‚µå‹™éé«˜ï¼ˆ{total_debt:.1f}å°æ™‚ï¼‰ï¼Œéœ€è¦å„ªå…ˆè™•ç†")
        
        # çµ±è¨ˆæ–‡ä»¶å¤§å°
        large_files = [f for f in file_complexities if f.total_lines > 500]
        if len(large_files) > len(file_complexities) * 0.1:  # è¶…é10%çš„æ–‡ä»¶éå¤§
            recommendations.append("å»ºè­°æ‹†åˆ†éå¤§çš„æ–‡ä»¶ä»¥æé«˜å¯ç¶­è­·æ€§")
        
        # æª¢æŸ¥å¹³å‡è¤‡é›œåº¦
        if total_functions:
            avg_complexity = np.mean([f.cyclomatic_complexity for f in total_functions])
            if avg_complexity > 10:
                recommendations.append("é …ç›®å¹³å‡è¤‡é›œåº¦åé«˜ï¼Œå»ºè­°åŠ å¼·ä»£ç¢¼å¯©æŸ¥å’Œé‡æ§‹")
        
        return recommendations
    
    def _save_historical_data(self, project_complexity: ProjectComplexity):
        """ä¿å­˜æ­·å²æ•¸æ“š"""
        historical_file = Path(self.config.get('output_directory', 'reports/complexity')) / 'historical_data.json'
        historical_file.parent.mkdir(parents=True, exist_ok=True)
        
        # åŠ è¼‰ç¾æœ‰æ­·å²æ•¸æ“š
        if historical_file.exists():
            with open(historical_file, 'r', encoding='utf-8') as f:
                historical_data = json.load(f)
        else:
            historical_data = []
        
        # æ·»åŠ æ–°çš„æ•¸æ“šé»
        data_point = {
            'timestamp': datetime.now().isoformat(),
            'project_name': project_complexity.project_name,
            'total_functions': project_complexity.total_functions,
            'average_complexity': project_complexity.average_complexity,
            'total_lines': project_complexity.total_lines,
            'technical_debt_hours': project_complexity.technical_debt_summary['total_hours']
        }
        
        historical_data.append(data_point)
        
        # ä¿ç•™æœ€è¿‘100å€‹æ•¸æ“šé»
        historical_data = historical_data[-100:]
        
        # ä¿å­˜æ­·å²æ•¸æ“š
        with open(historical_file, 'w', encoding='utf-8') as f:
            json.dump(historical_data, f, indent=2, ensure_ascii=False)
    
    def _analyze_trends(self) -> List[Dict[str, Any]]:
        """åˆ†æè¶¨å‹¢"""
        historical_file = Path(self.config.get('output_directory', 'reports/complexity')) / 'historical_data.json'
        
        if not historical_file.exists():
            return []
        
        with open(historical_file, 'r', encoding='utf-8') as f:
            historical_data = json.load(f)
        
        if len(historical_data) < 2:
            return []
        
        trends = []
        
        # è¨ˆç®—å„é …æŒ‡æ¨™çš„è¶¨å‹¢
        metrics = ['total_functions', 'average_complexity', 'total_lines', 'technical_debt_hours']
        
        for metric in metrics:
            values = [point[metric] for point in historical_data[-10:]]  # æœ€è¿‘10å€‹æ•¸æ“šé»
            
            if len(values) >= 2:
                # è¨ˆç®—è¶¨å‹¢ï¼ˆç°¡å–®ç·šæ€§å›æ­¸ï¼‰
                x = list(range(len(values)))
                trend_slope = np.polyfit(x, values, 1)[0]
                
                trend_direction = "increasing" if trend_slope > 0.1 else "decreasing" if trend_slope < -0.1 else "stable"
                
                trends.append({
                    'metric': metric,
                    'direction': trend_direction,
                    'slope': trend_slope,
                    'recent_values': values[-5:]
                })
        
        return trends
    
    def generate_report(self, project_complexity: ProjectComplexity, output_path: Optional[str] = None) -> str:
        """ç”Ÿæˆè¤‡é›œåº¦åˆ†æå ±å‘Š"""
        # å‰µå»ºè¼¸å‡ºç›®éŒ„
        output_dir = Path(output_path or self.config.get('output_directory', 'reports/complexity'))
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # ç”Ÿæˆ HTML å ±å‘Š
        html_report = self._generate_html_report(project_complexity)
        html_file = output_dir / f"complexity_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html"
        
        with open(html_file, 'w', encoding='utf-8') as f:
            f.write(html_report)
        
        # ç”Ÿæˆ JSON å ±å‘Š
        json_report = asdict(project_complexity)
        json_file = output_dir / f"complexity_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(json_report, f, indent=2, ensure_ascii=False, default=str)
        
        # ç”Ÿæˆ CSV å ±å‘Š
        csv_file = output_dir / f"complexity_functions_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        self._generate_csv_report(project_complexity, csv_file)
        
        print(f"å ±å‘Šå·²ç”Ÿæˆ:")
        print(f"HTML: {html_file}")
        print(f"JSON: {json_file}")
        print(f"CSV: {csv_file}")
        
        return str(html_file)
    
    def _generate_html_report(self, project_complexity: ProjectComplexity) -> str:
        """ç”Ÿæˆ HTML æ ¼å¼çš„å ±å‘Š"""
        html_template = """
<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ä»£ç¢¼è¤‡é›œåº¦åˆ†æå ±å‘Š - {project_name}</title>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <style>
        body {{ font-family: Arial, sans-serif; margin: 20px; background-color: #f5f5f5; }}
        .container {{ max-width: 1200px; margin: 0 auto; background-color: white; padding: 20px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }}
        .header {{ text-align: center; border-bottom: 2px solid #007bff; padding-bottom: 20px; margin-bottom: 30px; }}
        .metrics-grid {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 20px; margin-bottom: 30px; }}
        .metric-card {{ background-color: #f8f9fa; padding: 20px; border-radius: 8px; border-left: 4px solid #007bff; }}
        .metric-value {{ font-size: 2em; font-weight: bold; color: #007bff; }}
        .metric-label {{ color: #666; margin-top: 5px; }}
        .chart-container {{ margin: 30px 0; }}
        .risk-high {{ color: #dc3545; }}
        .risk-moderate {{ color: #ffc107; }}
        .risk-low {{ color: #28a745; }}
        .recommendations {{ background-color: #fff3cd; padding: 20px; border-radius: 8px; border-left: 4px solid #ffc107; }}
        .recommendations ul {{ margin: 10px 0; }}
        table {{ width: 100%; border-collapse: collapse; margin: 20px 0; }}
        th, td {{ padding: 12px; text-align: left; border-bottom: 1px solid #ddd; }}
        th {{ background-color: #f8f9fa; font-weight: bold; }}
        .risk-badge {{ padding: 4px 8px; border-radius: 4px; color: white; font-size: 0.8em; }}
        .risk-high {{ background-color: #dc3545; }}
        .risk-moderate {{ background-color: #ffc107; color: #000; }}
        .risk-low {{ background-color: #28a745; }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸ” ä»£ç¢¼è¤‡é›œåº¦åˆ†æå ±å‘Š</h1>
            <h2>{project_name}</h2>
            <p>ç”Ÿæˆæ™‚é–“: {timestamp}</p>
        </div>
        
        <div class="metrics-grid">
            <div class="metric-card">
                <div class="metric-value">{total_files}</div>
                <div class="metric-label">ç¸½æ–‡ä»¶æ•¸</div>
            </div>
            <div class="metric-card">
                <div class="metric-value">{total_functions}</div>
                <div class="metric-label">ç¸½å‡½æ•¸æ•¸</div>
            </div>
            <div class="metric-card">
                <div class="metric-value">{average_complexity:.1f}</div>
                <div class="metric-label">å¹³å‡è¤‡é›œåº¦</div>
            </div>
            <div class="metric-card">
                <div class="metric-value">{total_lines:,}</div>
                <div class="metric-label">ç¸½ä»£ç¢¼è¡Œæ•¸</div>
            </div>
            <div class="metric-card">
                <div class="metric-value">{technical_debt_hours:.1f}h</div>
                <div class="metric-label">æŠ€è¡“å‚µå‹™</div>
            </div>
            <div class="metric-card">
                <div class="metric-value">{maintainability_avg:.1f}</div>
                <div class="metric-label">å¹³å‡å¯ç¶­è­·æ€§æŒ‡æ•¸</div>
            </div>
        </div>
        
        <div class="chart-container">
            <h3>è¤‡é›œåº¦åˆ†ä½ˆ</h3>
            <canvas id="complexityChart"></canvas>
        </div>
        
        <div class="chart-container">
            <h3>æŠ€è¡“å‚µå‹™åˆ†æ</h3>
            <canvas id="debtChart"></canvas>
        </div>
        
        {recommendations_section}
        
        <div class="chart-container">
            <h3>æœ€è¤‡é›œçš„æ–‡ä»¶</h3>
            <table>
                <thead>
                    <tr>
                        <th>æ–‡ä»¶è·¯å¾‘</th>
                        <th>å¹³å‡è¤‡é›œåº¦</th>
                        <th>å‡½æ•¸æ•¸é‡</th>
                        <th>é¢¨éšªç­‰ç´š</th>
                        <th>æŠ€è¡“å‚µå‹™</th>
                    </tr>
                </thead>
                <tbody>
                    {most_complex_files_rows}
                </tbody>
            </table>
        </div>
    </div>
    
    <script>
        // è¤‡é›œåº¦åˆ†ä½ˆåœ–
        const complexityCtx = document.getElementById('complexityChart').getContext('2d');
        new Chart(complexityCtx, {{
            type: 'doughnut',
            data: {{
                labels: ['ä½é¢¨éšª', 'ä¸­ç­‰é¢¨éšª', 'é«˜é¢¨éšª', 'æ¥µé«˜é¢¨éšª'],
                datasets: [{{
                    data: [{complexity_low}, {complexity_moderate}, {complexity_high}, {complexity_very_high}],
                    backgroundColor: ['#28a745', '#ffc107', '#fd7e14', '#dc3545']
                }}]
            }},
            options: {{
                responsive: true,
                plugins: {{
                    title: {{
                        display: true,
                        text: 'å‡½æ•¸è¤‡é›œåº¦åˆ†ä½ˆ'
                    }}
                }}
            }}
        }});
        
        // æŠ€è¡“å‚µå‹™åœ–
        const debtCtx = document.getElementById('debtChart').getContext('2d');
        new Chart(debtCtx, {{
            type: 'bar',
            data: {{
                labels: ['ç¸½æŠ€è¡“å‚µå‹™', 'æœ‰å‚µå‹™çš„æ–‡ä»¶æ•¸', 'éœ€è¦é‡æ§‹çš„å‡½æ•¸æ•¸'],
                datasets: [{{
                    label: 'æ•¸é‡',
                    data: [{debt_total}, {debt_files}, {debt_functions}],
                    backgroundColor: ['#007bff', '#17a2b8', '#6f42c1']
                }}]
            }},
            options: {{
                responsive: true,
                plugins: {{
                    title: {{
                        display: true,
                        text: 'æŠ€è¡“å‚µå‹™çµ±è¨ˆ'
                    }}
                }}
            }}
        }});
    </script>
</body>
</html>
        """
        
        # æº–å‚™æ¨¡æ¿æ•¸æ“š
        complexity_dist = project_complexity.complexity_distribution
        tech_debt = project_complexity.technical_debt_summary
        
        recommendations_html = ""
        if project_complexity.recommendations:
            recommendations_html = f"""
            <div class="recommendations">
                <h3>ğŸ“‹ æ”¹é€²å»ºè­°</h3>
                <ul>
                {''.join(f'<li>{rec}</li>' for rec in project_complexity.recommendations)}
                </ul>
            </div>
            """
        
        # ç”Ÿæˆæœ€è¤‡é›œæ–‡ä»¶è¡¨æ ¼è¡Œ
        most_complex_files_rows = ""
        # é€™è£¡éœ€è¦å¾ file_complexities ä¸­ç²å–è©³ç´°ä¿¡æ¯ï¼Œæš«æ™‚ä½¿ç”¨ç°¡åŒ–ç‰ˆæœ¬
        
        # è¨ˆç®—å¹³å‡å¯ç¶­è­·æ€§æŒ‡æ•¸
        maintainability_avg = 70.0  # ç°¡åŒ–å¯¦ç¾
        
        return html_template.format(
            project_name=project_complexity.project_name,
            timestamp=datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            total_files=project_complexity.total_files,
            total_functions=project_complexity.total_functions,
            average_complexity=project_complexity.average_complexity,
            total_lines=project_complexity.total_lines,
            technical_debt_hours=tech_debt['total_hours'],
            maintainability_avg=maintainability_avg,
            complexity_low=complexity_dist.get('low', 0),
            complexity_moderate=complexity_dist.get('moderate', 0),
            complexity_high=complexity_dist.get('high', 0),
            complexity_very_high=complexity_dist.get('very_high', 0),
            debt_total=tech_debt['total_hours'],
            debt_files=tech_debt['files_with_debt'],
            debt_functions=tech_debt['functions_requiring_refactor'],
            recommendations_section=recommendations_html,
            most_complex_files_rows=most_complex_files_rows
        )
    
    def _generate_csv_report(self, project_complexity: ProjectComplexity, csv_file: Path):
        """ç”Ÿæˆ CSV æ ¼å¼çš„å ±å‘Š"""
        # é€™è£¡éœ€è¦æ”¶é›†æ‰€æœ‰å‡½æ•¸æ•¸æ“šä¸¦ç”Ÿæˆ CSV
        # ç°¡åŒ–å¯¦ç¾
        pass


def main():
    """ä¸»å‡½æ•¸"""
    import argparse
    
    parser = argparse.ArgumentParser(description="ä»£ç¢¼è¤‡é›œåº¦åˆ†æå·¥å…·")
    parser.add_argument("project_path", help="é …ç›®è·¯å¾‘")
    parser.add_argument("--output", "-o", help="è¼¸å‡ºç›®éŒ„")
    parser.add_argument("--config", "-c", help="é…ç½®æ–‡ä»¶è·¯å¾‘")
    parser.add_argument("--format", choices=['html', 'json', 'csv'], default='html', help="å ±å‘Šæ ¼å¼")
    
    args = parser.parse_args()
    
    # å‰µå»ºåˆ†æå™¨
    analyzer = CodeComplexityAnalyzer(args.config)
    
    # åˆ†æé …ç›®
    print("é–‹å§‹åˆ†æä»£ç¢¼è¤‡é›œåº¦...")
    project_complexity = analyzer.analyze_project(args.project_path)
    
    # ç”Ÿæˆå ±å‘Š
    report_path = analyzer.generate_report(project_complexity, args.output)
    
    print(f"\nåˆ†æå®Œæˆï¼")
    print(f"é …ç›®: {project_complexity.project_name}")
    print(f"ç¸½æ–‡ä»¶: {project_complexity.total_files}")
    print(f"ç¸½å‡½æ•¸: {project_complexity.total_functions}")
    print(f"å¹³å‡è¤‡é›œåº¦: {project_complexity.average_complexity:.2f}")
    print(f"æŠ€è¡“å‚µå‹™: {project_complexity.technical_debt_summary['total_hours']:.1f} å°æ™‚")
    print(f"å ±å‘Š: {report_path}")


if __name__ == "__main__":
    main()