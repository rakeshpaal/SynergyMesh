# ==============================================================================
# ç›£æ§å‘Šè­¦ç³»çµ±
# Monitoring and Alerting System
# ==============================================================================

import os
import json
import time
import asyncio
import statistics
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple, Callable, Union
from dataclasses import dataclass, asdict
from enum import Enum
from pathlib import Path
import logging
import threading

import prometheus_client
from prometheus_client import CollectorRegistry, Gauge, Counter, Histogram, generate_latest
import requests
import yaml
import psutil
import aiohttp
from redis import Redis


class MetricType(Enum):
    """æŒ‡æ¨™é¡å‹"""
    COUNTER = "counter"
    GAUGE = "gauge"
    HISTOGRAM = "histogram"
    SUMMARY = "summary"


class AlertSeverity(Enum):
    """å‘Šè­¦åš´é‡ç¨‹åº¦"""
    INFO = "info"
    WARNING = "warning"
    CRITICAL = "critical"
    EMERGENCY = "emergency"


class AlertStatus(Enum):
    """å‘Šè­¦ç‹€æ…‹"""
    ACTIVE = "active"
    RESOLVED = "resolved"
    SILENCED = "silenced"
    SUPPRESSED = "suppressed"


@dataclass
class MetricData:
    """æŒ‡æ¨™æ•¸æ“š"""
    name: str
    value: float
    labels: Dict[str, str]
    timestamp: datetime
    metric_type: MetricType
    help_text: str


@dataclass
class AlertRule:
    """å‘Šè­¦è¦å‰‡"""
    rule_id: str
    name: str
    description: str
    metric_name: str
    condition: str  # "> 100", "< 50", "== 0", etc.
    threshold: float
    severity: AlertSeverity
    for_duration: int  # æŒçºŒæ™‚é–“ï¼ˆç§’ï¼‰
    labels: Dict[str, str]
    annotations: Dict[str, str]
    enabled: bool = True
    evaluation_interval: int = 60  # è©•ä¼°é–“éš”ï¼ˆç§’ï¼‰


@dataclass
class Alert:
    """å‘Šè­¦"""
    alert_id: str
    rule_id: str
    status: AlertStatus
    severity: AlertSeverity
    start_time: datetime
    end_time: Optional[datetime]
    message: str
    labels: Dict[str, str]
    annotations: Dict[str, str]
    evaluation_count: int = 0
    last_evaluated: Optional[datetime] = None


@dataclass
class NotificationChannel:
    """é€šçŸ¥æ¸ é“"""
    channel_id: str
    name: str
    type: str  # 'slack', 'email', 'webhook', 'teams'
    config: Dict[str, Any]
    enabled: bool = True
    rate_limit: int = 60  # é€Ÿç‡é™åˆ¶ï¼ˆç§’ï¼‰


class MonitoringSystem:
    """ç›£æ§ç³»çµ±æ ¸å¿ƒé¡"""
    
    def __init__(self, config_path: str = None):
        self.config = self._load_config(config_path)
        self.logger = self._setup_logger()
        self.metrics_registry = CollectorRegistry()
        self.prometheus_metrics = {}
        self.alert_rules = {}
        self.active_alerts = {}
        self.notification_channels = {}
        self.metric_data = []
        self.redis_client = self._init_redis_client()
        
        # åˆå§‹åŒ–ç³»çµ±ç›£æ§
        self._init_system_metrics()
        
        # å•Ÿå‹•ç›£æ§ä»»å‹™
        self.monitoring_tasks = []
        self.alert_evaluation_task = None
        
    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """è¼‰å…¥é…ç½®æ–‡ä»¶"""
        if config_path and Path(config_path).exists():
            with open(config_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        
        # é»˜èªé…ç½®
        return {
            'prometheus': {
                'enabled': True,
                'port': 8090,
                'endpoint': '/metrics'
            },
            'metrics': {
                'retention_hours': 24,
                'collection_interval': 30,
                'batch_size': 100
            },
            'alerts': {
                'evaluation_interval': 60,
                'max_alerts_per_rule': 10,
                'alert_history_retention_days': 7
            },
            'notifications': {
                'default_rate_limit': 300,
                'max_notifications_per_minute': 10,
                'retry_attempts': 3,
                'retry_delay': 30
            },
            'redis': {
                'host': os.getenv('REDIS_HOST', 'localhost'),
                'port': int(os.getenv('REDIS_PORT', 6379)),
                'db': int(os.getenv('REDIS_DB', 0)),
                'enabled': False
            }
        }
    
    def _setup_logger(self) -> logging.Logger:
        """è¨­ç½®æ—¥èªŒè¨˜éŒ„å™¨"""
        logger = logging.getLogger('MonitoringSystem')
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        
        return logger
    
    def _init_redis_client(self) -> Optional[Redis]:
        """åˆå§‹åŒ– Redis å®¢æˆ¶ç«¯"""
        if not self.config['redis']['enabled']:
            return None
        
        try:
            redis_config = self.config['redis']
            return Redis(
                host=redis_config['host'],
                port=redis_config['port'],
                db=redis_config['db'],
                decode_responses=True
            )
        except Exception as e:
            self.logger.warning(f"Redis é€£æ¥å¤±æ•—: {e}")
            return None
    
    def _init_system_metrics(self):
        """åˆå§‹åŒ–ç³»çµ±ç›£æ§æŒ‡æ¨™"""
        # CPU ä½¿ç”¨ç‡
        self.create_metric(
            name="system_cpu_usage_percent",
            metric_type=MetricType.GAUGE,
            help_text="System CPU usage percentage",
            labels={"node": os.uname().nodename}
        )
        
        # å…§å­˜ä½¿ç”¨ç‡
        self.create_metric(
            name="system_memory_usage_percent",
            metric_type=MetricType.GAUGE,
            help_text="System memory usage percentage",
            labels={"node": os.uname().nodename}
        )
        
        # ç£ç›¤ä½¿ç”¨ç‡
        self.create_metric(
            name="system_disk_usage_percent",
            metric_type=MetricType.GAUGE,
            help_text="System disk usage percentage",
            labels={"node": os.uname().nodename}
        )
        
        # ç¶²çµ¡ I/O
        self.create_metric(
            name="system_network_bytes_sent",
            metric_type=MetricType.COUNTER,
            help_text="System network bytes sent",
            labels={"node": os.uname().nodename}
        )
        
        self.create_metric(
            name="system_network_bytes_recv",
            metric_type=MetricType.COUNTER,
            help_text="System network bytes received",
            labels={"node": os.uname().nodename}
        )
        
        # æ‡‰ç”¨æŒ‡æ¨™
        self.create_metric(
            name="http_requests_total",
            metric_type=MetricType.COUNTER,
            help_text="Total HTTP requests",
            labels={"method", "status", "endpoint"}
        )
        
        self.create_metric(
            name="http_request_duration_seconds",
            metric_type=MetricType.HISTOGRAM,
            help_text="HTTP request duration in seconds",
            labels={"method", "endpoint"}
        )
        
        self.create_metric(
            name="application_errors_total",
            metric_type=MetricType.COUNTER,
            help_text="Total application errors",
            labels={"error_type", "component"}
        )
    
    def create_metric(
        self,
        name: str,
        metric_type: MetricType,
        help_text: str,
        labels: Dict[str, str] = None,
        buckets: List[float] = None
    ):
        """å‰µå»º Prometheus æŒ‡æ¨™"""
        
        if name in self.prometheus_metrics:
            self.logger.warning(f"æŒ‡æ¨™ '{name}' å·²å­˜åœ¨")
            return
        
        try:
            if metric_type == MetricType.COUNTER:
                metric = Counter(
                    name,
                    help_text,
                    list(labels.keys()) if labels else [],
                    registry=self.metrics_registry
                )
            elif metric_type == MetricType.GAUGE:
                metric = Gauge(
                    name,
                    help_text,
                    list(labels.keys()) if labels else [],
                    registry=self.metrics_registry
                )
            elif metric_type == MetricType.HISTOGRAM:
                default_buckets = [0.1, 0.5, 1.0, 2.5, 5.0, 10.0]
                metric = Histogram(
                    name,
                    help_text,
                    list(labels.keys()) if labels else [],
                    buckets=buckets or default_buckets,
                    registry=self.metrics_registry
                )
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æŒ‡æ¨™é¡å‹: {metric_type}")
            
            self.prometheus_metrics[name] = {
                'metric': metric,
                'type': metric_type,
                'help_text': help_text,
                'labels': labels or {}
            }
            
            self.logger.info(f"å·²å‰µå»ºæŒ‡æ¨™: {name}")
            
        except Exception as e:
            self.logger.error(f"å‰µå»ºæŒ‡æ¨™å¤±æ•— '{name}': {e}")
    
    def record_metric(self, name: str, value: float, labels: Dict[str, str] = None):
        """è¨˜éŒ„æŒ‡æ¨™æ•¸æ“š"""
        
        if name not in self.prometheus_metrics:
            self.logger.error(f"æŒ‡æ¨™ '{name}' ä¸å­˜åœ¨")
            return
        
        try:
            metric_info = self.prometheus_metrics[name]
            metric = metric_info['metric']
            metric_type = metric_info['type']
            
            # åˆä½µæ¨™ç±¤
            final_labels = {**(metric_info['labels'] or {}), **(labels or {})}
            
            if metric_type == MetricType.COUNTER:
                if final_labels:
                    metric.labels(**final_labels).inc(value)
                else:
                    metric.inc(value)
            elif metric_type == MetricType.GAUGE:
                if final_labels:
                    metric.labels(**final_labels).set(value)
                else:
                    metric.set(value)
            elif metric_type == MetricType.HISTOGRAM:
                if final_labels:
                    metric.labels(**final_labels).observe(value)
                else:
                    metric.observe(value)
            
            # ä¿å­˜åˆ°å…§å­˜æ•¸æ“š
            metric_data = MetricData(
                name=name,
                value=value,
                labels=final_labels,
                timestamp=datetime.now(),
                metric_type=metric_type,
                help_text=metric_info['help_text']
            )
            
            self.metric_data.append(metric_data)
            
            # ä¿å­˜åˆ° Redisï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if self.redis_client:
                self._save_metric_to_redis(metric_data)
            
            # æ¸…ç†èˆŠæ•¸æ“š
            self._cleanup_old_metrics()
            
        except Exception as e:
            self.logger.error(f"è¨˜éŒ„æŒ‡æ¨™å¤±æ•— '{name}': {e}")
    
    def _save_metric_to_redis(self, metric_data: MetricData):
        """ä¿å­˜æŒ‡æ¨™æ•¸æ“šåˆ° Redis"""
        try:
            key = f"metric:{metric_data.name}"
            data = {
                'value': metric_data.value,
                'labels': metric_data.labels,
                'timestamp': metric_data.timestamp.isoformat(),
                'type': metric_data.metric_type.value
            }
            
            self.redis_client.lpush(key, json.dumps(data))
            self.redis_client.expire(key, self.config['metrics']['retention_hours'] * 3600)
            
        except Exception as e:
            self.logger.error(f"ä¿å­˜æŒ‡æ¨™åˆ° Redis å¤±æ•—: {e}")
    
    def _cleanup_old_metrics(self):
        """æ¸…ç†èˆŠçš„æŒ‡æ¨™æ•¸æ“š"""
        retention_time = datetime.now() - timedelta(hours=self.config['metrics']['retention_hours'])
        
        # ä¿ç•™æœ€è¿‘çš„æ•¸æ“š
        max_items = self.config['metrics']['batch_size'] * 10
        
        # æŒ‰æ™‚é–“æ’åºä¸¦åˆªé™¤èˆŠæ•¸æ“š
        self.metric_data.sort(key=lambda x: x.timestamp, reverse=True)
        
        if len(self.metric_data) > max_items:
            self.metric_data = self.metric_data[:max_items]
        
        # åˆªé™¤éæœŸçš„æ•¸æ“š
        self.metric_data = [
            m for m in self.metric_data 
            if m.timestamp > retention_time
        ]
    
    def create_alert_rule(
        self,
        rule_id: str,
        name: str,
        description: str,
        metric_name: str,
        condition: str,
        threshold: float,
        severity: AlertSeverity,
        for_duration: int = 60,
        labels: Dict[str, str] = None,
        annotations: Dict[str, str] = None,
        evaluation_interval: int = 60
    ) -> AlertRule:
        """å‰µå»ºå‘Šè­¦è¦å‰‡"""
        
        rule = AlertRule(
            rule_id=rule_id,
            name=name,
            description=description,
            metric_name=metric_name,
            condition=condition,
            threshold=threshold,
            severity=severity,
            for_duration=for_duration,
            labels=labels or {},
            annotations=annotations or {},
            enabled=True,
            evaluation_interval=evaluation_interval
        )
        
        self.alert_rules[rule_id] = rule
        self.logger.info(f"å·²å‰µå»ºå‘Šè­¦è¦å‰‡: {rule_id}")
        
        return rule
    
    def create_notification_channel(
        self,
        channel_id: str,
        name: str,
        channel_type: str,
        config: Dict[str, Any],
        enabled: bool = True,
        rate_limit: int = 300
    ) -> NotificationChannel:
        """å‰µå»ºé€šçŸ¥æ¸ é“"""
        
        channel = NotificationChannel(
            channel_id=channel_id,
            name=name,
            type=channel_type,
            config=config,
            enabled=enabled,
            rate_limit=rate_limit
        )
        
        self.notification_channels[channel_id] = channel
        self.logger.info(f"å·²å‰µå»ºé€šçŸ¥æ¸ é“: {channel_id}")
        
        return channel
    
    async def evaluate_alert_rules(self):
        """è©•ä¼°å‘Šè­¦è¦å‰‡"""
        while True:
            try:
                for rule_id, rule in self.alert_rules.items():
                    if not rule.enabled:
                        continue
                    
                    await self._evaluate_alert_rule(rule)
                
                await asyncio.sleep(self.config['alerts']['evaluation_interval'])
                
            except Exception as e:
                self.logger.error(f"å‘Šè­¦è¦å‰‡è©•ä¼°å¤±æ•—: {e}")
                await asyncio.sleep(10)
    
    async def _evaluate_alert_rule(self, rule: AlertRule):
        """è©•ä¼°å–®å€‹å‘Šè­¦è¦å‰‡"""
        try:
            # ç²å–æœ€æ–°çš„æŒ‡æ¨™æ•¸æ“š
            current_value = self._get_latest_metric_value(rule.metric_name, rule.labels)
            
            if current_value is None:
                return
            
            # è©•ä¼°æ¢ä»¶
            is_triggered = self._evaluate_condition(current_value, rule.condition, rule.threshold)
            
            # æª¢æŸ¥æ˜¯å¦å·²ç¶“å­˜åœ¨å‘Šè­¦
            existing_alert = self.active_alerts.get(rule_id)
            
            if is_triggered:
                if not existing_alert:
                    # å‰µå»ºæ–°å‘Šè­¦
                    await self._create_alert(rule, current_value)
                else:
                    # æ›´æ–°ç¾æœ‰å‘Šè­¦
                    await self._update_alert(existing_alert, current_value)
            else:
                if existing_alert and existing_alert.status == AlertStatus.ACTIVE:
                    # è§£æ±ºå‘Šè­¦
                    await self._resolve_alert(existing_alert)
                
        except Exception as e:
            self.logger.error(f"è©•ä¼°å‘Šè­¦è¦å‰‡å¤±æ•— '{rule.rule_id}': {e}")
    
    def _get_latest_metric_value(self, metric_name: str, labels: Dict[str, str] = None) -> Optional[float]:
        """ç²å–æœ€æ–°çš„æŒ‡æ¨™æ•¸æ“š"""
        
        # å¾å…§å­˜æ•¸æ“šä¸­æŸ¥æ‰¾
        for metric_data in reversed(self.metric_data):
            if metric_data.name == metric_name:
                # æª¢æŸ¥æ¨™ç±¤æ˜¯å¦åŒ¹é…
                if not labels or all(metric_data.labels.get(k) == v for k, v in labels.items()):
                    return metric_data.value
        
        # å¾ Redis ä¸­æŸ¥æ‰¾
        if self.redis_client:
            try:
                key = f"metric:{metric_name}"
                data = self.redis_client.lindex(key, 0)  # ç²å–æœ€æ–°æ•¸æ“š
                
                if data:
                    metric_info = json.loads(data)
                    if not labels or all(metric_info['labels'].get(k) == v for k, v in labels.items()):
                        return metric_info['value']
                        
            except Exception as e:
                self.logger.error(f"å¾ Redis ç²å–æŒ‡æ¨™å¤±æ•—: {e}")
        
        return None
    
    def _evaluate_condition(self, value: float, condition: str, threshold: float) -> bool:
        """è©•ä¼°æ¢ä»¶"""
        try:
            if condition == ">":
                return value > threshold
            elif condition == ">=":
                return value >= threshold
            elif condition == "<":
                return value < threshold
            elif condition == "<=":
                return value <= threshold
            elif condition == "==":
                return value == threshold
            elif condition == "!=":
                return value != threshold
            else:
                self.logger.warning(f"ä¸æ”¯æŒçš„æ¢ä»¶: {condition}")
                return False
                
        except Exception as e:
            self.logger.error(f"æ¢ä»¶è©•ä¼°å¤±æ•—: {e}")
            return False
    
    async def _create_alert(self, rule: AlertRule, current_value: float):
        """å‰µå»ºå‘Šè­¦"""
        
        alert_id = f"alert_{rule.rule_id}_{int(time.time())}"
        
        message = f"å‘Šè­¦ '{rule.name}' è§¸ç™¼ - {rule.metric_name} = {current_value} {rule.condition} {rule.threshold}"
        
        alert = Alert(
            alert_id=alert_id,
            rule_id=rule.rule_id,
            status=AlertStatus.ACTIVE,
            severity=rule.severity,
            start_time=datetime.now(),
            end_time=None,
            message=message,
            labels=rule.labels.copy(),
            annotations=rule.annotations.copy(),
            evaluation_count=1,
            last_evaluated=datetime.now()
        )
        
        self.active_alerts[rule.rule_id] = alert
        
        self.logger.warning(f"å‘Šè­¦å·²è§¸ç™¼: {message}")
        
        # ç™¼é€é€šçŸ¥
        await self._send_alert_notification(alert, rule)
    
    async def _update_alert(self, alert: Alert, current_value: float):
        """æ›´æ–°å‘Šè­¦"""
        alert.evaluation_count += 1
        alert.last_evaluated = datetime.now()
        
        # æª¢æŸ¥æ˜¯å¦æŒçºŒæ™‚é–“è¶³å¤ 
        duration = (datetime.now() - alert.start_time).total_seconds()
        rule = self.alert_rules[alert.rule_id]
        
        if duration >= rule.for_duration:
            # ç™¼é€æŒçºŒå‘Šè­¦é€šçŸ¥
            await self._send_alert_notification(alert, rule)
    
    async def _resolve_alert(self, alert: Alert):
        """è§£æ±ºå‘Šè­¦"""
        alert.status = AlertStatus.RESOLVED
        alert.end_time = datetime.now()
        
        self.logger.info(f"å‘Šè­¦å·²è§£æ±º: {alert.alert_id}")
        
        # ç™¼é€è§£æ±ºé€šçŸ¥
        rule = self.alert_rules[alert.rule_id]
        await self._send_alert_notification(alert, rule)
    
    async def _send_alert_notification(self, alert: Alert, rule: AlertRule):
        """ç™¼é€å‘Šè­¦é€šçŸ¥"""
        
        for channel_id, channel in self.notification_channels.items():
            if not channel.enabled:
                continue
            
            try:
                await self._send_notification_to_channel(alert, rule, channel)
                
            except Exception as e:
                self.logger.error(f"ç™¼é€é€šçŸ¥å¤±æ•— '{channel_id}': {e}")
    
    async def _send_notification_to_channel(self, alert: Alert, rule: AlertRule, channel: NotificationChannel):
        """ç™¼é€é€šçŸ¥åˆ°æŒ‡å®šæ¸ é“"""
        
        if channel.type == 'slack':
            await self._send_slack_notification(alert, rule, channel)
        elif channel.type == 'webhook':
            await self._send_webhook_notification(alert, rule, channel)
        elif channel.type == 'email':
            await self._send_email_notification(alert, rule, channel)
        elif channel.type == 'teams':
            await self._send_teams_notification(alert, rule, channel)
        else:
            self.logger.warning(f"ä¸æ”¯æŒçš„é€šçŸ¥æ¸ é“é¡å‹: {channel.type}")
    
    async def _send_slack_notification(self, alert: Alert, rule: AlertRule, channel: NotificationChannel):
        """ç™¼é€ Slack é€šçŸ¥"""
        
        webhook_url = channel.config.get('webhook_url')
        if not webhook_url:
            return
        
        # ç¢ºå®šé¡è‰²
        colors = {
            AlertSeverity.INFO: "#36a64f",
            AlertSeverity.WARNING: "#ff9500",
            AlertSeverity.CRITICAL: "#ff0000",
            AlertSeverity.EMERGENCY: "#8b0000"
        }
        
        color = colors.get(alert.severity, "#36a64f")
        
        # æ§‹å»ºæ¶ˆæ¯
        status_emoji = "ğŸ”´" if alert.status == AlertStatus.ACTIVE else "âœ…"
        
        payload = {
            "text": f"{status_emoji} {alert.message}",
            "attachments": [{
                "color": color,
                "fields": [
                    {"title": "å‘Šè­¦åç¨±", "value": rule.name, "short": True},
                    {"title": "åš´é‡ç¨‹åº¦", "value": alert.severity.value.upper(), "short": True},
                    {"title": "é–‹å§‹æ™‚é–“", "value": alert.start_time.strftime('%Y-%m-%d %H:%M:%S'), "short": True},
                    {"title": "è©•ä¼°æ¬¡æ•¸", "value": str(alert.evaluation_count), "short": True}
                ],
                "footer": "ç›£æ§ç³»çµ±",
                "ts": int(alert.start_time.timestamp())
            }]
        }
        
        async with aiohttp.ClientSession() as session:
            async with session.post(webhook_url, json=payload) as response:
                if response.status != 200:
                    self.logger.error(f"Slack é€šçŸ¥ç™¼é€å¤±æ•—: {response.status}")
    
    async def _send_webhook_notification(self, alert: Alert, rule: AlertRule, channel: NotificationChannel):
        """ç™¼é€ Webhook é€šçŸ¥"""
        
        webhook_url = channel.config.get('url')
        if not webhook_url:
            return
        
        payload = {
            "alert_id": alert.alert_id,
            "rule_id": rule.rule_id,
            "status": alert.status.value,
            "severity": alert.severity.value,
            "message": alert.message,
            "start_time": alert.start_time.isoformat(),
            "end_time": alert.end_time.isoformat() if alert.end_time else None,
            "labels": alert.labels,
            "annotations": alert.annotations
        }
        
        headers = channel.config.get('headers', {})
        
        async with aiohttp.ClientSession() as session:
            async with session.post(webhook_url, json=payload, headers=headers) as response:
                if response.status not in [200, 201, 204]:
                    self.logger.error(f"Webhook é€šçŸ¥ç™¼é€å¤±æ•—: {response.status}")
    
    async def _send_email_notification(self, alert: Alert, rule: AlertRule, channel: NotificationChannel):
        """ç™¼é€éƒµä»¶é€šçŸ¥"""
        # é€™è£¡éœ€è¦å¯¦ç¾éƒµä»¶ç™¼é€é‚è¼¯
        # ç°¡åŒ–å¯¦ç¾ï¼Œå¯¦éš›æ‡‰è©²ä½¿ç”¨ SMTP æˆ–éƒµä»¶æœå‹™
        self.logger.info(f"ç™¼é€éƒµä»¶é€šçŸ¥: {alert.message}")
    
    async def _send_teams_notification(self, alert: Alert, rule: AlertRule, channel: NotificationChannel):
        """ç™¼é€ Teams é€šçŸ¥"""
        
        webhook_url = channel.config.get('webhook_url')
        if not webhook_url:
            return
        
        # ç¢ºå®šé¡è‰²
        colors = {
            AlertSeverity.INFO: "00FF00",
            AlertSeverity.WARNING: "FFFF00",
            AlertSeverity.CRITICAL: "FF0000",
            AlertSeverity.EMERGENCY: "8B0000"
        }
        
        color = colors.get(alert.severity, "00FF00")
        
        payload = {
            "@type": "MessageCard",
            "@context": "http://schema.org/extensions",
            "themeColor": color,
            "summary": alert.message,
            "sections": [{
                "activityTitle": alert.message,
                "activitySubtitle": rule.description,
                "facts": [
                    {"name": "å‘Šè­¦åç¨±", "value": rule.name},
                    {"name": "åš´é‡ç¨‹åº¦", "value": alert.severity.value.upper()},
                    {"name": "ç‹€æ…‹", "value": alert.status.value},
                    {"name": "é–‹å§‹æ™‚é–“", "value": alert.start_time.strftime('%Y-%m-%d %H:%M:%S')}
                ],
                "markdown": True
            }]
        }
        
        async with aiohttp.ClientSession() as session:
            async with session.post(webhook_url, json=payload) as response:
                if response.status != 200:
                    self.logger.error(f"Teams é€šçŸ¥ç™¼é€å¤±æ•—: {response.status}")
    
    def collect_system_metrics(self):
        """æ”¶é›†ç³»çµ±æŒ‡æ¨™"""
        while True:
            try:
                # CPU ä½¿ç”¨ç‡
                cpu_percent = psutil.cpu_percent(interval=1)
                self.record_metric("system_cpu_usage_percent", cpu_percent)
                
                # å…§å­˜ä½¿ç”¨ç‡
                memory = psutil.virtual_memory()
                self.record_metric("system_memory_usage_percent", memory.percent)
                
                # ç£ç›¤ä½¿ç”¨ç‡
                disk = psutil.disk_usage('/')
                disk_percent = (disk.used / disk.total) * 100
                self.record_metric("system_disk_usage_percent", disk_percent)
                
                # ç¶²çµ¡ I/O
                net_io = psutil.net_io_counters()
                self.record_metric("system_network_bytes_sent", net_io.bytes_sent)
                self.record_metric("system_network_bytes_recv", net_io.bytes_recv)
                
                time.sleep(self.config['metrics']['collection_interval'])
                
            except Exception as e:
                self.logger.error(f"æ”¶é›†ç³»çµ±æŒ‡æ¨™å¤±æ•—: {e}")
                time.sleep(10)
    
    def start_prometheus_server(self):
        """å•Ÿå‹• Prometheus æŒ‡æ¨™æœå‹™å™¨"""
        
        if not self.config['prometheus']['enabled']:
            return
        
        from prometheus_client import start_http_server
        
        port = self.config['prometheus']['port']
        start_http_server(port, registry=self.metrics_registry)
        
        self.logger.info(f"Prometheus æŒ‡æ¨™æœå‹™å™¨å·²å•Ÿå‹•: http://localhost:{port}{self.config['prometheus']['endpoint']}")
    
    def get_metrics_data(self, metric_name: str = None, start_time: datetime = None, end_time: datetime = None) -> List[MetricData]:
        """ç²å–æŒ‡æ¨™æ•¸æ“š"""
        
        data = self.metric_data
        
        # éæ¿¾æŒ‡æ¨™åç¨±
        if metric_name:
            data = [m for m in data if m.name == metric_name]
        
        # éæ¿¾æ™‚é–“ç¯„åœ
        if start_time:
            data = [m for m in data if m.timestamp >= start_time]
        
        if end_time:
            data = [m for m in data if m.timestamp <= end_time]
        
        return data
    
    def get_active_alerts(self) -> List[Alert]:
        """ç²å–æ´»èºå‘Šè­¦"""
        return [alert for alert in self.active_alerts.values() if alert.status == AlertStatus.ACTIVE]
    
    def get_alert_history(self, limit: int = 100) -> List[Alert]:
        """ç²å–å‘Šè­¦æ­·å²"""
        history = list(self.active_alerts.values())
        history.sort(key=lambda x: x.start_time, reverse=True)
        return history[:limit]
    
    def start_monitoring(self):
        """å•Ÿå‹•ç›£æ§ç³»çµ±"""
        self.logger.info("å•Ÿå‹•ç›£æ§ç³»çµ±...")
        
        # å•Ÿå‹• Prometheus æœå‹™å™¨
        self.start_prometheus_server()
        
        # å•Ÿå‹•ç³»çµ±æŒ‡æ¨™æ”¶é›†
        system_metrics_thread = threading.Thread(target=self.collect_system_metrics, daemon=True)
        system_metrics_thread.start()
        
        # å•Ÿå‹•å‘Šè­¦è©•ä¼°ä»»å‹™
        if self.alert_evaluation_task is None:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            self.alert_evaluation_task = loop.create_task(self.evaluate_alert_rules())
            threading.Thread(target=lambda: loop.run_forever(), daemon=True).start()
        
        self.logger.info("ç›£æ§ç³»çµ±å·²å•Ÿå‹•")
    
    def stop_monitoring(self):
        """åœæ­¢ç›£æ§ç³»çµ±"""
        self.logger.info("åœæ­¢ç›£æ§ç³»çµ±...")
        
        if self.alert_evaluation_task:
            self.alert_evaluation_task.cancel()
        
        self.logger.info("ç›£æ§ç³»çµ±å·²åœæ­¢")


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    import asyncio
    
    async def main():
        # åˆå§‹åŒ–ç›£æ§ç³»çµ±
        monitoring = MonitoringSystem()
        
        # å‰µå»ºå‘Šè­¦è¦å‰‡
        monitoring.create_alert_rule(
            rule_id="high_cpu",
            name="é«˜ CPU ä½¿ç”¨ç‡",
            description="CPU ä½¿ç”¨ç‡è¶…é 80%",
            metric_name="system_cpu_usage_percent",
            condition=">",
            threshold=80.0,
            severity=AlertSeverity.WARNING,
            for_duration=60
        )
        
        # å‰µå»ºé€šçŸ¥æ¸ é“
        monitoring.create_notification_channel(
            channel_id="slack_alerts",
            name="Slack å‘Šè­¦",
            channel_type="slack",
            config={
                "webhook_url": os.getenv("SLACK_WEBHOOK_URL")
            }
        )
        
        # å•Ÿå‹•ç›£æ§
        monitoring.start_monitoring()
        
        # æ¨¡æ“¬ä¸€äº›æŒ‡æ¨™æ•¸æ“š
        for i in range(100):
            monitoring.record_metric(
                "http_requests_total",
                i,
                {"method": "GET", "status": "200", "endpoint": "/api/users"}
            )
            await asyncio.sleep(1)
    
    asyncio.run(main())