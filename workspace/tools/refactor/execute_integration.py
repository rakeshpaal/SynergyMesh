#!/usr/bin/env python3
"""
Integration Executor - é›†æˆåŸ·è¡Œå¼•æ“

åŸ·è¡Œè³‡ç”¢æ•´åˆæ“ä½œï¼ŒåŒ…æ‹¬ï¼š
1. ç›®éŒ„å„ªåŒ–
2. æª”æ¡ˆç§»å‹•/åˆä½µ
3. å¼•ç”¨æ›´æ–°
4. æ‰¹é‡è™•ç†
5. é©—è­‰ç¢ºèª

Usage:
    python execute_integration.py single --decision <file>
    python execute_integration.py batch --decisions <dir>
    python execute_integration.py reorganize --target <dir>

Version: 1.0.0
"""

import argparse
import yaml
import json
import os
import re
import shutil
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Tuple, Any, Set
from dataclasses import dataclass, field, asdict
from enum import Enum

# ============================================================================
# å¸¸æ•¸èˆ‡é…ç½®
# ============================================================================

BASE_PATH = Path(__file__).parent.parent.parent
PLAYBOOKS_PATH = BASE_PATH / "docs" / "refactor_playbooks"
CONFIG_PATH = PLAYBOOKS_PATH / "config" / "integration-processor.yaml"
BACKUP_PATH = PLAYBOOKS_PATH / ".integration_backup"

# ============================================================================
# æšèˆ‰å®šç¾©
# ============================================================================

class OperationType(Enum):
    """æ“ä½œé¡å‹"""
    CREATE_DIR = "create_directory"
    MOVE_FILE = "move_file"
    COPY_FILE = "copy_file"
    MERGE_FILE = "merge_file"
    DELETE_FILE = "delete_file"
    UPDATE_REFS = "update_references"
    EMBED_CONTENT = "embed_content"
    UPDATE_INDEX = "update_index"

class ExecutionMode(Enum):
    """åŸ·è¡Œæ¨¡å¼"""
    DRY_RUN = "dry_run"
    CONFIRM = "confirm"
    FORCE = "force"

# ============================================================================
# è³‡æ–™çµæ§‹
# ============================================================================

@dataclass
class Operation:
    """æ“ä½œå®šç¾©"""
    op_id: str
    op_type: OperationType
    source: Optional[str]
    target: str
    options: Dict = field(default_factory=dict)
    depends_on: List[str] = field(default_factory=list)

@dataclass
class OperationResult:
    """æ“ä½œçµæœ"""
    op_id: str
    success: bool
    message: str
    changes: List[str] = field(default_factory=list)
    rollback_info: Optional[Dict] = None

@dataclass
class DirectoryOptimization:
    """ç›®éŒ„å„ªåŒ–æ–¹æ¡ˆ"""
    target_dir: str
    current_structure: Dict
    optimized_structure: Dict
    operations: List[Operation]
    improvement_score: float

@dataclass
class IntegrationPlan:
    """æ•´åˆè¨ˆç•«"""
    plan_id: str
    created_at: str
    target_directory: str
    operations: List[Operation]
    estimated_changes: int
    risk_level: str

# ============================================================================
# ç›®éŒ„å„ªåŒ–å™¨
# ============================================================================

class DirectoryOptimizer:
    """
    ç›®éŒ„å„ªåŒ–å™¨ï¼šåˆ†æä¸¦å„ªåŒ–ç›®éŒ„çµæ§‹
    """

    def __init__(self, config: Optional[Dict] = None):
        self.config = config or {}

        # å„ªåŒ–è¦å‰‡
        self.max_root_files = 10
        self.max_depth = 4
        self.naming_convention = "snake_case"

        # æ¨™æº–å­ç›®éŒ„
        self.standard_subdirs = {
            "reports": ["*_report.md", "*_analysis.md"],
            "generated": ["*__playbook.md", "*_generated.*"],
            "templates": ["*_template.*", "TEMPLATE_*"],
            "meta": ["*.meta.yaml", "META_*"],
        }

    def analyze(self, target_dir: Path) -> DirectoryOptimization:
        """åˆ†æä¸¦ç”Ÿæˆå„ªåŒ–æ–¹æ¡ˆ"""
        current = self._scan_structure(target_dir)
        optimized = self._generate_optimized_structure(current, target_dir)
        operations = self._generate_operations(current, optimized, target_dir)
        score = self._calculate_improvement(current, optimized)

        return DirectoryOptimization(
            target_dir=str(target_dir),
            current_structure=current,
            optimized_structure=optimized,
            operations=operations,
            improvement_score=score,
        )

    def _scan_structure(self, target_dir: Path) -> Dict:
        """æƒæç•¶å‰çµæ§‹"""
        structure = {
            "root_files": [],
            "subdirs": {},
            "total_files": 0,
            "max_depth": 0,
            "naming_issues": [],
        }

        if not target_dir.exists():
            return structure

        for item in target_dir.iterdir():
            if item.is_file():
                structure["root_files"].append(item.name)
                structure["total_files"] += 1

                # æª¢æŸ¥å‘½å
                if not self._check_naming(item.name):
                    structure["naming_issues"].append(item.name)

            elif item.is_dir() and not item.name.startswith('.'):
                subdir_files = list(item.rglob("*"))
                structure["subdirs"][item.name] = {
                    "files": [f.name for f in subdir_files if f.is_file()],
                    "count": len([f for f in subdir_files if f.is_file()]),
                }
                structure["total_files"] += structure["subdirs"][item.name]["count"]

        return structure

    def _generate_optimized_structure(self, current: Dict, target_dir: Path) -> Dict:
        """ç”Ÿæˆå„ªåŒ–å¾Œçš„çµæ§‹"""
        optimized = {
            "root_files": [],
            "subdirs": dict(current.get("subdirs", {})),
            "new_subdirs": {},
        }

        # åˆ†é¡æ ¹ç›®éŒ„æª”æ¡ˆ
        for filename in current.get("root_files", []):
            placed = False

            for subdir, patterns in self.standard_subdirs.items():
                for pattern in patterns:
                    if self._match_pattern(filename, pattern):
                        if subdir not in optimized["new_subdirs"]:
                            optimized["new_subdirs"][subdir] = []
                        optimized["new_subdirs"][subdir].append(filename)
                        placed = True
                        break
                if placed:
                    break

            if not placed:
                # ä¿ç•™åœ¨æ ¹ç›®éŒ„
                optimized["root_files"].append(filename)

        return optimized

    def _generate_operations(self, current: Dict, optimized: Dict,
                            target_dir: Path) -> List[Operation]:
        """ç”Ÿæˆæ“ä½œåˆ—è¡¨"""
        operations = []
        op_counter = 0

        # å»ºç«‹æ–°å­ç›®éŒ„
        for subdir, files in optimized.get("new_subdirs", {}).items():
            op_counter += 1
            operations.append(Operation(
                op_id=f"op_{op_counter:03d}",
                op_type=OperationType.CREATE_DIR,
                source=None,
                target=str(target_dir / subdir),
            ))

            # ç§»å‹•æª”æ¡ˆåˆ°æ–°å­ç›®éŒ„
            for filename in files:
                op_counter += 1
                operations.append(Operation(
                    op_id=f"op_{op_counter:03d}",
                    op_type=OperationType.MOVE_FILE,
                    source=str(target_dir / filename),
                    target=str(target_dir / subdir / filename),
                    depends_on=[f"op_{op_counter-len(files):03d}"],
                ))

        # ä¿®å¾©å‘½åå•é¡Œ
        for filename in current.get("naming_issues", []):
            new_name = self._fix_naming(filename)
            if new_name != filename:
                op_counter += 1
                operations.append(Operation(
                    op_id=f"op_{op_counter:03d}",
                    op_type=OperationType.MOVE_FILE,
                    source=str(target_dir / filename),
                    target=str(target_dir / new_name),
                    options={"rename": True},
                ))

        return operations

    def _calculate_improvement(self, current: Dict, optimized: Dict) -> float:
        """è¨ˆç®—æ”¹é€²åˆ†æ•¸"""
        score = 0.0

        # æ ¹ç›®éŒ„æª”æ¡ˆæ¸›å°‘
        current_root = len(current.get("root_files", []))
        optimized_root = len(optimized.get("root_files", []))
        if current_root > 0:
            reduction = (current_root - optimized_root) / current_root
            score += reduction * 0.4

        # å‘½åå•é¡Œä¿®å¾©
        naming_issues = len(current.get("naming_issues", []))
        if naming_issues > 0:
            score += 0.2

        # çµæ§‹æ”¹é€²
        if optimized.get("new_subdirs"):
            score += 0.3

        return min(score, 1.0)

    def _check_naming(self, filename: str) -> bool:
        """æª¢æŸ¥å‘½åæ˜¯å¦ç¬¦åˆè¦ç¯„"""
        name = Path(filename).stem

        if self.naming_convention == "snake_case":
            # ä¸æ‡‰åŒ…å«å¤§å¯«æˆ–é€£å­—ç¬¦
            return not bool(re.search(r'[A-Z]|-', name))

        return True

    def _fix_naming(self, filename: str) -> str:
        """ä¿®å¾©å‘½å"""
        path = Path(filename)
        name = path.stem
        ext = path.suffix

        # è½‰æ›ç‚º snake_case
        # è™•ç† camelCase
        name = re.sub(r'([A-Z]+)([A-Z][a-z])', r'\1_\2', name)
        name = re.sub(r'([a-z\d])([A-Z])', r'\1_\2', name)
        # è™•ç†é€£å­—ç¬¦
        name = name.replace('-', '_')
        # è™•ç†å¤šå€‹ä¸‹åŠƒç·š
        name = re.sub(r'_+', '_', name)
        name = name.lower()

        return name + ext

    def _match_pattern(self, filename: str, pattern: str) -> bool:
        """åŒ¹é…æª”æ¡ˆæ¨¡å¼"""
        import fnmatch
        return fnmatch.fnmatch(filename, pattern)

# ============================================================================
# ç›®éŒ„åœ–è­œç”Ÿæˆå™¨
# ============================================================================

class DirectoryMapper:
    """
    ç›®éŒ„åœ–è­œç”Ÿæˆå™¨ï¼šç”Ÿæˆç›®éŒ„çµæ§‹åœ–
    """

    def generate_ascii_tree(self, target_dir: Path, max_depth: int = 3) -> str:
        """ç”Ÿæˆ ASCII ç›®éŒ„æ¨¹"""
        lines = [f"{target_dir.name}/"]
        self._build_tree(target_dir, lines, "", max_depth, 0)
        return "\n".join(lines)

    def _build_tree(self, path: Path, lines: List[str], prefix: str,
                    max_depth: int, current_depth: int):
        """éè¿´å»ºç«‹æ¨¹çµæ§‹"""
        if current_depth >= max_depth:
            return

        try:
            items = sorted(path.iterdir(), key=lambda x: (x.is_file(), x.name))
        except PermissionError:
            return

        # éæ¿¾éš±è—æª”æ¡ˆ
        items = [i for i in items if not i.name.startswith('.')]

        for i, item in enumerate(items):
            is_last = i == len(items) - 1
            connector = "â””â”€â”€ " if is_last else "â”œâ”€â”€ "
            new_prefix = prefix + ("    " if is_last else "â”‚   ")

            if item.is_dir():
                lines.append(f"{prefix}{connector}{item.name}/")
                self._build_tree(item, lines, new_prefix, max_depth, current_depth + 1)
            else:
                lines.append(f"{prefix}{connector}{item.name}")

    def generate_mermaid_diagram(self, target_dir: Path) -> str:
        """ç”Ÿæˆ Mermaid æµç¨‹åœ–"""
        lines = ["```mermaid", "graph TD"]

        def add_node(path: Path, parent_id: Optional[str] = None):
            node_id = path.name.replace('.', '_').replace('-', '_')
            if parent_id:
                lines.append(f"    {parent_id} --> {node_id}[{path.name}]")
            else:
                lines.append(f"    {node_id}[{path.name}]")

            if path.is_dir():
                for child in sorted(path.iterdir()):
                    if not child.name.startswith('.'):
                        add_node(child, node_id)

        add_node(target_dir)
        lines.append("```")
        return "\n".join(lines)

# ============================================================================
# æ•´åˆåŸ·è¡Œå™¨
# ============================================================================

class IntegrationExecutor:
    """
    æ•´åˆåŸ·è¡Œå™¨ï¼šåŸ·è¡Œæ•´åˆæ“ä½œ
    """

    def __init__(self, mode: ExecutionMode = ExecutionMode.DRY_RUN):
        self.mode = mode
        self.backup_dir = BACKUP_PATH / datetime.now().strftime("%Y%m%d_%H%M%S")
        self.executed_ops: List[OperationResult] = []
        self.reference_updates: List[Tuple[Path, str, str]] = []

    def execute_plan(self, plan: IntegrationPlan) -> List[OperationResult]:
        """åŸ·è¡Œæ•´åˆè¨ˆç•«"""
        print(f"\n{'ğŸ” æ¨¡æ“¬åŸ·è¡Œ' if self.mode == ExecutionMode.DRY_RUN else 'ğŸš€ åŸ·è¡Œ'} è¨ˆç•«: {plan.plan_id}")
        print(f"   ç›®æ¨™: {plan.target_directory}")
        print(f"   æ“ä½œæ•¸: {len(plan.operations)}")

        if self.mode != ExecutionMode.DRY_RUN:
            self._create_backup(plan)

        results = []
        for op in plan.operations:
            # æª¢æŸ¥ä¾è³´
            if not self._check_dependencies(op, results):
                results.append(OperationResult(
                    op_id=op.op_id,
                    success=False,
                    message="ä¾è³´æ“ä½œå¤±æ•—",
                ))
                continue

            result = self._execute_operation(op)
            results.append(result)
            self.executed_ops.append(result)

            if not result.success and self.mode != ExecutionMode.FORCE:
                print(f"   âŒ {op.op_id} å¤±æ•—ï¼Œåœæ­¢åŸ·è¡Œ")
                break

        # æ›´æ–°å¼•ç”¨
        if self.mode != ExecutionMode.DRY_RUN:
            self._update_all_references()

        return results

    def execute_single(self, decision_file: Path) -> OperationResult:
        """åŸ·è¡Œå–®ä¸€æ±ºç­–"""
        with open(decision_file, 'r', encoding='utf-8') as f:
            decision = yaml.safe_load(f)

        # å¾æ±ºç­–ç”Ÿæˆæ“ä½œ
        op = self._decision_to_operation(decision)

        return self._execute_operation(op)

    def _execute_operation(self, op: Operation) -> OperationResult:
        """åŸ·è¡Œå–®ä¸€æ“ä½œ"""
        print(f"   [{op.op_id}] {op.op_type.value}: ", end="")

        if self.mode == ExecutionMode.DRY_RUN:
            print(f"(æ¨¡æ“¬) {op.target}")
            return OperationResult(
                op_id=op.op_id,
                success=True,
                message="æ¨¡æ“¬æˆåŠŸ",
                changes=[f"Would {op.op_type.value}: {op.target}"],
            )

        try:
            if op.op_type == OperationType.CREATE_DIR:
                result = self._op_create_dir(op)
            elif op.op_type == OperationType.MOVE_FILE:
                result = self._op_move_file(op)
            elif op.op_type == OperationType.COPY_FILE:
                result = self._op_copy_file(op)
            elif op.op_type == OperationType.MERGE_FILE:
                result = self._op_merge_file(op)
            elif op.op_type == OperationType.DELETE_FILE:
                result = self._op_delete_file(op)
            elif op.op_type == OperationType.EMBED_CONTENT:
                result = self._op_embed_content(op)
            elif op.op_type == OperationType.UPDATE_INDEX:
                result = self._op_update_index(op)
            else:
                result = OperationResult(
                    op_id=op.op_id,
                    success=False,
                    message=f"æœªçŸ¥æ“ä½œé¡å‹: {op.op_type}",
                )

            status = "âœ“" if result.success else "âœ—"
            print(f"{status} {result.message}")
            return result

        except Exception as e:
            print(f"âœ— éŒ¯èª¤: {e}")
            return OperationResult(
                op_id=op.op_id,
                success=False,
                message=str(e),
            )

    def _op_create_dir(self, op: Operation) -> OperationResult:
        """å»ºç«‹ç›®éŒ„"""
        target = Path(op.target)
        target.mkdir(parents=True, exist_ok=True)

        return OperationResult(
            op_id=op.op_id,
            success=True,
            message=f"å·²å»ºç«‹: {target.name}",
            changes=[f"Created directory: {op.target}"],
        )

    def _op_move_file(self, op: Operation) -> OperationResult:
        """ç§»å‹•æª”æ¡ˆ"""
        source = Path(op.source)
        target = Path(op.target)

        if not source.exists():
            return OperationResult(
                op_id=op.op_id,
                success=False,
                message=f"ä¾†æºä¸å­˜åœ¨: {source}",
            )

        target.parent.mkdir(parents=True, exist_ok=True)

        # è¨˜éŒ„å¼•ç”¨æ›´æ–°
        self.reference_updates.append((source, str(source), str(target)))

        shutil.move(str(source), str(target))

        return OperationResult(
            op_id=op.op_id,
            success=True,
            message=f"å·²ç§»å‹•: {source.name} -> {target.parent.name}/",
            changes=[f"Moved: {op.source} -> {op.target}"],
            rollback_info={"source": str(target), "target": str(source)},
        )

    def _op_copy_file(self, op: Operation) -> OperationResult:
        """è¤‡è£½æª”æ¡ˆ"""
        source = Path(op.source)
        target = Path(op.target)

        if not source.exists():
            return OperationResult(
                op_id=op.op_id,
                success=False,
                message=f"ä¾†æºä¸å­˜åœ¨: {source}",
            )

        target.parent.mkdir(parents=True, exist_ok=True)
        shutil.copy2(str(source), str(target))

        return OperationResult(
            op_id=op.op_id,
            success=True,
            message=f"å·²è¤‡è£½: {source.name}",
            changes=[f"Copied: {op.source} -> {op.target}"],
            rollback_info={"delete": str(target)},
        )

    def _op_merge_file(self, op: Operation) -> OperationResult:
        """åˆä½µæª”æ¡ˆ"""
        source = Path(op.source)
        target = Path(op.target)

        if not source.exists():
            return OperationResult(
                op_id=op.op_id,
                success=False,
                message=f"ä¾†æºä¸å­˜åœ¨: {source}",
            )

        # è®€å–ä¾†æºå…§å®¹
        source_content = source.read_text(encoding='utf-8')

        # è®€å–æˆ–å»ºç«‹ç›®æ¨™
        if target.exists():
            target_content = target.read_text(encoding='utf-8')
            merged_content = target_content + "\n\n---\n\n" + source_content
        else:
            merged_content = source_content

        # å¯«å…¥åˆä½µå…§å®¹
        target.parent.mkdir(parents=True, exist_ok=True)
        target.write_text(merged_content, encoding='utf-8')

        return OperationResult(
            op_id=op.op_id,
            success=True,
            message=f"å·²åˆä½µ: {source.name} -> {target.name}",
            changes=[f"Merged: {op.source} into {op.target}"],
        )

    def _op_delete_file(self, op: Operation) -> OperationResult:
        """åˆªé™¤æª”æ¡ˆ"""
        target = Path(op.target)

        if not target.exists():
            return OperationResult(
                op_id=op.op_id,
                success=True,
                message="æª”æ¡ˆå·²ä¸å­˜åœ¨",
            )

        # å‚™ä»½åˆ°å›æ»¾ç›®éŒ„
        backup_path = self.backup_dir / target.name
        backup_path.parent.mkdir(parents=True, exist_ok=True)
        shutil.copy2(str(target), str(backup_path))

        target.unlink()

        return OperationResult(
            op_id=op.op_id,
            success=True,
            message=f"å·²åˆªé™¤: {target.name}",
            changes=[f"Deleted: {op.target}"],
            rollback_info={"restore_from": str(backup_path), "restore_to": str(target)},
        )

    def _op_embed_content(self, op: Operation) -> OperationResult:
        """åµŒå…¥å…§å®¹"""
        source = Path(op.source)
        target = Path(op.target)
        section = op.options.get("section", "## Embedded Content")

        if not source.exists() or not target.exists():
            return OperationResult(
                op_id=op.op_id,
                success=False,
                message="ä¾†æºæˆ–ç›®æ¨™ä¸å­˜åœ¨",
            )

        source_content = source.read_text(encoding='utf-8')
        target_content = target.read_text(encoding='utf-8')

        # åµŒå…¥åˆ°æŒ‡å®šæ®µè½
        embed_marker = f"\n\n{section}\n\n"
        if embed_marker in target_content:
            # åœ¨ç¾æœ‰æ®µè½å¾Œæ·»åŠ 
            parts = target_content.split(embed_marker)
            new_content = parts[0] + embed_marker + source_content + "\n\n" + "".join(parts[1:])
        else:
            # æ·»åŠ æ–°æ®µè½
            new_content = target_content + embed_marker + source_content

        target.write_text(new_content, encoding='utf-8')

        return OperationResult(
            op_id=op.op_id,
            success=True,
            message=f"å·²åµŒå…¥: {source.name} -> {target.name}",
            changes=[f"Embedded: {op.source} into {op.target} at '{section}'"],
        )

    def _op_update_index(self, op: Operation) -> OperationResult:
        """æ›´æ–°ç´¢å¼•"""
        target = Path(op.target)

        if not target.exists():
            return OperationResult(
                op_id=op.op_id,
                success=False,
                message=f"ç´¢å¼•æª”æ¡ˆä¸å­˜åœ¨: {target}",
            )

        # èª¿ç”¨ç´¢å¼•æ›´æ–°è…³æœ¬
        # é€™è£¡å¯ä»¥å°å…¥ update_indexes æ¨¡çµ„
        return OperationResult(
            op_id=op.op_id,
            success=True,
            message=f"ç´¢å¼•å·²æ›´æ–°: {target.name}",
            changes=[f"Updated index: {op.target}"],
        )

    def _check_dependencies(self, op: Operation, results: List[OperationResult]) -> bool:
        """æª¢æŸ¥ä¾è³´æ˜¯å¦æ»¿è¶³"""
        for dep_id in op.depends_on:
            dep_result = next((r for r in results if r.op_id == dep_id), None)
            if dep_result is None or not dep_result.success:
                return False
        return True

    def _create_backup(self, plan: IntegrationPlan):
        """å»ºç«‹å‚™ä»½"""
        self.backup_dir.mkdir(parents=True, exist_ok=True)

        manifest = {
            "plan_id": plan.plan_id,
            "timestamp": datetime.now().isoformat(),
            "operations": [asdict(op) for op in plan.operations],
        }

        manifest_path = self.backup_dir / "manifest.yaml"
        with open(manifest_path, 'w', encoding='utf-8') as f:
            yaml.dump(manifest, f, allow_unicode=True)

    def _update_all_references(self):
        """æ›´æ–°æ‰€æœ‰å—å½±éŸ¿çš„å¼•ç”¨"""
        if not self.reference_updates:
            return

        print("\nğŸ“ æ›´æ–°å¼•ç”¨...")

        # æƒææ‰€æœ‰ .md å’Œ .yaml æª”æ¡ˆ
        for file in PLAYBOOKS_PATH.rglob("*"):
            if file.suffix in ['.md', '.yaml', '.yml'] and file.is_file():
                try:
                    content = file.read_text(encoding='utf-8')
                    modified = False

                    for _, old_path, new_path in self.reference_updates:
                        if old_path in content:
                            content = content.replace(old_path, new_path)
                            modified = True

                    if modified:
                        file.write_text(content, encoding='utf-8')
                        print(f"   æ›´æ–°å¼•ç”¨: {file.name}")

                except Exception as e:
                    print(f"   âš ï¸ ç„¡æ³•æ›´æ–° {file.name}: {e}")

    def _decision_to_operation(self, decision: Dict) -> Operation:
        """å°‡æ±ºç­–è½‰æ›ç‚ºæ“ä½œ"""
        integration_type = decision.get("integration_type", "full_integration")

        if integration_type == "full_integration":
            return Operation(
                op_id=decision.get("asset_id", "op_001"),
                op_type=OperationType.MOVE_FILE,
                source=decision.get("source_path"),
                target=decision.get("target_directory") + "/" + decision.get("target_filename", ""),
            )
        elif integration_type == "embedded_integration":
            return Operation(
                op_id=decision.get("asset_id", "op_001"),
                op_type=OperationType.EMBED_CONTENT,
                source=decision.get("source_path"),
                target=decision.get("embedding_location"),
                options={"section": decision.get("embedding_section")},
            )
        elif integration_type == "archive":
            return Operation(
                op_id=decision.get("asset_id", "op_001"),
                op_type=OperationType.MOVE_FILE,
                source=decision.get("source_path"),
                target="_legacy_scratch/archive/" + decision.get("target_filename", ""),
            )
        else:
            raise ValueError(f"æœªçŸ¥æ•´åˆé¡å‹: {integration_type}")

    def rollback(self, steps: int = 1):
        """å›æ»¾æ“ä½œ"""
        print(f"\nğŸ”„ å›æ»¾æœ€è¿‘ {steps} å€‹æ“ä½œ...")

        ops_to_rollback = self.executed_ops[-steps:]
        for op_result in reversed(ops_to_rollback):
            if op_result.rollback_info:
                info = op_result.rollback_info
                if "source" in info and "target" in info:
                    # ç§»å‹•å›æ»¾
                    shutil.move(info["source"], info["target"])
                    print(f"   å·²å›æ»¾: {op_result.op_id}")
                elif "delete" in info:
                    # åˆªé™¤å›æ»¾
                    Path(info["delete"]).unlink(missing_ok=True)
                    print(f"   å·²å›æ»¾: {op_result.op_id}")
                elif "restore_from" in info:
                    # é‚„åŸå›æ»¾
                    shutil.copy2(info["restore_from"], info["restore_to"])
                    print(f"   å·²å›æ»¾: {op_result.op_id}")

# ============================================================================
# æ‰¹é‡è™•ç†å™¨
# ============================================================================

class BatchProcessor:
    """
    æ‰¹é‡è™•ç†å™¨ï¼šæ‰¹é‡åŸ·è¡Œå¤šå€‹æ±ºç­–
    """

    def __init__(self, executor: IntegrationExecutor):
        self.executor = executor

    def process_directory(self, decisions_dir: Path) -> List[OperationResult]:
        """è™•ç†ç›®éŒ„ä¸­çš„æ‰€æœ‰æ±ºç­–"""
        results = []

        decision_files = list(decisions_dir.glob("*_decision.yaml"))
        print(f"\nğŸ“‚ æ‰¾åˆ° {len(decision_files)} å€‹æ±ºç­–æª”æ¡ˆ")

        for decision_file in decision_files:
            print(f"\nè™•ç†: {decision_file.name}")
            result = self.executor.execute_single(decision_file)
            results.append(result)

        return results

    def process_plan(self, plan_file: Path) -> List[OperationResult]:
        """è™•ç†è¨ˆç•«æª”æ¡ˆ"""
        with open(plan_file, 'r', encoding='utf-8') as f:
            plan_data = yaml.safe_load(f)

        operations = []
        for i, op_data in enumerate(plan_data.get("operations", [])):
            operations.append(Operation(
                op_id=op_data.get("op_id", f"op_{i:03d}"),
                op_type=OperationType(op_data.get("op_type")),
                source=op_data.get("source"),
                target=op_data.get("target"),
                options=op_data.get("options", {}),
                depends_on=op_data.get("depends_on", []),
            ))

        plan = IntegrationPlan(
            plan_id=plan_data.get("plan_id", datetime.now().strftime("%Y%m%d_%H%M%S")),
            created_at=plan_data.get("created_at", datetime.now().isoformat()),
            target_directory=plan_data.get("target_directory", str(PLAYBOOKS_PATH)),
            operations=operations,
            estimated_changes=len(operations),
            risk_level=plan_data.get("risk_level", "medium"),
        )

        return self.executor.execute_plan(plan)

# ============================================================================
# CLI å…¥å£
# ============================================================================

def main():
    parser = argparse.ArgumentParser(
        description="Integration Executor - é›†æˆåŸ·è¡Œå¼•æ“",
        formatter_class=argparse.RawDescriptionHelpFormatter,
    )

    subparsers = parser.add_subparsers(dest="command", help="å¯ç”¨å‘½ä»¤")

    # single å‘½ä»¤
    single_parser = subparsers.add_parser("single", help="åŸ·è¡Œå–®ä¸€æ±ºç­–")
    single_parser.add_argument("--decision", "-d", required=True, help="æ±ºç­–æª”æ¡ˆ")
    single_parser.add_argument("--dry-run", action="store_true", help="æ¨¡æ“¬åŸ·è¡Œ")
    single_parser.add_argument("--confirm", action="store_true", help="ç¢ºèªåŸ·è¡Œ")

    # batch å‘½ä»¤
    batch_parser = subparsers.add_parser("batch", help="æ‰¹é‡åŸ·è¡Œ")
    batch_parser.add_argument("--decisions", "-d", help="æ±ºç­–ç›®éŒ„")
    batch_parser.add_argument("--plan", "-p", help="è¨ˆç•«æª”æ¡ˆ")
    batch_parser.add_argument("--dry-run", action="store_true", help="æ¨¡æ“¬åŸ·è¡Œ")
    batch_parser.add_argument("--confirm", action="store_true", help="ç¢ºèªåŸ·è¡Œ")

    # reorganize å‘½ä»¤
    reorg_parser = subparsers.add_parser("reorganize", help="é‡çµ„ç›®éŒ„")
    reorg_parser.add_argument("--target", "-t", required=True, help="ç›®æ¨™ç›®éŒ„")
    reorg_parser.add_argument("--dry-run", action="store_true", help="æ¨¡æ“¬åŸ·è¡Œ")
    reorg_parser.add_argument("--confirm", action="store_true", help="ç¢ºèªåŸ·è¡Œ")
    reorg_parser.add_argument("--output", "-o", help="è¼¸å‡ºå„ªåŒ–å ±å‘Š")

    # rollback å‘½ä»¤
    rollback_parser = subparsers.add_parser("rollback", help="å›æ»¾æ“ä½œ")
    rollback_parser.add_argument("--steps", "-s", type=int, default=1, help="å›æ»¾æ­¥æ•¸")

    # map å‘½ä»¤
    map_parser = subparsers.add_parser("map", help="ç”Ÿæˆç›®éŒ„åœ–è­œ")
    map_parser.add_argument("--target", "-t", required=True, help="ç›®æ¨™ç›®éŒ„")
    map_parser.add_argument("--format", "-f", choices=["ascii", "mermaid"], default="ascii")
    map_parser.add_argument("--output", "-o", help="è¼¸å‡ºæª”æ¡ˆ")

    args = parser.parse_args()

    if not args.command:
        parser.print_help()
        return

    # ç¢ºå®šåŸ·è¡Œæ¨¡å¼
    mode = ExecutionMode.DRY_RUN
    if hasattr(args, 'confirm') and args.confirm:
        mode = ExecutionMode.CONFIRM
    elif hasattr(args, 'dry_run') and not args.dry_run:
        mode = ExecutionMode.CONFIRM

    executor = IntegrationExecutor(mode=mode)

    if args.command == "single":
        result = executor.execute_single(Path(args.decision))
        print(f"\nçµæœ: {'âœ… æˆåŠŸ' if result.success else 'âŒ å¤±æ•—'}")
        print(f"è¨Šæ¯: {result.message}")

    elif args.command == "batch":
        batch_processor = BatchProcessor(executor)

        if args.plan:
            results = batch_processor.process_plan(Path(args.plan))
        elif args.decisions:
            results = batch_processor.process_directory(Path(args.decisions))
        else:
            print("è«‹æŒ‡å®š --decisions æˆ– --plan")
            return

        success_count = sum(1 for r in results if r.success)
        print(f"\nå®Œæˆ: {success_count}/{len(results)} æˆåŠŸ")

    elif args.command == "reorganize":
        optimizer = DirectoryOptimizer()
        target = Path(args.target)

        optimization = optimizer.analyze(target)
        print(f"\nğŸ“Š å„ªåŒ–åˆ†æ: {target}")
        print(f"   æ”¹é€²åˆ†æ•¸: {optimization.improvement_score:.2f}")
        print(f"   æ“ä½œæ•¸: {len(optimization.operations)}")

        if args.output:
            output = {
                "target": optimization.target_dir,
                "improvement_score": optimization.improvement_score,
                "current_structure": optimization.current_structure,
                "optimized_structure": optimization.optimized_structure,
                "operations": [asdict(op) for op in optimization.operations],
            }
            with open(args.output, 'w', encoding='utf-8') as f:
                yaml.dump(output, f, allow_unicode=True, default_flow_style=False)
            print(f"\nå ±å‘Šå·²å„²å­˜: {args.output}")

        if optimization.operations and mode != ExecutionMode.DRY_RUN:
            plan = IntegrationPlan(
                plan_id=f"reorg_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                created_at=datetime.now().isoformat(),
                target_directory=str(target),
                operations=optimization.operations,
                estimated_changes=len(optimization.operations),
                risk_level="low",
            )
            executor.execute_plan(plan)

    elif args.command == "rollback":
        executor.rollback(steps=args.steps)

    elif args.command == "map":
        mapper = DirectoryMapper()
        target = Path(args.target)

        if args.format == "ascii":
            output = mapper.generate_ascii_tree(target)
        else:
            output = mapper.generate_mermaid_diagram(target)

        if args.output:
            with open(args.output, 'w', encoding='utf-8') as f:
                f.write(output)
            print(f"åœ–è­œå·²å„²å­˜: {args.output}")
        else:
            print(output)

if __name__ == "__main__":
    main()
