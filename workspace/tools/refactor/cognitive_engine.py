#!/usr/bin/env python3
"""
Cognitive Engine - èªçŸ¥æ¨ç†å¼•æ“

æä¾›é«˜éšèªçŸ¥èƒ½åŠ›ï¼ŒåŒ…æ‹¬ï¼š
1. ç†è§£å±¤ (Understanding): å¤šç¶­åº¦å…¨é¢ç†è§£ç”¨æˆ¶éœ€æ±‚
2. æ¨ç†å±¤ (Reasoning): å…§éƒ¨æ¨ç†èˆ‡é‚è¼¯åˆ†æ
3. æœå°‹å±¤ (Search): åˆ©ç”¨å·¥å…·/APIå°‹æ‰¾æœ€æ–°è§£æ±ºæ–¹æ¡ˆ
4. æ•´åˆå±¤ (Integration): æ•´åˆæ¨ç†çµæœç”Ÿæˆæ±ºç­–

Version: 1.0.0
"""

import os
import re
import json
import yaml
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, field, asdict
from enum import Enum
from abc import ABC, abstractmethod

# ============================================================================
# èªçŸ¥å±¤ç´šå®šç¾©
# ============================================================================

class CognitiveLevel(Enum):
    """èªçŸ¥å±¤ç´š"""
    PERCEPTION = "perception"        # æ„ŸçŸ¥å±¤ï¼šæ¥æ”¶åŸå§‹è¼¸å…¥
    UNDERSTANDING = "understanding"  # ç†è§£å±¤ï¼šèªç¾©è§£æ
    REASONING = "reasoning"          # æ¨ç†å±¤ï¼šé‚è¼¯åˆ†æ
    SEARCH = "search"               # æœå°‹å±¤ï¼šå¤–éƒ¨è³‡æº
    INTEGRATION = "integration"     # æ•´åˆå±¤ï¼šç¶œåˆæ±ºç­–
    DECISION = "decision"           # æ±ºç­–å±¤ï¼šæœ€çµ‚è¼¸å‡º

class ConfidenceLevel(Enum):
    """ä¿¡å¿ƒæ°´å¹³"""
    HIGH = "high"           # >= 0.8
    MEDIUM = "medium"       # 0.5 - 0.8
    LOW = "low"             # 0.3 - 0.5
    INSUFFICIENT = "insufficient"  # < 0.3

# ============================================================================
# è³‡æ–™çµæ§‹
# ============================================================================

@dataclass
class CognitiveContext:
    """èªçŸ¥ä¸Šä¸‹æ–‡"""
    session_id: str
    timestamp: str
    raw_input: Dict
    understanding: Optional[Dict] = None
    reasoning_trace: List[Dict] = field(default_factory=list)
    search_results: List[Dict] = field(default_factory=list)
    integration_result: Optional[Dict] = None
    final_decision: Optional[Dict] = None
    confidence: float = 0.0
    metadata: Dict = field(default_factory=dict)

@dataclass
class UnderstandingResult:
    """ç†è§£å±¤çµæœ"""
    intent: str                          # ç”¨æˆ¶æ„åœ–
    entities: List[Dict]                 # è­˜åˆ¥çš„å¯¦é«”
    constraints: List[str]               # ç´„æŸæ¢ä»¶
    implicit_requirements: List[str]     # éš±å«éœ€æ±‚
    ambiguities: List[str]               # æ­§ç¾©é»
    completeness_score: float            # å®Œæ•´åº¦è©•åˆ† 0-1
    dimensions: Dict[str, Any]           # å¤šç¶­åº¦åˆ†æ

@dataclass
class ReasoningStep:
    """æ¨ç†æ­¥é©Ÿ"""
    step_id: int
    hypothesis: str           # å‡è¨­
    evidence: List[str]       # è­‰æ“š
    conclusion: str           # çµè«–
    confidence: float         # ä¿¡å¿ƒåº¦
    alternatives: List[str]   # å‚™é¸æ–¹æ¡ˆ

@dataclass
class SearchQuery:
    """æœå°‹æŸ¥è©¢"""
    query_type: str           # local, web, api, knowledge_base
    query_text: str
    filters: Dict
    max_results: int = 10

@dataclass
class IntegrationResult:
    """æ•´åˆçµæœ"""
    synthesized_understanding: Dict
    weighted_recommendations: List[Dict]
    risk_assessment: Dict
    confidence_breakdown: Dict
    final_score: float

# ============================================================================
# ç†è§£å±¤ - Understanding Layer
# ============================================================================

class UnderstandingLayer:
    """
    ç†è§£å±¤ï¼šå¤šç¶­åº¦å…¨é¢ç†è§£ç”¨æˆ¶éœ€æ±‚

    åŠŸèƒ½ï¼š
    - æ„åœ–è­˜åˆ¥
    - å¯¦é«”æŠ½å–
    - ç´„æŸåˆ†æ
    - éš±å«éœ€æ±‚æ¨æ–·
    - æ­§ç¾©æª¢æ¸¬
    - å®Œæ•´åº¦è©•ä¼°
    """

    def __init__(self, config: Optional[Dict] = None):
        self.config = config or {}

        # æ„åœ–æ¨¡å¼åº«
        self.intent_patterns = {
            "refactor": ["é‡æ§‹", "refactor", "restructure", "reorganize", "æ•´ç†"],
            "analyze": ["åˆ†æ", "analyze", "examine", "inspect", "æª¢è¦–"],
            "integrate": ["æ•´åˆ", "integrate", "merge", "combine", "é›†æˆ"],
            "migrate": ["é·ç§»", "migrate", "move", "transfer", "æ¬é·"],
            "cleanup": ["æ¸…ç†", "cleanup", "remove", "delete", "åˆªé™¤"],
            "optimize": ["å„ªåŒ–", "optimize", "improve", "enhance", "æ”¹é€²"],
        }

        # å¯¦é«”é¡å‹
        self.entity_types = {
            "path": r"[\w\-./]+(?:\.(?:py|yaml|yml|md|json|ts|js))?",
            "module": r"(?:module|package|library|å¥—ä»¶|æ¨¡çµ„)[\s:ï¼š]*[\w\-]+",
            "priority": r"(?:P[0-3]|å„ªå…ˆ[ç´šåº¦][\s:ï¼š]*[é«˜ä¸­ä½])",
            "action": r"(?:create|update|delete|move|rename|å»ºç«‹|æ›´æ–°|åˆªé™¤|ç§»å‹•|é‡å‘½å)",
        }

    def understand(self, raw_input: Dict) -> UnderstandingResult:
        """åŸ·è¡Œå¤šç¶­åº¦ç†è§£"""
        text = self._extract_text(raw_input)

        intent = self._identify_intent(text)
        entities = self._extract_entities(text, raw_input)
        constraints = self._extract_constraints(text, raw_input)
        implicit_reqs = self._infer_implicit_requirements(intent, entities, constraints)
        ambiguities = self._detect_ambiguities(text, entities)
        completeness = self._assess_completeness(intent, entities, constraints)
        dimensions = self._multi_dimensional_analysis(raw_input)

        return UnderstandingResult(
            intent=intent,
            entities=entities,
            constraints=constraints,
            implicit_requirements=implicit_reqs,
            ambiguities=ambiguities,
            completeness_score=completeness,
            dimensions=dimensions,
        )

    def _extract_text(self, raw_input: Dict) -> str:
        """å¾åŸå§‹è¼¸å…¥æå–æ–‡æœ¬"""
        if isinstance(raw_input, str):
            return raw_input
        if "text" in raw_input:
            return raw_input["text"]
        if "description" in raw_input:
            return raw_input["description"]
        if "query" in raw_input:
            return raw_input["query"]
        return str(raw_input)

    def _identify_intent(self, text: str) -> str:
        """è­˜åˆ¥ç”¨æˆ¶æ„åœ–"""
        text_lower = text.lower()

        intent_scores = {}
        for intent, patterns in self.intent_patterns.items():
            score = sum(1 for p in patterns if p.lower() in text_lower)
            if score > 0:
                intent_scores[intent] = score

        if not intent_scores:
            return "unknown"

        return max(intent_scores, key=intent_scores.get)

    def _extract_entities(self, text: str, raw_input: Dict) -> List[Dict]:
        """æŠ½å–å¯¦é«”"""
        entities = []

        for entity_type, pattern in self.entity_types.items():
            matches = re.findall(pattern, text, re.IGNORECASE)
            for match in matches:
                entities.append({
                    "type": entity_type,
                    "value": match,
                    "confidence": 0.8,
                })

        # å¾çµæ§‹åŒ–è¼¸å…¥æå–
        if isinstance(raw_input, dict):
            if "target" in raw_input:
                entities.append({"type": "path", "value": raw_input["target"], "confidence": 1.0})
            if "files" in raw_input:
                for f in raw_input["files"]:
                    entities.append({"type": "path", "value": f, "confidence": 1.0})

        return entities

    def _extract_constraints(self, text: str, raw_input: Dict) -> List[str]:
        """æå–ç´„æŸæ¢ä»¶"""
        constraints = []

        # æ™‚é–“ç´„æŸ
        time_patterns = [
            r"(?:before|by|until|åœ¨[\s]*ä¹‹å‰)[\s]*([^,ã€‚]+)",
            r"(?:within|åœ¨[\s]*)(\d+[\s]*(?:å¤©|å°æ™‚|åˆ†é˜|days?|hours?))",
        ]
        for pattern in time_patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            constraints.extend([f"time_constraint: {m}" for m in matches])

        # ç¯„åœç´„æŸ
        if "only" in text.lower() or "åƒ…" in text or "åª" in text:
            constraints.append("scope_limited")

        # æ˜ç¢ºçš„ç´„æŸ
        if isinstance(raw_input, dict):
            if "constraints" in raw_input:
                constraints.extend(raw_input["constraints"])
            if "exclude" in raw_input:
                constraints.append(f"exclude: {raw_input['exclude']}")

        return constraints

    def _infer_implicit_requirements(self, intent: str, entities: List[Dict],
                                     constraints: List[str]) -> List[str]:
        """æ¨æ–·éš±å«éœ€æ±‚"""
        implicit = []

        # æ ¹æ“šæ„åœ–æ¨æ–·
        if intent == "refactor":
            implicit.append("éœ€è¦ä¿æŒå‘å¾Œå…¼å®¹")
            implicit.append("éœ€è¦æ›´æ–°ç›¸é—œå¼•ç”¨")
            implicit.append("éœ€è¦ç¶­è­·ç›®éŒ„çµæ§‹ä¸€è‡´æ€§")

        if intent == "integrate":
            implicit.append("éœ€è¦è§£æ±ºæ½›åœ¨è¡çª")
            implicit.append("éœ€è¦é©—è­‰ä¾è³´é—œä¿‚")

        if intent == "cleanup":
            implicit.append("éœ€è¦å‚™ä»½å¾…åˆªé™¤å…§å®¹")
            implicit.append("éœ€è¦ç¢ºèªç„¡æ´»èºå¼•ç”¨")

        # æ ¹æ“šå¯¦é«”æ¨æ–·
        paths = [e["value"] for e in entities if e["type"] == "path"]
        if any("legacy" in p.lower() for p in paths):
            implicit.append("æ¶‰åŠéºç•™ä»£ç¢¼è™•ç†")

        if any("config" in p.lower() for p in paths):
            implicit.append("éœ€è¦å°å¿ƒè™•ç†é…ç½®è®Šæ›´")

        return implicit

    def _detect_ambiguities(self, text: str, entities: List[Dict]) -> List[str]:
        """æª¢æ¸¬æ­§ç¾©"""
        ambiguities = []

        # æ¨¡ç³Šè©æª¢æ¸¬
        vague_terms = ["ç›¸é—œ", "é¡ä¼¼", "ç­‰ç­‰", "ä¹‹é¡", "some", "etc", "related"]
        for term in vague_terms:
            if term in text.lower():
                ambiguities.append(f"æ¨¡ç³Šè¡“èª: '{term}'")

        # å¯¦é«”æ­§ç¾©
        path_entities = [e for e in entities if e["type"] == "path"]
        for entity in path_entities:
            if "*" in entity["value"] or "?" in entity["value"]:
                ambiguities.append(f"è·¯å¾‘é€šé…ç¬¦éœ€è¦ç¢ºèª: {entity['value']}")

        # ç¼ºå¤±é—œéµä¿¡æ¯
        if len(entities) == 0:
            ambiguities.append("æœªè­˜åˆ¥åˆ°å…·é«”æ“ä½œç›®æ¨™")

        return ambiguities

    def _assess_completeness(self, intent: str, entities: List[Dict],
                             constraints: List[str]) -> float:
        """è©•ä¼°ä¿¡æ¯å®Œæ•´åº¦"""
        score = 0.0
        max_score = 5.0

        # æœ‰æ˜ç¢ºæ„åœ–
        if intent != "unknown":
            score += 1.0

        # æœ‰ç›®æ¨™å¯¦é«”
        if len(entities) > 0:
            score += 1.0
            if len(entities) >= 3:
                score += 0.5

        # æœ‰ç´„æŸæ¢ä»¶
        if len(constraints) > 0:
            score += 0.5

        # æœ‰è·¯å¾‘å¯¦é«”
        if any(e["type"] == "path" for e in entities):
            score += 1.0

        # æœ‰å„ªå…ˆç´šæŒ‡å®š
        if any(e["type"] == "priority" for e in entities):
            score += 0.5

        # æœ‰å‹•ä½œæŒ‡å®š
        if any(e["type"] == "action" for e in entities):
            score += 0.5

        return min(score / max_score, 1.0)

    def _multi_dimensional_analysis(self, raw_input: Dict) -> Dict[str, Any]:
        """å¤šç¶­åº¦åˆ†æ"""
        return {
            "scope_dimension": self._analyze_scope(raw_input),
            "complexity_dimension": self._analyze_complexity(raw_input),
            "risk_dimension": self._analyze_risk(raw_input),
            "temporal_dimension": self._analyze_temporal(raw_input),
            "dependency_dimension": self._analyze_dependencies(raw_input),
        }

    def _analyze_scope(self, raw_input: Dict) -> Dict:
        """åˆ†æç¯„åœç¶­åº¦"""
        return {
            "breadth": "narrow",  # narrow, moderate, wide
            "depth": "surface",   # surface, moderate, deep
            "coverage": 0.5,
        }

    def _analyze_complexity(self, raw_input: Dict) -> Dict:
        """åˆ†æè¤‡é›œåº¦ç¶­åº¦"""
        return {
            "structural": "low",
            "logical": "medium",
            "integration": "low",
        }

    def _analyze_risk(self, raw_input: Dict) -> Dict:
        """åˆ†æé¢¨éšªç¶­åº¦"""
        return {
            "breaking_changes": "low",
            "data_loss": "low",
            "rollback_difficulty": "easy",
        }

    def _analyze_temporal(self, raw_input: Dict) -> Dict:
        """åˆ†ææ™‚é–“ç¶­åº¦"""
        return {
            "urgency": "normal",
            "estimated_duration": "unknown",
        }

    def _analyze_dependencies(self, raw_input: Dict) -> Dict:
        """åˆ†æä¾è³´ç¶­åº¦"""
        return {
            "internal_deps": [],
            "external_deps": [],
            "blocking_tasks": [],
        }

# ============================================================================
# æ¨ç†å±¤ - Reasoning Layer
# ============================================================================

class ReasoningLayer:
    """
    æ¨ç†å±¤ï¼šå…§éƒ¨é‚è¼¯æ¨ç†èˆ‡åˆ†æ

    åŠŸèƒ½ï¼š
    - å‡è¨­ç”Ÿæˆ
    - è­‰æ“šæ”¶é›†
    - é‚è¼¯æ¨å°
    - çµè«–é©—è­‰
    - å‚™é¸æ–¹æ¡ˆç”Ÿæˆ
    """

    def __init__(self, config: Optional[Dict] = None):
        self.config = config or {}
        self.reasoning_trace: List[ReasoningStep] = []

    def reason(self, understanding: UnderstandingResult,
               context: Optional[Dict] = None) -> List[ReasoningStep]:
        """åŸ·è¡Œæ¨ç†"""
        self.reasoning_trace = []

        # æ­¥é©Ÿ1: ä¿¡æ¯å……è¶³æ€§æ¨ç†
        step1 = self._reason_completeness(understanding)
        self.reasoning_trace.append(step1)

        # å¦‚æœä¿¡æ¯ä¸è¶³ï¼Œé€²è¡Œè£œå……æ¨ç†
        if understanding.completeness_score < 0.6:
            step_infer = self._infer_missing_information(understanding)
            self.reasoning_trace.append(step_infer)

        # æ­¥é©Ÿ2: æ„åœ–æ¾„æ¸…æ¨ç†
        step2 = self._reason_intent_clarification(understanding)
        self.reasoning_trace.append(step2)

        # æ­¥é©Ÿ3: ç´„æŸåˆ†ææ¨ç†
        step3 = self._reason_constraints(understanding)
        self.reasoning_trace.append(step3)

        # æ­¥é©Ÿ4: æ–¹æ¡ˆå¯è¡Œæ€§æ¨ç†
        step4 = self._reason_feasibility(understanding, context)
        self.reasoning_trace.append(step4)

        # æ­¥é©Ÿ5: æœ€ä½³è·¯å¾‘æ¨ç†
        step5 = self._reason_optimal_path(understanding, context)
        self.reasoning_trace.append(step5)

        return self.reasoning_trace

    def _reason_completeness(self, understanding: UnderstandingResult) -> ReasoningStep:
        """æ¨ç†ä¿¡æ¯å®Œæ•´æ€§"""
        hypothesis = "ç•¶å‰è¼¸å…¥ä¿¡æ¯æ˜¯å¦è¶³ä»¥åšå‡ºæ±ºç­–"

        evidence = []
        if understanding.intent != "unknown":
            evidence.append(f"å·²è­˜åˆ¥æ„åœ–: {understanding.intent}")
        if len(understanding.entities) > 0:
            evidence.append(f"å·²è­˜åˆ¥ {len(understanding.entities)} å€‹å¯¦é«”")
        if len(understanding.ambiguities) > 0:
            evidence.append(f"ç™¼ç¾ {len(understanding.ambiguities)} å€‹æ­§ç¾©é»")

        completeness = understanding.completeness_score
        if completeness >= 0.8:
            conclusion = "ä¿¡æ¯å……è¶³ï¼Œå¯ç›´æ¥é€²è¡Œæ±ºç­–"
        elif completeness >= 0.5:
            conclusion = "ä¿¡æ¯åŸºæœ¬å……è¶³ï¼Œéœ€è¦è£œå……éƒ¨åˆ†ç´°ç¯€"
        else:
            conclusion = "ä¿¡æ¯ä¸è¶³ï¼Œéœ€è¦é¡å¤–æ¨ç†æˆ–ç”¨æˆ¶ç¢ºèª"

        return ReasoningStep(
            step_id=1,
            hypothesis=hypothesis,
            evidence=evidence,
            conclusion=conclusion,
            confidence=completeness,
            alternatives=[],
        )

    def _infer_missing_information(self, understanding: UnderstandingResult) -> ReasoningStep:
        """æ¨æ–·ç¼ºå¤±ä¿¡æ¯"""
        hypothesis = "å˜—è©¦æ¨æ–·ç¼ºå¤±çš„é—œéµä¿¡æ¯"

        inferences = []
        evidence = []

        # æ ¹æ“šæ„åœ–æ¨æ–·ç›®æ¨™
        if understanding.intent == "refactor" and not any(
            e["type"] == "path" for e in understanding.entities
        ):
            inferences.append("åŸºæ–¼ä¸Šä¸‹æ–‡ï¼Œç›®æ¨™å¯èƒ½æ˜¯ docs/refactor_playbooks")
            evidence.append("é‡æ§‹æ„åœ–é€šå¸¸é‡å° playbooks ç›®éŒ„")

        # æ ¹æ“šéš±å«éœ€æ±‚æ¨æ–·ç´„æŸ
        for implicit in understanding.implicit_requirements:
            if "å…¼å®¹" in implicit:
                inferences.append("æ¨æ–·éœ€è¦ç”Ÿæˆé·ç§»è¨ˆç•«")
                evidence.append("å‘å¾Œå…¼å®¹æš—ç¤ºéœ€è¦æ¼¸é€²å¼é·ç§»")

        return ReasoningStep(
            step_id=len(self.reasoning_trace) + 1,
            hypothesis=hypothesis,
            evidence=evidence,
            conclusion="; ".join(inferences) if inferences else "ç„¡æ³•æœ‰æ•ˆæ¨æ–·ï¼Œéœ€è¦æ›´å¤šä¿¡æ¯",
            confidence=0.6 if inferences else 0.3,
            alternatives=["è«‹æ±‚ç”¨æˆ¶æä¾›æ›´å¤šç´°ç¯€"],
        )

    def _reason_intent_clarification(self, understanding: UnderstandingResult) -> ReasoningStep:
        """æ¨ç†æ„åœ–æ¾„æ¸…"""
        hypothesis = f"ç”¨æˆ¶æ„åœ– '{understanding.intent}' çš„å…·é«”å«ç¾©"

        evidence = [f"è­˜åˆ¥çš„æ„åœ–: {understanding.intent}"]
        for entity in understanding.entities:
            evidence.append(f"ç›¸é—œå¯¦é«”: {entity['type']}={entity['value']}")

        # æ„åœ–ç´°åŒ–
        if understanding.intent == "refactor":
            conclusion = "ç”¨æˆ¶å¸Œæœ›é‡æ–°çµ„ç¹”ç›®éŒ„çµæ§‹ï¼Œæé«˜å¯ç¶­è­·æ€§"
            alternatives = ["å¯èƒ½æ˜¯é‡å‘½å", "å¯èƒ½æ˜¯åˆ†å‰²æ¨¡çµ„", "å¯èƒ½æ˜¯åˆä½µæª”æ¡ˆ"]
        elif understanding.intent == "integrate":
            conclusion = "ç”¨æˆ¶å¸Œæœ›å°‡åˆ†æ•£çš„è³‡æºæ•´åˆåˆ°çµ±ä¸€ä½ç½®"
            alternatives = ["å¯èƒ½æ˜¯åˆä½µå…§å®¹", "å¯èƒ½æ˜¯å»ºç«‹å¼•ç”¨", "å¯èƒ½æ˜¯åµŒå…¥å¼æ•´åˆ"]
        else:
            conclusion = f"åŸ·è¡Œ {understanding.intent} æ“ä½œ"
            alternatives = []

        return ReasoningStep(
            step_id=len(self.reasoning_trace) + 1,
            hypothesis=hypothesis,
            evidence=evidence,
            conclusion=conclusion,
            confidence=0.75,
            alternatives=alternatives,
        )

    def _reason_constraints(self, understanding: UnderstandingResult) -> ReasoningStep:
        """æ¨ç†ç´„æŸæ¢ä»¶"""
        hypothesis = "åˆ†æä¸¦æ•´åˆæ‰€æœ‰ç´„æŸæ¢ä»¶"

        evidence = understanding.constraints.copy()
        evidence.extend([f"éš±å«ç´„æŸ: {r}" for r in understanding.implicit_requirements])

        # è­˜åˆ¥è¡çª
        conflicts = []
        if "scope_limited" in understanding.constraints and len(understanding.entities) == 0:
            conflicts.append("ç¯„åœé™åˆ¶ä½†æœªæŒ‡å®šå…·é«”ç›®æ¨™")

        if conflicts:
            conclusion = f"ç™¼ç¾ {len(conflicts)} å€‹ç´„æŸè¡çªéœ€è¦è§£æ±º"
        else:
            conclusion = f"å…± {len(evidence)} å€‹ç´„æŸæ¢ä»¶ï¼Œç„¡æ˜é¡¯è¡çª"

        return ReasoningStep(
            step_id=len(self.reasoning_trace) + 1,
            hypothesis=hypothesis,
            evidence=evidence,
            conclusion=conclusion,
            confidence=0.8 if not conflicts else 0.5,
            alternatives=[f"è¡çª: {c}" for c in conflicts],
        )

    def _reason_feasibility(self, understanding: UnderstandingResult,
                           context: Optional[Dict]) -> ReasoningStep:
        """æ¨ç†å¯è¡Œæ€§"""
        hypothesis = "è©•ä¼°æ“ä½œçš„æŠ€è¡“å¯è¡Œæ€§"

        evidence = []
        feasibility_score = 1.0

        # æª¢æŸ¥è³‡æºå¯ç”¨æ€§
        if context and "available_resources" in context:
            evidence.append(f"å¯ç”¨è³‡æº: {context['available_resources']}")
        else:
            evidence.append("æœªæä¾›è³‡æºä¸Šä¸‹æ–‡ï¼Œå‡è¨­è³‡æºå……è¶³")

        # æª¢æŸ¥é¢¨éšªç­‰ç´š
        risk = understanding.dimensions.get("risk_dimension", {})
        if risk.get("breaking_changes") == "high":
            feasibility_score -= 0.3
            evidence.append("é«˜ç ´å£æ€§è®Šæ›´é¢¨éšª")

        if feasibility_score >= 0.7:
            conclusion = "æŠ€è¡“å¯è¡Œï¼Œé¢¨éšªå¯æ§"
        elif feasibility_score >= 0.4:
            conclusion = "æŠ€è¡“å¯è¡Œï¼Œä½†éœ€è¦é¡å¤–é¢¨éšªæ§åˆ¶"
        else:
            conclusion = "å­˜åœ¨é‡å¤§æŠ€è¡“éšœç¤™ï¼Œéœ€è¦é‡æ–°è©•ä¼°"

        return ReasoningStep(
            step_id=len(self.reasoning_trace) + 1,
            hypothesis=hypothesis,
            evidence=evidence,
            conclusion=conclusion,
            confidence=feasibility_score,
            alternatives=["åˆ†éšæ®µåŸ·è¡Œ", "ç°¡åŒ–ç¯„åœ", "å°‹æ±‚æ›¿ä»£æ–¹æ¡ˆ"],
        )

    def _reason_optimal_path(self, understanding: UnderstandingResult,
                            context: Optional[Dict]) -> ReasoningStep:
        """æ¨ç†æœ€ä½³åŸ·è¡Œè·¯å¾‘"""
        hypothesis = "ç¢ºå®šæœ€å„ªåŸ·è¡Œç­–ç•¥"

        evidence = []
        paths = []

        # æ ¹æ“šæ„åœ–ç”Ÿæˆè·¯å¾‘
        if understanding.intent == "refactor":
            paths = [
                {"name": "æ¼¸é€²å¼é‡æ§‹", "phases": 9, "risk": "low"},
                {"name": "ä¸€æ¬¡æ€§é‡æ§‹", "phases": 3, "risk": "medium"},
                {"name": "ä¸¦è¡Œé‡æ§‹", "phases": 6, "risk": "low"},
            ]
            evidence.append("é‡æ§‹æ“ä½œæ”¯æŒå¤šç¨®ç­–ç•¥")

        elif understanding.intent == "integrate":
            paths = [
                {"name": "å®Œå…¨æ•´åˆ", "phases": 3, "risk": "medium"},
                {"name": "åµŒå…¥å¼æ•´åˆ", "phases": 2, "risk": "low"},
                {"name": "å¼•ç”¨å¼æ•´åˆ", "phases": 1, "risk": "low"},
            ]
            evidence.append("æ•´åˆæ“ä½œæ ¹æ“šå…§å®¹é¡å‹é¸æ“‡ç­–ç•¥")

        # é¸æ“‡æœ€å„ªè·¯å¾‘
        if paths:
            optimal = min(paths, key=lambda p: (
                {"low": 0, "medium": 1, "high": 2}[p["risk"]], p["phases"]
            ))
            conclusion = f"æ¨è–¦ç­–ç•¥: {optimal['name']} ({optimal['phases']} éšæ®µ, {optimal['risk']} é¢¨éšª)"
        else:
            conclusion = "ä½¿ç”¨é»˜èªåŸ·è¡Œç­–ç•¥"
            optimal = None

        return ReasoningStep(
            step_id=len(self.reasoning_trace) + 1,
            hypothesis=hypothesis,
            evidence=evidence,
            conclusion=conclusion,
            confidence=0.8 if optimal else 0.5,
            alternatives=[p["name"] for p in paths if p != optimal] if paths else [],
        )

    def get_confidence_level(self) -> ConfidenceLevel:
        """ç²å–æ•´é«”ä¿¡å¿ƒæ°´å¹³"""
        if not self.reasoning_trace:
            return ConfidenceLevel.INSUFFICIENT

        avg_confidence = sum(s.confidence for s in self.reasoning_trace) / len(self.reasoning_trace)

        if avg_confidence >= 0.8:
            return ConfidenceLevel.HIGH
        elif avg_confidence >= 0.5:
            return ConfidenceLevel.MEDIUM
        elif avg_confidence >= 0.3:
            return ConfidenceLevel.LOW
        else:
            return ConfidenceLevel.INSUFFICIENT

    def needs_external_search(self) -> bool:
        """åˆ¤æ–·æ˜¯å¦éœ€è¦å¤–éƒ¨æœå°‹"""
        if self.get_confidence_level() in [ConfidenceLevel.LOW, ConfidenceLevel.INSUFFICIENT]:
            return True

        # æª¢æŸ¥æ˜¯å¦æœ‰æœªè§£æ±ºçš„æ­§ç¾©
        for step in self.reasoning_trace:
            if "éœ€è¦æ›´å¤šä¿¡æ¯" in step.conclusion or "ç„¡æ³•æœ‰æ•ˆæ¨æ–·" in step.conclusion:
                return True

        return False

# ============================================================================
# æœå°‹å±¤ - Search Layer
# ============================================================================

class SearchLayer:
    """
    æœå°‹å±¤ï¼šåˆ©ç”¨å¤–éƒ¨å·¥å…·/APIå°‹æ‰¾æœ€æ–°è§£æ±ºæ–¹æ¡ˆ

    åŠŸèƒ½ï¼š
    - æœ¬åœ°ä»£ç¢¼åº«æœå°‹
    - çŸ¥è­˜åº«æŸ¥è©¢
    - ç¶²è·¯æœå°‹ (æ¨¡æ“¬)
    - API èª¿ç”¨ (æ¨¡æ“¬)
    """

    def __init__(self, config: Optional[Dict] = None):
        self.config = config or {}
        self.search_results: List[Dict] = []

    def search(self, queries: List[SearchQuery], context: Optional[Dict] = None) -> List[Dict]:
        """åŸ·è¡Œæœå°‹"""
        self.search_results = []

        for query in queries:
            if query.query_type == "local":
                results = self._search_local(query, context)
            elif query.query_type == "knowledge_base":
                results = self._search_knowledge_base(query)
            elif query.query_type == "web":
                results = self._search_web(query)
            elif query.query_type == "api":
                results = self._search_api(query)
            else:
                results = []

            self.search_results.extend(results)

        return self.search_results

    def _search_local(self, query: SearchQuery, context: Optional[Dict]) -> List[Dict]:
        """æœ¬åœ°ä»£ç¢¼åº«æœå°‹"""
        results = []

        # æœå°‹ç›®æ¨™ç›®éŒ„
        target = context.get("target_path") if context else "."
        target_path = Path(target)

        if not target_path.exists():
            return results

        # æ ¹æ“šæŸ¥è©¢æ–‡æœ¬æœå°‹æª”æ¡ˆ
        search_term = query.query_text.lower()
        for file in target_path.rglob("*"):
            if file.is_file():
                if search_term in file.name.lower():
                    results.append({
                        "source": "local",
                        "type": "file_match",
                        "path": str(file),
                        "relevance": 0.9,
                    })

                # å…§å®¹æœå°‹ (é™åˆ¶æ–¼å°æª”æ¡ˆ)
                if file.suffix in [".md", ".yaml", ".yml", ".py"] and file.stat().st_size < 100000:
                    try:
                        content = file.read_text(encoding='utf-8')
                        if search_term in content.lower():
                            results.append({
                                "source": "local",
                                "type": "content_match",
                                "path": str(file),
                                "relevance": 0.7,
                            })
                    except:
                        pass

        return results[:query.max_results]

    def _search_knowledge_base(self, query: SearchQuery) -> List[Dict]:
        """çŸ¥è­˜åº«æŸ¥è©¢"""
        # æ¨¡æ“¬çŸ¥è­˜åº«æŸ¥è©¢
        kb_entries = [
            {
                "topic": "refactor_best_practices",
                "content": "é‡æ§‹æœ€ä½³å¯¦è¸ï¼šæ¼¸é€²å¼è®Šæ›´ã€ä¿æŒæ¸¬è©¦è¦†è“‹ã€æ›´æ–°æ–‡æª”",
                "relevance": 0.8,
            },
            {
                "topic": "directory_organization",
                "content": "ç›®éŒ„çµ„ç¹”åŸå‰‡ï¼šåŠŸèƒ½åˆ†çµ„ã€æ·±åº¦é™åˆ¶ã€å‘½åä¸€è‡´æ€§",
                "relevance": 0.85,
            },
            {
                "topic": "legacy_migration",
                "content": "éºç•™ä»£ç¢¼é·ç§»ï¼šæš«å­˜å€è™•ç†ã€å¼•ç”¨æ›´æ–°ã€é©—è­‰æ¸¬è©¦",
                "relevance": 0.75,
            },
        ]

        results = []
        search_term = query.query_text.lower()

        for entry in kb_entries:
            if any(term in entry["content"].lower() for term in search_term.split()):
                results.append({
                    "source": "knowledge_base",
                    "type": "kb_entry",
                    "topic": entry["topic"],
                    "content": entry["content"],
                    "relevance": entry["relevance"],
                })

        return results[:query.max_results]

    def _search_web(self, query: SearchQuery) -> List[Dict]:
        """ç¶²è·¯æœå°‹ (æ¨¡æ“¬)"""
        # åœ¨å¯¦éš›å¯¦ç¾ä¸­ï¼Œé€™è£¡æœƒèª¿ç”¨æœå°‹ API
        return [
            {
                "source": "web",
                "type": "web_result",
                "title": f"æœå°‹çµæœ: {query.query_text}",
                "url": "https://example.com/result",
                "snippet": "æ¨¡æ“¬çš„ç¶²è·¯æœå°‹çµæœ...",
                "relevance": 0.6,
            }
        ]

    def _search_api(self, query: SearchQuery) -> List[Dict]:
        """API èª¿ç”¨ (æ¨¡æ“¬)"""
        # åœ¨å¯¦éš›å¯¦ç¾ä¸­ï¼Œé€™è£¡æœƒèª¿ç”¨å¤–éƒ¨ API
        return [
            {
                "source": "api",
                "type": "api_response",
                "endpoint": query.query_text,
                "data": {"status": "simulated"},
                "relevance": 0.5,
            }
        ]

    def generate_queries(self, understanding: UnderstandingResult,
                        reasoning: List[ReasoningStep]) -> List[SearchQuery]:
        """æ ¹æ“šç†è§£å’Œæ¨ç†çµæœç”Ÿæˆæœå°‹æŸ¥è©¢"""
        queries = []

        # æ ¹æ“šæ„åœ–ç”ŸæˆæŸ¥è©¢
        if understanding.intent == "refactor":
            queries.append(SearchQuery(
                query_type="knowledge_base",
                query_text="refactor best practices",
                filters={},
            ))

        # æ ¹æ“šå¯¦é«”ç”Ÿæˆæœ¬åœ°æœå°‹
        for entity in understanding.entities:
            if entity["type"] == "path":
                queries.append(SearchQuery(
                    query_type="local",
                    query_text=entity["value"],
                    filters={"type": "file"},
                ))

        # æ ¹æ“šæ­§ç¾©ç”Ÿæˆæ¾„æ¸…æŸ¥è©¢
        for ambiguity in understanding.ambiguities:
            queries.append(SearchQuery(
                query_type="knowledge_base",
                query_text=ambiguity,
                filters={},
                max_results=3,
            ))

        return queries

# ============================================================================
# æ•´åˆå±¤ - Integration Layer
# ============================================================================

class IntegrationLayer:
    """
    æ•´åˆå±¤ï¼šç¶œåˆæ‰€æœ‰ä¿¡æ¯ç”Ÿæˆæœ€çµ‚æ±ºç­–

    åŠŸèƒ½ï¼š
    - ä¿¡æ¯ç¶œåˆ
    - æ¬Šé‡è¨ˆç®—
    - é¢¨éšªè©•ä¼°
    - æœ€çµ‚æ±ºç­–ç”Ÿæˆ
    """

    def __init__(self, config: Optional[Dict] = None):
        self.config = config or {}

    def integrate(self, understanding: UnderstandingResult,
                  reasoning: List[ReasoningStep],
                  search_results: List[Dict]) -> IntegrationResult:
        """æ•´åˆæ‰€æœ‰å±¤çš„çµæœ"""

        # ç¶œåˆç†è§£
        synthesized = self._synthesize_understanding(understanding, search_results)

        # ç”ŸæˆåŠ æ¬Šå»ºè­°
        recommendations = self._generate_weighted_recommendations(
            understanding, reasoning, search_results
        )

        # é¢¨éšªè©•ä¼°
        risk_assessment = self._assess_risks(understanding, reasoning)

        # ä¿¡å¿ƒåˆ†è§£
        confidence_breakdown = self._calculate_confidence_breakdown(
            understanding, reasoning, search_results
        )

        # æœ€çµ‚è©•åˆ†
        final_score = self._calculate_final_score(confidence_breakdown)

        return IntegrationResult(
            synthesized_understanding=synthesized,
            weighted_recommendations=recommendations,
            risk_assessment=risk_assessment,
            confidence_breakdown=confidence_breakdown,
            final_score=final_score,
        )

    def _synthesize_understanding(self, understanding: UnderstandingResult,
                                  search_results: List[Dict]) -> Dict:
        """ç¶œåˆç†è§£"""
        return {
            "confirmed_intent": understanding.intent,
            "validated_entities": [e for e in understanding.entities if e["confidence"] > 0.7],
            "resolved_ambiguities": self._resolve_ambiguities(understanding, search_results),
            "enriched_context": self._enrich_context(understanding, search_results),
        }

    def _resolve_ambiguities(self, understanding: UnderstandingResult,
                            search_results: List[Dict]) -> List[Dict]:
        """è§£æ±ºæ­§ç¾©"""
        resolutions = []

        for ambiguity in understanding.ambiguities:
            # å˜—è©¦å¾æœå°‹çµæœä¸­æ‰¾åˆ°è§£ç­”
            relevant_results = [r for r in search_results
                               if ambiguity.lower() in str(r).lower()]

            if relevant_results:
                resolutions.append({
                    "ambiguity": ambiguity,
                    "resolution": relevant_results[0].get("content", "å·²æ‰¾åˆ°ç›¸é—œä¿¡æ¯"),
                    "confidence": 0.7,
                })
            else:
                resolutions.append({
                    "ambiguity": ambiguity,
                    "resolution": "æœªèƒ½è‡ªå‹•è§£æ±ºï¼Œéœ€è¦ç”¨æˆ¶ç¢ºèª",
                    "confidence": 0.3,
                })

        return resolutions

    def _enrich_context(self, understanding: UnderstandingResult,
                       search_results: List[Dict]) -> Dict:
        """è±å¯Œä¸Šä¸‹æ–‡"""
        enriched = {}

        # å¾çŸ¥è­˜åº«çµæœä¸­æå–æœ€ä½³å¯¦è¸
        kb_results = [r for r in search_results if r.get("source") == "knowledge_base"]
        if kb_results:
            enriched["best_practices"] = [r.get("content") for r in kb_results]

        # å¾æœ¬åœ°æœå°‹ä¸­è­˜åˆ¥ç›¸é—œæª”æ¡ˆ
        local_results = [r for r in search_results if r.get("source") == "local"]
        if local_results:
            enriched["related_files"] = [r.get("path") for r in local_results]

        return enriched

    def _generate_weighted_recommendations(self, understanding: UnderstandingResult,
                                          reasoning: List[ReasoningStep],
                                          search_results: List[Dict]) -> List[Dict]:
        """ç”ŸæˆåŠ æ¬Šå»ºè­°"""
        recommendations = []

        # å¾æ¨ç†æ­¥é©Ÿä¸­æå–å»ºè­°
        for step in reasoning:
            if step.conclusion and "æ¨è–¦" in step.conclusion:
                recommendations.append({
                    "source": "reasoning",
                    "recommendation": step.conclusion,
                    "weight": step.confidence,
                    "alternatives": step.alternatives,
                })

        # å¾æœå°‹çµæœä¸­æå–å»ºè­°
        for result in search_results:
            if result.get("source") == "knowledge_base":
                recommendations.append({
                    "source": "knowledge_base",
                    "recommendation": result.get("content", ""),
                    "weight": result.get("relevance", 0.5),
                    "alternatives": [],
                })

        # æŒ‰æ¬Šé‡æ’åº
        recommendations.sort(key=lambda r: -r["weight"])

        return recommendations

    def _assess_risks(self, understanding: UnderstandingResult,
                     reasoning: List[ReasoningStep]) -> Dict:
        """è©•ä¼°é¢¨éšª"""
        risks = {
            "overall_level": "low",
            "factors": [],
            "mitigations": [],
        }

        # å¾ç¶­åº¦åˆ†æä¸­æå–é¢¨éšª
        risk_dim = understanding.dimensions.get("risk_dimension", {})
        if risk_dim.get("breaking_changes") == "high":
            risks["factors"].append("é«˜ç ´å£æ€§è®Šæ›´")
            risks["mitigations"].append("å»ºè­°åˆ†éšæ®µåŸ·è¡Œ")
            risks["overall_level"] = "medium"

        if risk_dim.get("data_loss") in ["medium", "high"]:
            risks["factors"].append("æ½›åœ¨æ•¸æ“šä¸Ÿå¤±")
            risks["mitigations"].append("åŸ·è¡Œå‰å‰µå»ºå®Œæ•´å‚™ä»½")
            risks["overall_level"] = "medium" if risks["overall_level"] == "low" else "high"

        # å¾æ¨ç†ä¸­è­˜åˆ¥é¢¨éšª
        for step in reasoning:
            if step.confidence < 0.5:
                risks["factors"].append(f"ä½ä¿¡å¿ƒåº¦æ¨ç†: {step.hypothesis}")
                risks["mitigations"].append("éœ€è¦é¡å¤–é©—è­‰")

        return risks

    def _calculate_confidence_breakdown(self, understanding: UnderstandingResult,
                                       reasoning: List[ReasoningStep],
                                       search_results: List[Dict]) -> Dict:
        """è¨ˆç®—ä¿¡å¿ƒåº¦åˆ†è§£"""
        return {
            "understanding_confidence": understanding.completeness_score,
            "reasoning_confidence": (
                sum(s.confidence for s in reasoning) / len(reasoning)
                if reasoning else 0.0
            ),
            "search_confidence": (
                sum(r.get("relevance", 0) for r in search_results) / len(search_results)
                if search_results else 0.0
            ),
            "overall_weights": {
                "understanding": 0.3,
                "reasoning": 0.4,
                "search": 0.3,
            },
        }

    def _calculate_final_score(self, confidence_breakdown: Dict) -> float:
        """è¨ˆç®—æœ€çµ‚è©•åˆ†"""
        weights = confidence_breakdown["overall_weights"]
        score = (
            confidence_breakdown["understanding_confidence"] * weights["understanding"] +
            confidence_breakdown["reasoning_confidence"] * weights["reasoning"] +
            confidence_breakdown["search_confidence"] * weights["search"]
        )
        return round(score, 3)

# ============================================================================
# èªçŸ¥å¼•æ“ - Cognitive Engine (ä¸»æ§åˆ¶å™¨)
# ============================================================================

class CognitiveEngine:
    """
    èªçŸ¥å¼•æ“ï¼šå”èª¿æ‰€æœ‰èªçŸ¥å±¤çš„ä¸»æ§åˆ¶å™¨

    è™•ç†æµç¨‹ï¼š
    1. æ„ŸçŸ¥ â†’ æ¥æ”¶åŸå§‹è¼¸å…¥
    2. ç†è§£ â†’ å¤šç¶­åº¦è§£æ
    3. æ¨ç† â†’ é‚è¼¯åˆ†æ
    4. æœå°‹ â†’ å¤–éƒ¨è³‡æº (å¦‚éœ€è¦)
    5. å†æ¨ç† â†’ æ•´åˆæ–°ä¿¡æ¯
    6. æ•´åˆ â†’ ç”Ÿæˆæ±ºç­–
    7. è¼¸å‡º â†’ è¿”å›çµæœ
    """

    def __init__(self, config: Optional[Dict] = None):
        self.config = config or {}
        self.understanding_layer = UnderstandingLayer(config)
        self.reasoning_layer = ReasoningLayer(config)
        self.search_layer = SearchLayer(config)
        self.integration_layer = IntegrationLayer(config)

    def process(self, raw_input: Dict, context: Optional[Dict] = None) -> CognitiveContext:
        """åŸ·è¡Œå®Œæ•´èªçŸ¥è™•ç†"""
        # åˆå§‹åŒ–ä¸Šä¸‹æ–‡
        ctx = CognitiveContext(
            session_id=datetime.now().strftime("%Y%m%d_%H%M%S"),
            timestamp=datetime.now().isoformat(),
            raw_input=raw_input,
        )

        print(f"ğŸ§  èªçŸ¥å¼•æ“å•Ÿå‹• (Session: {ctx.session_id})")

        # éšæ®µ1: ç†è§£
        print("ğŸ“– éšæ®µ1: å¤šç¶­åº¦ç†è§£...")
        understanding = self.understanding_layer.understand(raw_input)
        ctx.understanding = asdict(understanding)
        print(f"   æ„åœ–: {understanding.intent}")
        print(f"   å®Œæ•´åº¦: {understanding.completeness_score:.2f}")
        print(f"   æ­§ç¾©: {len(understanding.ambiguities)} å€‹")

        # éšæ®µ2: åˆæ­¥æ¨ç†
        print("ğŸ” éšæ®µ2: å…§éƒ¨æ¨ç†...")
        reasoning = self.reasoning_layer.reason(understanding, context)
        ctx.reasoning_trace = [asdict(s) for s in reasoning]
        confidence = self.reasoning_layer.get_confidence_level()
        print(f"   æ¨ç†æ­¥é©Ÿ: {len(reasoning)}")
        print(f"   ä¿¡å¿ƒæ°´å¹³: {confidence.value}")

        # éšæ®µ3: åˆ¤æ–·æ˜¯å¦éœ€è¦å¤–éƒ¨æœå°‹
        if self.reasoning_layer.needs_external_search():
            print("ğŸ” éšæ®µ3: å¤–éƒ¨æœå°‹...")
            queries = self.search_layer.generate_queries(understanding, reasoning)
            search_results = self.search_layer.search(queries, context)
            ctx.search_results = search_results
            print(f"   æŸ¥è©¢æ•¸: {len(queries)}")
            print(f"   çµæœæ•¸: {len(search_results)}")

            # éšæ®µ4: å†æ¨ç† (æ•´åˆæœå°‹çµæœ)
            print("ğŸ”„ éšæ®µ4: å†æ¨ç†...")
            # æ›´æ–°ç†è§£
            for result in search_results:
                if result.get("source") == "local" and result.get("type") == "file_match":
                    understanding.entities.append({
                        "type": "discovered_file",
                        "value": result.get("path"),
                        "confidence": result.get("relevance", 0.5),
                    })

            # é‡æ–°æ¨ç†
            reasoning = self.reasoning_layer.reason(understanding, context)
            ctx.reasoning_trace.extend([asdict(s) for s in reasoning])
        else:
            print("âœ“ è·³éå¤–éƒ¨æœå°‹ (ä¿¡æ¯å……è¶³)")
            ctx.search_results = []

        # éšæ®µ5: æ•´åˆ
        print("ğŸ”— éšæ®µ5: ä¿¡æ¯æ•´åˆ...")
        integration_result = self.integration_layer.integrate(
            understanding, reasoning, ctx.search_results
        )
        ctx.integration_result = asdict(integration_result)
        print(f"   æœ€çµ‚è©•åˆ†: {integration_result.final_score:.3f}")
        print(f"   é¢¨éšªç­‰ç´š: {integration_result.risk_assessment['overall_level']}")

        # éšæ®µ6: ç”Ÿæˆæœ€çµ‚æ±ºç­–
        print("ğŸ“‹ éšæ®µ6: ç”Ÿæˆæ±ºç­–...")
        ctx.final_decision = self._generate_final_decision(
            understanding, reasoning, integration_result
        )
        ctx.confidence = integration_result.final_score

        print(f"\nâœ… èªçŸ¥è™•ç†å®Œæˆ (ä¿¡å¿ƒåº¦: {ctx.confidence:.3f})")
        return ctx

    def _generate_final_decision(self, understanding: UnderstandingResult,
                                reasoning: List[ReasoningStep],
                                integration: IntegrationResult) -> Dict:
        """ç”Ÿæˆæœ€çµ‚æ±ºç­–"""
        # ç¢ºå®šæ˜¯å¦å¯ä»¥è‡ªå‹•åŸ·è¡Œ
        can_auto_execute = (
            integration.final_score >= 0.7 and
            integration.risk_assessment["overall_level"] != "high" and
            understanding.completeness_score >= 0.6
        )

        # æå–é—œéµå»ºè­°
        top_recommendations = integration.weighted_recommendations[:3]

        # ç”Ÿæˆè¡Œå‹•è¨ˆç•«
        action_plan = []
        for i, rec in enumerate(top_recommendations, 1):
            action_plan.append({
                "priority": f"P{i}",
                "action": rec["recommendation"],
                "confidence": rec["weight"],
            })

        return {
            "decision_type": "auto" if can_auto_execute else "manual_confirm",
            "primary_intent": understanding.intent,
            "action_plan": action_plan,
            "requires_confirmation": not can_auto_execute,
            "confirmation_points": [
                amb for amb in understanding.ambiguities
            ] if not can_auto_execute else [],
            "risk_summary": integration.risk_assessment["overall_level"],
            "mitigations": integration.risk_assessment["mitigations"],
        }

# ============================================================================
# ä¾¿æ·å‡½æ•¸
# ============================================================================

def quick_understand(text: str) -> UnderstandingResult:
    """å¿«é€Ÿç†è§£æ–‡æœ¬"""
    layer = UnderstandingLayer()
    return layer.understand({"text": text})

def quick_reason(understanding: UnderstandingResult) -> List[ReasoningStep]:
    """å¿«é€Ÿæ¨ç†"""
    layer = ReasoningLayer()
    return layer.reason(understanding)

def full_cognitive_process(raw_input: Dict, context: Optional[Dict] = None) -> CognitiveContext:
    """å®Œæ•´èªçŸ¥è™•ç†"""
    engine = CognitiveEngine()
    return engine.process(raw_input, context)

# ============================================================================
# ä¸»ç¨‹åºå…¥å£
# ============================================================================

def main():
    """æ¸¬è©¦èªçŸ¥å¼•æ“"""
    import argparse

    parser = argparse.ArgumentParser(description="èªçŸ¥æ¨ç†å¼•æ“")
    parser.add_argument("--input", "-i", required=True, help="è¼¸å…¥æ–‡æœ¬æˆ– JSON æª”æ¡ˆ")
    parser.add_argument("--output", "-o", help="è¼¸å‡ºæª”æ¡ˆ")
    parser.add_argument("--verbose", "-v", action="store_true", help="è©³ç´°è¼¸å‡º")

    args = parser.parse_args()

    # è§£æè¼¸å…¥
    if args.input.endswith(".json"):
        with open(args.input, 'r', encoding='utf-8') as f:
            raw_input = json.load(f)
    elif args.input.endswith(".yaml") or args.input.endswith(".yml"):
        with open(args.input, 'r', encoding='utf-8') as f:
            raw_input = yaml.safe_load(f)
    else:
        raw_input = {"text": args.input}

    # åŸ·è¡ŒèªçŸ¥è™•ç†
    engine = CognitiveEngine()
    result = engine.process(raw_input)

    # è¼¸å‡ºçµæœ
    output = {
        "session_id": result.session_id,
        "timestamp": result.timestamp,
        "confidence": result.confidence,
        "understanding": result.understanding,
        "reasoning_steps": len(result.reasoning_trace),
        "search_results": len(result.search_results),
        "final_decision": result.final_decision,
    }

    if args.verbose:
        output["full_reasoning_trace"] = result.reasoning_trace
        output["integration_result"] = result.integration_result

    output_str = yaml.dump(output, allow_unicode=True, default_flow_style=False, sort_keys=False)

    if args.output:
        with open(args.output, 'w', encoding='utf-8') as f:
            f.write(output_str)
        print(f"\nçµæœå·²å„²å­˜: {args.output}")
    else:
        print("\n" + "=" * 50)
        print("èªçŸ¥è™•ç†çµæœ:")
        print("=" * 50)
        print(output_str)

if __name__ == "__main__":
    main()
