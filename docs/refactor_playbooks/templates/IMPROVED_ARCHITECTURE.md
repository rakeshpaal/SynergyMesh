# ğŸ—ï¸ SynergyMesh æ”¹è¿›æ¶æ„è®¾è®¡

## æ ¸å¿ƒé—®é¢˜åˆ†æ

### å½“å‰æ¶æ„çš„å•ç‚¹æ•…éšœ
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     automation_launcher.py              â”‚  â† å•ç‚¹æ•…éšœ
â”‚  (å¯åŠ¨å™¨ã€è°ƒåº¦å™¨ã€ç›‘æ§å™¨åˆä¸€)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚     Master Orchestrator                 â”‚  â† æ¬¡çº§å•ç‚¹
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚     å¼•æ“1   å¼•æ“2   å¼•æ“3   ...          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**é—®é¢˜**:
1. **å•ç‚¹æ•…éšœ**: Launcherå¤±æ•ˆ = æ•´ä¸ªç³»ç»Ÿå¤±æ§
2. **èŒè´£æ··ä¹±**: ä¸€ä¸ªç»„ä»¶æ‰¿æ‹…å¤ªå¤šèŒè´£
3. **æ¢å¤å›°éš¾**: æ²¡æœ‰è‡ªåŠ¨æ•…éšœè½¬ç§»æœºåˆ¶
4. **çŠ¶æ€ä¸¢å¤±**: é‡å¯å¯èƒ½å¯¼è‡´çŠ¶æ€ä¸ä¸€è‡´

---

## æ”¹è¿›æ¶æ„: å…­å±‚é˜²å¾¡ä½“ç³»

åŸºäºä½ çš„AXIOMç†å¿µï¼Œé‡‡ç”¨**å¤šå±‚éªŒè¯é—¨ + é›¶ä¿¡ä»»åŸåˆ™**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  L-A: Watchdog Layer (çœ‹é—¨ç‹—å±‚)                              â”‚
â”‚  â€¢ ç‹¬ç«‹è¿›ç¨‹ç›‘æ§                                              â”‚
â”‚  â€¢ è‡ªåŠ¨æ•…éšœæ¢å¤                                              â”‚
â”‚  â€¢ å¿ƒè·³æ£€æµ‹                                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  L-B: Control Plane (æ§åˆ¶å¹³é¢)                               â”‚
â”‚  â€¢ ä¸»æ§è°ƒåº¦å™¨ (Primary Scheduler)                            â”‚
â”‚  â€¢ å¤‡ç”¨è°ƒåº¦å™¨ (Standby Scheduler)                            â”‚
â”‚  â€¢ çŠ¶æ€åŒæ­¥                                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  L-C: Orchestration Layer (ç¼–æ’å±‚)                           â”‚
â”‚  â€¢ Master Orchestrator (å¯å¤šå®ä¾‹)                            â”‚
â”‚  â€¢ åˆ†å¸ƒå¼åè°ƒ                                                â”‚
â”‚  â€¢ ä»»åŠ¡åˆ†å‘                                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  L-D: Engine Layer (å¼•æ“å±‚)                                  â”‚
â”‚  â€¢ å„ç±»æ‰§è¡Œå¼•æ“                                              â”‚
â”‚  â€¢ ç‹¬ç«‹è¿è¡Œã€å¯æ›¿æ¢                                          â”‚
â”‚  â€¢ å¥åº·ä¸ŠæŠ¥                                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  L-E: State Management (çŠ¶æ€ç®¡ç†å±‚)                          â”‚
â”‚  â€¢ åˆ†å¸ƒå¼çŠ¶æ€å­˜å‚¨ (Redis/etcd)                               â”‚
â”‚  â€¢ æŒä¹…åŒ–æ—¥å¿—                                                â”‚
â”‚  â€¢ å¿«ç…§ä¸å›æ”¾                                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  L-F: Monitoring & Observability (ç›‘æ§å¯è§‚æµ‹å±‚)              â”‚
â”‚  â€¢ æŒ‡æ ‡æ”¶é›†                                                  â”‚
â”‚  â€¢ æ—¥å¿—èšåˆ                                                  â”‚
â”‚  â€¢ å‘Šè­¦ç³»ç»Ÿ                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Layer A: Watchdog Layer (çœ‹é—¨ç‹—å±‚)

### è®¾è®¡åŸåˆ™
- **ç‹¬ç«‹æ€§**: ä¸è¢«ç›‘æ§ç³»ç»Ÿå®Œå…¨åˆ†ç¦»
- **è½»é‡çº§**: æœ€å°ä¾èµ–ï¼Œæä½èµ„æºå ç”¨
- **å¯é æ€§**: è‡ªèº«å…·å¤‡è‡ªæ„ˆèƒ½åŠ›

### å®ç°æ–¹æ¡ˆ

#### 1. ç³»ç»Ÿçº§Watchdog (systemd)
```ini
# /etc/systemd/system/synergymesh-watchdog.service
[Unit]
Description=SynergyMesh Watchdog Service
After=network.target

[Service]
Type=simple
ExecStart=/usr/local/bin/synergymesh_watchdog
Restart=always
RestartSec=10
User=synergymesh
StandardOutput=journal
StandardError=journal

# å¥åº·æ£€æŸ¥
WatchdogSec=30
NotifyAccess=main

[Install]
WantedBy=multi-user.target
```

#### 2. åº”ç”¨çº§Watchdog

```python
#!/usr/bin/env python3
"""
synergymesh_watchdog.py - çœ‹é—¨ç‹—å®ˆæŠ¤è¿›ç¨‹

èŒè´£ï¼š
1. ç›‘æ§æ‰€æœ‰å…³é”®è¿›ç¨‹ï¼ˆLauncherã€Orchestratorã€Enginesï¼‰
2. æ£€æµ‹å¼‚å¸¸å¹¶è‡ªåŠ¨æ¢å¤
3. è®°å½•æ‰€æœ‰æ¢å¤æ“ä½œ
4. å‘ç›‘æ§ç³»ç»Ÿå‘é€å¿ƒè·³
"""

import asyncio
import psutil
import subprocess
import time
from pathlib import Path
from datetime import datetime
import json
import signal
import sys

class ProcessWatchdog:
    """è¿›ç¨‹çœ‹é—¨ç‹—"""
    
    def __init__(self, config_path: str = "/etc/synergymesh/watchdog.json"):
        self.config = self._load_config(config_path)
        self.monitored_processes = {}
        self.recovery_count = {}
        self.running = False
        
        # æœ€å¤§æ¢å¤å°è¯•æ¬¡æ•°
        self.max_recovery_attempts = self.config.get("max_recovery_attempts", 3)
        self.recovery_window = self.config.get("recovery_window_seconds", 300)  # 5åˆ†é’Ÿ
    
    def _load_config(self, config_path: str) -> dict:
        """åŠ è½½é…ç½®"""
        default_config = {
            "check_interval": 10,
            "processes": [
                {
                    "name": "automation_launcher",
                    "command": ["python", "automation_launcher.py", "start"],
                    "cwd": "/opt/synergymesh",
                    "critical": True,
                    "restart_delay": 5
                },
                {
                    "name": "master_orchestrator",
                    "command": ["python", "-m", "master_orchestrator"],
                    "cwd": "/opt/synergymesh/tools/automation",
                    "critical": True,
                    "restart_delay": 3
                }
            ],
            "alerting": {
                "enabled": True,
                "webhook_url": None,
                "email": None
            }
        }
        
        try:
            with open(config_path, 'r') as f:
                loaded_config = json.load(f)
                default_config.update(loaded_config)
        except FileNotFoundError:
            print(f"âš ï¸  é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {config_path}")
        except Exception as e:
            print(f"âŒ åŠ è½½é…ç½®å¤±è´¥: {e}")
        
        return default_config
    
    def _check_process_health(self, process_name: str) -> tuple[bool, str]:
        """æ£€æŸ¥è¿›ç¨‹å¥åº·çŠ¶æ€"""
        # æ–¹æ³•1: æ£€æŸ¥è¿›ç¨‹æ˜¯å¦å­˜åœ¨
        for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
            try:
                cmdline = ' '.join(proc.info['cmdline'] or [])
                if process_name in cmdline:
                    # è¿›ç¨‹å­˜åœ¨ï¼Œæ£€æŸ¥æ˜¯å¦å“åº”
                    if proc.status() == psutil.STATUS_ZOMBIE:
                        return False, f"è¿›ç¨‹ {process_name} æˆä¸ºåƒµå°¸è¿›ç¨‹"
                    
                    # æ£€æŸ¥CPUä½¿ç”¨ç‡ï¼ˆå¯é€‰ï¼‰
                    cpu_percent = proc.cpu_percent(interval=1)
                    if cpu_percent > 95:
                        return False, f"è¿›ç¨‹ {process_name} CPUä½¿ç”¨ç‡å¼‚å¸¸: {cpu_percent}%"
                    
                    return True, "å¥åº·"
            except (psutil.NoSuchProcess, psutil.AccessDenied):
                continue
        
        return False, f"è¿›ç¨‹ {process_name} ä¸å­˜åœ¨"
    
    async def _recover_process(self, process_config: dict) -> bool:
        """æ¢å¤è¿›ç¨‹"""
        process_name = process_config["name"]
        
        # æ£€æŸ¥æ¢å¤æ¬¡æ•°é™åˆ¶
        current_time = time.time()
        if process_name not in self.recovery_count:
            self.recovery_count[process_name] = []
        
        # æ¸…ç†æ—§çš„æ¢å¤è®°å½•
        self.recovery_count[process_name] = [
            t for t in self.recovery_count[process_name]
            if current_time - t < self.recovery_window
        ]
        
        # æ£€æŸ¥æ˜¯å¦è¶…è¿‡æœ€å¤§å°è¯•æ¬¡æ•°
        if len(self.recovery_count[process_name]) >= self.max_recovery_attempts:
            print(f"âŒ è¿›ç¨‹ {process_name} æ¢å¤æ¬¡æ•°è¶…é™ï¼Œéœ€è¦äººå·¥ä»‹å…¥")
            await self._send_alert(
                f"CRITICAL: è¿›ç¨‹ {process_name} æ¢å¤å¤±è´¥è¶…è¿‡ {self.max_recovery_attempts} æ¬¡",
                severity="critical"
            )
            return False
        
        print(f"ğŸ”„ å°è¯•æ¢å¤è¿›ç¨‹: {process_name}")
        
        try:
            # æ€æ­»å¯èƒ½å­˜åœ¨çš„åƒµå°¸è¿›ç¨‹
            subprocess.run(["pkill", "-9", "-f", process_name], check=False)
            
            # ç­‰å¾…æ¸…ç†
            await asyncio.sleep(process_config.get("restart_delay", 5))
            
            # å¯åŠ¨è¿›ç¨‹
            cwd = process_config.get("cwd", ".")
            proc = subprocess.Popen(
                process_config["command"],
                cwd=cwd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                start_new_session=True  # åˆ›å»ºæ–°ä¼šè¯ç»„
            )
            
            # ç­‰å¾…å¯åŠ¨
            await asyncio.sleep(3)
            
            # éªŒè¯å¯åŠ¨
            if proc.poll() is None:  # è¿›ç¨‹ä»åœ¨è¿è¡Œ
                print(f"âœ… è¿›ç¨‹ {process_name} æ¢å¤æˆåŠŸ, PID: {proc.pid}")
                self.recovery_count[process_name].append(current_time)
                self.monitored_processes[process_name] = proc
                return True
            else:
                print(f"âŒ è¿›ç¨‹ {process_name} æ¢å¤å¤±è´¥ï¼Œç«‹å³é€€å‡º")
                return False
                
        except Exception as e:
            print(f"âŒ æ¢å¤è¿›ç¨‹ {process_name} æ—¶å‡ºé”™: {e}")
            return False
    
    async def _send_alert(self, message: str, severity: str = "warning"):
        """å‘é€å‘Šè­¦"""
        if not self.config["alerting"]["enabled"]:
            return
        
        alert_data = {
            "timestamp": datetime.now().isoformat(),
            "severity": severity,
            "message": message,
            "source": "SynergyMesh Watchdog"
        }
        
        print(f"ğŸš¨ å‘Šè­¦: [{severity.upper()}] {message}")
        
        # Webhooké€šçŸ¥
        webhook_url = self.config["alerting"].get("webhook_url")
        if webhook_url:
            try:
                import requests
                requests.post(webhook_url, json=alert_data, timeout=5)
            except Exception as e:
                print(f"âš ï¸  å‘é€webhookå‘Šè­¦å¤±è´¥: {e}")
        
        # Emailé€šçŸ¥ï¼ˆå¦‚æœé…ç½®ï¼‰
        # TODO: å®ç°emailé€šçŸ¥
    
    async def monitor_loop(self):
        """ä¸»ç›‘æ§å¾ªç¯"""
        check_interval = self.config.get("check_interval", 10)
        
        while self.running:
            for process_config in self.config["processes"]:
                process_name = process_config["name"]
                is_healthy, status_msg = self._check_process_health(process_name)
                
                if not is_healthy:
                    print(f"âš ï¸  æ£€æµ‹åˆ°è¿›ç¨‹å¼‚å¸¸: {process_name} - {status_msg}")
                    
                    if process_config.get("critical", False):
                        # å…³é”®è¿›ç¨‹ï¼Œç«‹å³æ¢å¤
                        recovery_success = await self._recover_process(process_config)
                        
                        if not recovery_success:
                            await self._send_alert(
                                f"å…³é”®è¿›ç¨‹ {process_name} æ¢å¤å¤±è´¥",
                                severity="critical"
                            )
                    else:
                        # éå…³é”®è¿›ç¨‹ï¼Œä»…å‘Šè­¦
                        await self._send_alert(
                            f"è¿›ç¨‹ {process_name} å¼‚å¸¸: {status_msg}",
                            severity="warning"
                        )
            
            await asyncio.sleep(check_interval)
    
    async def start(self):
        """å¯åŠ¨çœ‹é—¨ç‹—"""
        print("ğŸ• SynergyMesh Watchdog å¯åŠ¨ä¸­...")
        self.running = True
        
        # æ³¨å†Œä¿¡å·å¤„ç†
        signal.signal(signal.SIGTERM, self._signal_handler)
        signal.signal(signal.SIGINT, self._signal_handler)
        
        await self.monitor_loop()
    
    def _signal_handler(self, signum, frame):
        """ä¿¡å·å¤„ç†"""
        print(f"ğŸ›‘ æ”¶åˆ°ä¿¡å· {signum}ï¼Œå‡†å¤‡åœæ­¢...")
        self.running = False
    
    async def stop(self):
        """åœæ­¢çœ‹é—¨ç‹—"""
        self.running = False
        print("ğŸ›‘ Watchdog å·²åœæ­¢")

async def main():
    watchdog = ProcessWatchdog()
    await watchdog.start()

if __name__ == "__main__":
    asyncio.run(main())
```

---

## Layer B: Control Plane (æ§åˆ¶å¹³é¢)

### ä¸»å¤‡è°ƒåº¦å™¨è®¾è®¡

```python
"""
scheduler_ha.py - é«˜å¯ç”¨è°ƒåº¦å™¨

å®ç°ä¸»å¤‡æ¨¡å¼ï¼š
- ä¸»è°ƒåº¦å™¨å¤„ç†æ‰€æœ‰è¯·æ±‚
- å¤‡ç”¨è°ƒåº¦å™¨å®æ—¶åŒæ­¥çŠ¶æ€
- æ•…éšœæ—¶è‡ªåŠ¨åˆ‡æ¢
"""

import asyncio
import enum
from typing import Optional
import time

class SchedulerRole(enum.Enum):
    PRIMARY = "primary"
    STANDBY = "standby"
    UNKNOWN = "unknown"

class HAScheduler:
    """é«˜å¯ç”¨è°ƒåº¦å™¨"""
    
    def __init__(self, node_id: str, peers: list[str]):
        self.node_id = node_id
        self.peers = peers
        self.role = SchedulerRole.UNKNOWN
        
        # ä½¿ç”¨åˆ†å¸ƒå¼é”é€‰ä¸¾
        self.lock_service = None  # Redis/etcd
        self.heartbeat_interval = 5
        self.election_timeout = 15
        
        self.last_heartbeat = time.time()
    
    async def start_election(self):
        """å¯åŠ¨é€‰ä¸¾"""
        print(f"[{self.node_id}] å¼€å§‹é€‰ä¸¾...")
        
        # å°è¯•è·å–åˆ†å¸ƒå¼é”
        acquired = await self.lock_service.try_acquire(
            key="scheduler_primary_lock",
            ttl=self.election_timeout,
            node_id=self.node_id
        )
        
        if acquired:
            self.role = SchedulerRole.PRIMARY
            print(f"âœ… [{self.node_id}] æˆä¸ºä¸»è°ƒåº¦å™¨")
            asyncio.create_task(self.primary_loop())
        else:
            self.role = SchedulerRole.STANDBY
            print(f"â¸ï¸  [{self.node_id}] æˆä¸ºå¤‡ç”¨è°ƒåº¦å™¨")
            asyncio.create_task(self.standby_loop())
    
    async def primary_loop(self):
        """ä¸»è°ƒåº¦å™¨å¾ªç¯"""
        while self.role == SchedulerRole.PRIMARY:
            try:
                # ç»­çº¦é”
                await self.lock_service.renew_lock(
                    key="scheduler_primary_lock",
                    node_id=self.node_id
                )
                
                # å‘é€å¿ƒè·³
                await self.broadcast_heartbeat()
                
                # æ‰§è¡Œè°ƒåº¦ä»»åŠ¡
                await self.schedule_tasks()
                
                await asyncio.sleep(self.heartbeat_interval)
            except Exception as e:
                print(f"âŒ ä¸»è°ƒåº¦å™¨å¼‚å¸¸: {e}")
                # é‡Šæ”¾é”ï¼Œè§¦å‘é‡æ–°é€‰ä¸¾
                await self.lock_service.release_lock(
                    key="scheduler_primary_lock",
                    node_id=self.node_id
                )
                self.role = SchedulerRole.UNKNOWN
                await self.start_election()
    
    async def standby_loop(self):
        """å¤‡ç”¨è°ƒåº¦å™¨å¾ªç¯"""
        while self.role == SchedulerRole.STANDBY:
            try:
                # ç›‘å¬ä¸»è°ƒåº¦å™¨å¿ƒè·³
                heartbeat_received = await self.check_primary_heartbeat()
                
                if not heartbeat_received:
                    print(f"âš ï¸  [{self.node_id}] ä¸»è°ƒåº¦å™¨å¿ƒè·³è¶…æ—¶ï¼Œè§¦å‘é€‰ä¸¾")
                    await self.start_election()
                    break
                
                # åŒæ­¥çŠ¶æ€ï¼ˆè¢«åŠ¨å¤åˆ¶ï¼‰
                await self.sync_state_from_primary()
                
                await asyncio.sleep(self.heartbeat_interval)
            except Exception as e:
                print(f"âŒ å¤‡ç”¨è°ƒåº¦å™¨å¼‚å¸¸: {e}")
    
    async def schedule_tasks(self):
        """è°ƒåº¦ä»»åŠ¡ï¼ˆä»…ä¸»è°ƒåº¦å™¨ï¼‰"""
        # å®ç°ä»»åŠ¡è°ƒåº¦é€»è¾‘
        pass
    
    async def broadcast_heartbeat(self):
        """å¹¿æ’­å¿ƒè·³"""
        self.last_heartbeat = time.time()
        # å‘æ‰€æœ‰peerå‘é€å¿ƒè·³
        pass
    
    async def check_primary_heartbeat(self) -> bool:
        """æ£€æŸ¥ä¸»è°ƒåº¦å™¨å¿ƒè·³"""
        # æ£€æŸ¥æ˜¯å¦æ”¶åˆ°ä¸»è°ƒåº¦å™¨å¿ƒè·³
        time_since_heartbeat = time.time() - self.last_heartbeat
        return time_since_heartbeat < self.election_timeout
    
    async def sync_state_from_primary(self):
        """ä»ä¸»è°ƒåº¦å™¨åŒæ­¥çŠ¶æ€"""
        # å®ç°çŠ¶æ€åŒæ­¥
        pass
```

---

## Layer C: Orchestration Layer (ç¼–æ’å±‚)

### åˆ†å¸ƒå¼Orchestrator

```python
"""
distributed_orchestrator.py - åˆ†å¸ƒå¼ç¼–æ’å™¨

ç‰¹æ€§ï¼š
1. å¯æ°´å¹³æ‰©å±•ï¼ˆå¤šå®ä¾‹ï¼‰
2. ä»»åŠ¡åˆ†ç‰‡
3. å¤±è´¥è‡ªåŠ¨è½¬ç§»
"""

class DistributedOrchestrator:
    """åˆ†å¸ƒå¼ç¼–æ’å™¨"""
    
    def __init__(self, instance_id: str, cluster_config: dict):
        self.instance_id = instance_id
        self.cluster = cluster_config
        
        # ä»»åŠ¡åˆ†ç‰‡ç­–ç•¥
        self.shard_count = cluster_config.get("shard_count", 16)
        self.my_shards = self._calculate_my_shards()
        
        # å¼•æ“æ³¨å†Œè¡¨ï¼ˆåˆ†å¸ƒå¼ï¼‰
        self.registry = DistributedRegistry(
            backend="redis",
            cluster_nodes=cluster_config["redis_nodes"]
        )
    
    def _calculate_my_shards(self) -> set[int]:
        """è®¡ç®—æœ¬å®ä¾‹è´Ÿè´£çš„åˆ†ç‰‡"""
        total_instances = len(self.cluster["instances"])
        instance_index = self.cluster["instances"].index(self.instance_id)
        
        shards = set()
        for shard_id in range(self.shard_count):
            if shard_id % total_instances == instance_index:
                shards.add(shard_id)
        
        return shards
    
    async def handle_engine_registration(self, engine_id: str, engine_info: dict):
        """å¤„ç†å¼•æ“æ³¨å†Œ"""
        # è®¡ç®—å¼•æ“æ‰€å±åˆ†ç‰‡
        shard_id = hash(engine_id) % self.shard_count
        
        if shard_id in self.my_shards:
            # æœ¬å®ä¾‹è´Ÿè´£æ­¤å¼•æ“
            await self.registry.register_engine(engine_id, engine_info)
            print(f"âœ… [{self.instance_id}] æ³¨å†Œå¼•æ“: {engine_id} (shard {shard_id})")
        else:
            # è½¬å‘åˆ°è´Ÿè´£çš„å®ä¾‹
            responsible_instance = self._get_responsible_instance(shard_id)
            await self._forward_registration(responsible_instance, engine_id, engine_info)
    
    def _get_responsible_instance(self, shard_id: int) -> str:
        """è·å–è´Ÿè´£æŒ‡å®šåˆ†ç‰‡çš„å®ä¾‹"""
        total_instances = len(self.cluster["instances"])
        instance_index = shard_id % total_instances
        return self.cluster["instances"][instance_index]
    
    async def _forward_registration(self, target_instance: str, engine_id: str, engine_info: dict):
        """è½¬å‘æ³¨å†Œè¯·æ±‚åˆ°å…¶ä»–å®ä¾‹"""
        # å®ç°è·¨å®ä¾‹é€šä¿¡
        pass
```

---

## Layer E: State Management (çŠ¶æ€ç®¡ç†å±‚)

### åˆ†å¸ƒå¼çŠ¶æ€å­˜å‚¨

```python
"""
state_manager.py - åˆ†å¸ƒå¼çŠ¶æ€ç®¡ç†

ä½¿ç”¨Redis/etcdå®ç°ï¼š
1. çŠ¶æ€æŒä¹…åŒ–
2. äº‹ä»¶æº¯æº
3. å¿«ç…§ä¸æ¢å¤
"""

class StateManager:
    """çŠ¶æ€ç®¡ç†å™¨"""
    
    def __init__(self, backend="redis", connection_config: dict = None):
        self.backend = backend
        
        if backend == "redis":
            import redis
            self.client = redis.Redis(**connection_config)
        elif backend == "etcd":
            import etcd3
            self.client = etcd3.client(**connection_config)
    
    async def save_state(self, key: str, state: dict):
        """ä¿å­˜çŠ¶æ€"""
        # åºåˆ—åŒ–çŠ¶æ€
        import json
        state_json = json.dumps(state)
        
        # ä¿å­˜åˆ°åç«¯
        self.client.set(key, state_json)
        
        # è®°å½•äº‹ä»¶æ—¥å¿—ï¼ˆç”¨äºé‡æ”¾ï¼‰
        event = {
            "timestamp": time.time(),
            "action": "state_update",
            "key": key,
            "state": state
        }
        self.client.lpush(f"events:{key}", json.dumps(event))
    
    async def load_state(self, key: str) -> Optional[dict]:
        """åŠ è½½çŠ¶æ€"""
        import json
        state_json = self.client.get(key)
        
        if state_json:
            return json.loads(state_json)
        return None
    
    async def replay_events(self, key: str, from_timestamp: float = 0):
        """é‡æ”¾äº‹ä»¶ï¼ˆæ¢å¤çŠ¶æ€ï¼‰"""
        import json
        events = self.client.lrange(f"events:{key}", 0, -1)
        
        state = {}
        for event_json in events:
            event = json.loads(event_json)
            if event["timestamp"] >= from_timestamp:
                # é‡æ”¾äº‹ä»¶
                state.update(event["state"])
        
        return state
    
    async def create_snapshot(self, prefix: str = ""):
        """åˆ›å»ºå¿«ç…§"""
        import json
        snapshot = {
            "timestamp": time.time(),
            "states": {}
        }
        
        # è·å–æ‰€æœ‰çŠ¶æ€
        keys = self.client.keys(f"{prefix}*")
        for key in keys:
            if not key.startswith(b"events:"):
                state_json = self.client.get(key)
                if state_json:
                    snapshot["states"][key.decode()] = json.loads(state_json)
        
        # ä¿å­˜å¿«ç…§
        snapshot_key = f"snapshot:{prefix}:{time.time()}"
        self.client.set(snapshot_key, json.dumps(snapshot))
        
        print(f"ğŸ“¸ åˆ›å»ºå¿«ç…§: {snapshot_key}")
        return snapshot_key
```

---

## å®Œæ•´æ¶æ„å®ç°ç¤ºä¾‹

### å¯åŠ¨è„šæœ¬ (é‡æ„å)

```python
#!/usr/bin/env python3
"""
synergymesh_cluster.py - é›†ç¾¤å¯åŠ¨è„šæœ¬

å¯åŠ¨å®Œæ•´çš„é«˜å¯ç”¨é›†ç¾¤ï¼š
1. Watchdog
2. State Manager
3. HA Scheduler (ä¸»å¤‡)
4. Distributed Orchestrators
5. Engines
"""

import asyncio
import argparse
from typing import List

class SynergyMeshCluster:
    """SynergyMesh é›†ç¾¤ç®¡ç†å™¨"""
    
    def __init__(self, config_path: str):
        self.config = self._load_config(config_path)
        self.components = {}
    
    async def start_watchdog(self):
        """å¯åŠ¨Watchdog"""
        from synergymesh_watchdog import ProcessWatchdog
        
        watchdog = ProcessWatchdog(self.config["watchdog"])
        self.components["watchdog"] = watchdog
        
        asyncio.create_task(watchdog.start())
        print("âœ… Watchdog å·²å¯åŠ¨")
    
    async def start_state_manager(self):
        """å¯åŠ¨çŠ¶æ€ç®¡ç†å™¨"""
        from state_manager import StateManager
        
        state_mgr = StateManager(
            backend=self.config["state"]["backend"],
            connection_config=self.config["state"]["connection"]
        )
        self.components["state_manager"] = state_mgr
        
        print("âœ… State Manager å·²å¯åŠ¨")
    
    async def start_schedulers(self):
        """å¯åŠ¨HAè°ƒåº¦å™¨"""
        from scheduler_ha import HAScheduler
        
        node_id = self.config["scheduler"]["node_id"]
        peers = self.config["scheduler"]["peers"]
        
        scheduler = HAScheduler(node_id, peers)
        self.components["scheduler"] = scheduler
        
        await scheduler.start_election()
        print(f"âœ… Scheduler å·²å¯åŠ¨ (node: {node_id})")
    
    async def start_orchestrators(self):
        """å¯åŠ¨åˆ†å¸ƒå¼Orchestrator"""
        from distributed_orchestrator import DistributedOrchestrator
        
        instance_id = self.config["orchestrator"]["instance_id"]
        cluster_config = self.config["orchestrator"]["cluster"]
        
        orchestrator = DistributedOrchestrator(instance_id, cluster_config)
        self.components["orchestrator"] = orchestrator
        
        await orchestrator.start()
        print(f"âœ… Orchestrator å·²å¯åŠ¨ (instance: {instance_id})")
    
    async def start_all(self):
        """å¯åŠ¨æ‰€æœ‰ç»„ä»¶"""
        print("ğŸš€ SynergyMesh é›†ç¾¤å¯åŠ¨ä¸­...")
        print("=" * 60)
        
        # æŒ‰é¡ºåºå¯åŠ¨å„å±‚
        await self.start_watchdog()
        await self.start_state_manager()
        await self.start_schedulers()
        await self.start_orchestrators()
        
        print("=" * 60)
        print("ğŸ‰ SynergyMesh é›†ç¾¤å¯åŠ¨å®Œæˆï¼")
        
        # ä¿æŒè¿è¡Œ
        try:
            while True:
                await asyncio.sleep(60)
                await self._health_check()
        except KeyboardInterrupt:
            await self.stop_all()
    
    async def _health_check(self):
        """é›†ç¾¤å¥åº·æ£€æŸ¥"""
        # å®ç°å¥åº·æ£€æŸ¥é€»è¾‘
        pass
    
    async def stop_all(self):
        """åœæ­¢æ‰€æœ‰ç»„ä»¶"""
        print("\nğŸ›‘ åœæ­¢é›†ç¾¤...")
        
        for name, component in self.components.items():
            if hasattr(component, 'stop'):
                await component.stop()
                print(f"  âœ“ {name} å·²åœæ­¢")

async def main():
    parser = argparse.ArgumentParser(description="SynergyMesh é›†ç¾¤ç®¡ç†")
    parser.add_argument("--config", default="/etc/synergymesh/cluster.json", help="é…ç½®æ–‡ä»¶è·¯å¾„")
    args = parser.parse_args()
    
    cluster = SynergyMeshCluster(args.config)
    await cluster.start_all()

if __name__ == "__main__":
    asyncio.run(main())
```

---

## éƒ¨ç½²é…ç½®

### Docker Compose (é«˜å¯ç”¨)

```yaml
version: '3.8'

services:
  # Redis - çŠ¶æ€å­˜å‚¨
  redis:
    image: redis:7-alpine
    command: redis-server --appendonly yes
    volumes:
      - redis-data:/data
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 3

  # Watchdog (ä¸»)
  watchdog-primary:
    build: .
    command: python synergymesh_watchdog.py
    environment:
      - NODE_ID=watchdog-1
      - REDIS_URL=redis://redis:6379
    depends_on:
      - redis
    restart: unless-stopped

  # Scheduler (ä¸»)
  scheduler-primary:
    build: .
    command: python scheduler_ha.py --role primary
    environment:
      - NODE_ID=scheduler-1
      - REDIS_URL=redis://redis:6379
      - PEERS=scheduler-2,scheduler-3
    depends_on:
      - redis
    restart: unless-stopped

  # Scheduler (å¤‡1)
  scheduler-standby-1:
    build: .
    command: python scheduler_ha.py --role standby
    environment:
      - NODE_ID=scheduler-2
      - REDIS_URL=redis://redis:6379
      - PEERS=scheduler-1,scheduler-3
    depends_on:
      - redis
    restart: unless-stopped

  # Orchestrator (å®ä¾‹1)
  orchestrator-1:
    build: .
    command: python distributed_orchestrator.py --instance-id orch-1
    environment:
      - INSTANCE_ID=orch-1
      - REDIS_URL=redis://redis:6379
      - CLUSTER_INSTANCES=orch-1,orch-2,orch-3
    depends_on:
      - redis
      - scheduler-primary
    restart: unless-stopped

  # Orchestrator (å®ä¾‹2)
  orchestrator-2:
    build: .
    command: python distributed_orchestrator.py --instance-id orch-2
    environment:
      - INSTANCE_ID=orch-2
      - REDIS_URL=redis://redis:6379
      - CLUSTER_INSTANCES=orch-1,orch-2,orch-3
    depends_on:
      - redis
      - scheduler-primary
    restart: unless-stopped

  # Orchestrator (å®ä¾‹3)
  orchestrator-3:
    build: .
    command: python distributed_orchestrator.py --instance-id orch-3
    environment:
      - INSTANCE_ID=orch-3
      - REDIS_URL=redis://redis:6379
      - CLUSTER_INSTANCES=orch-1,orch-2,orch-3
    depends_on:
      - redis
      - scheduler-primary
    restart: unless-stopped

  # Prometheus - ç›‘æ§
  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    ports:
      - "9090:9090"
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'

  # Grafana - å¯è§†åŒ–
  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana-data:/var/lib/grafana

volumes:
  redis-data:
  prometheus-data:
  grafana-data:
```

---

## Kubernetes éƒ¨ç½² (ç”Ÿäº§çº§)

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: synergymesh-config
data:
  cluster.json: |
    {
      "watchdog": {
        "check_interval": 10,
        "max_recovery_attempts": 3
      },
      "scheduler": {
        "election_timeout": 15,
        "heartbeat_interval": 5
      },
      "orchestrator": {
        "shard_count": 16,
        "health_check_interval": 30
      },
      "state": {
        "backend": "redis",
        "connection": {
          "host": "redis-service",
          "port": 6379
        }
      }
    }

---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: synergymesh-scheduler
spec:
  serviceName: scheduler
  replicas: 3
  selector:
    matchLabels:
      app: synergymesh-scheduler
  template:
    metadata:
      labels:
        app: synergymesh-scheduler
    spec:
      containers:
      - name: scheduler
        image: synergymesh/scheduler:latest
        env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: REDIS_URL
          value: "redis://redis-service:6379"
        volumeMounts:
        - name: config
          mountPath: /etc/synergymesh
        livenessProbe:
          httpGet:
            path: /healthz
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
      volumes:
      - name: config
        configMap:
          name: synergymesh-config

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: synergymesh-orchestrator
spec:
  replicas: 3
  selector:
    matchLabels:
      app: synergymesh-orchestrator
  template:
    metadata:
      labels:
        app: synergymesh-orchestrator
    spec:
      containers:
      - name: orchestrator
        image: synergymesh/orchestrator:latest
        env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: REDIS_URL
          value: "redis://redis-service:6379"
        resources:
          requests:
            cpu: 100m
            memory: 256Mi
          limits:
            cpu: 500m
            memory: 512Mi
        livenessProbe:
          httpGet:
            path: /healthz
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10

---
apiVersion: v1
kind: Service
metadata:
  name: orchestrator-service
spec:
  selector:
    app: synergymesh-orchestrator
  ports:
  - protocol: TCP
    port: 8080
    targetPort: 8080
  type: ClusterIP
```

---

## å¯¹æ¯”: æ”¹è¿›å‰ vs æ”¹è¿›å

| ç‰¹æ€§ | æ”¹è¿›å‰ | æ”¹è¿›å |
|------|--------|--------|
| **å•ç‚¹æ•…éšœ** | âŒ Launcheræ˜¯å•ç‚¹ | âœ… æ— å•ç‚¹ï¼Œæ‰€æœ‰å±‚éƒ½å†—ä½™ |
| **è‡ªåŠ¨æ¢å¤** | âŒ æ‰‹åŠ¨æ¢å¤ | âœ… Watchdogè‡ªåŠ¨æ¢å¤ |
| **æ°´å¹³æ‰©å±•** | âŒ æ— æ³•æ‰©å±• | âœ… Orchestratorå¯æ‰©å±• |
| **çŠ¶æ€æŒä¹…åŒ–** | âŒ å†…å­˜çŠ¶æ€ | âœ… Redis/etcdæŒä¹…åŒ– |
| **æ•…éšœè½¬ç§»** | âŒ æ—  | âœ… ä¸»å¤‡è‡ªåŠ¨åˆ‡æ¢ |
| **ç›‘æ§å‘Šè­¦** | âš ï¸  åŸºç¡€æ—¥å¿— | âœ… Prometheus + Grafana |
| **éƒ¨ç½²å¤æ‚åº¦** | ğŸŸ¢ ç®€å• | ğŸŸ¡ ä¸­ç­‰ï¼ˆæœ‰å·¥å…·æ”¯æŒï¼‰ |
| **è¿ç»´æˆæœ¬** | ğŸ”´ é«˜ï¼ˆéœ€äººå·¥ä»‹å…¥ï¼‰ | ğŸŸ¢ ä½ï¼ˆè‡ªåŠ¨åŒ–ï¼‰ |

---

## å®æ–½è·¯çº¿å›¾

### Phase 1: åº”æ€¥æªæ–½ (ç«‹å³)
- âœ… éƒ¨ç½² `emergency_recovery.py`
- âœ… åˆ›å»º `RECOVERY_PLAYBOOK.md`
- âœ… å»ºç«‹ç›‘æ§å‘Šè­¦

### Phase 2: Watchdogå±‚ (1-2å‘¨)
- â¬œ å®ç°ç³»ç»Ÿçº§Watchdog
- â¬œ é›†æˆsystemdæœåŠ¡
- â¬œ æµ‹è¯•è‡ªåŠ¨æ¢å¤

### Phase 3: æ§åˆ¶å¹³é¢ (2-3å‘¨)
- â¬œ å®ç°ä¸»å¤‡è°ƒåº¦å™¨
- â¬œ åˆ†å¸ƒå¼é”æœºåˆ¶
- â¬œ æ•…éšœè½¬ç§»æµ‹è¯•

### Phase 4: åˆ†å¸ƒå¼ç¼–æ’ (3-4å‘¨)
- â¬œ Orchestratoråˆ†ç‰‡
- â¬œ ä»»åŠ¡åˆ†å‘ä¼˜åŒ–
- â¬œ è´Ÿè½½å‡è¡¡

### Phase 5: çŠ¶æ€ç®¡ç† (2å‘¨)
- â¬œ Redis/etcdé›†æˆ
- â¬œ äº‹ä»¶æº¯æº
- â¬œ å¿«ç…§ä¸æ¢å¤

### Phase 6: ç”Ÿäº§éƒ¨ç½² (1-2å‘¨)
- â¬œ DockeråŒ–
- â¬œ Kubernetesç¼–æ’
- â¬œ ç›‘æ§ä¸å¯è§‚æµ‹æ€§

---

## æ€»ç»“

**å…³é”®æ”¹è¿›**:
1. **é›¶å•ç‚¹æ•…éšœ**: æ‰€æœ‰ç»„ä»¶éƒ½æœ‰å†—ä½™
2. **è‡ªåŠ¨æ•…éšœæ¢å¤**: Watchdog + ä¸»å¤‡åˆ‡æ¢
3. **æ°´å¹³å¯æ‰©å±•**: Orchestratorå¯å¤šå®ä¾‹è¿è¡Œ
4. **çŠ¶æ€æŒä¹…åŒ–**: ä¸å†ä¾èµ–å†…å­˜çŠ¶æ€
5. **äº‘åŸç”Ÿ**: æ”¯æŒK8séƒ¨ç½²

**ç«‹å³å¯ç”¨**:
- `emergency_recovery.py` - ç°åœ¨å°±å¯ä»¥ç”¨ä½œåº”æ€¥æ–¹æ¡ˆ
- `RECOVERY_PLAYBOOK.md` - æ ‡å‡†åŒ–æ¢å¤æµç¨‹

**é•¿æœŸæ¶æ„**:
- å…­å±‚é˜²å¾¡ä½“ç³»
- ç¬¦åˆä½ çš„AXIOMç³»ç»Ÿç†å¿µ
- ä¼ä¸šçº§å¯é æ€§

---

**ä¸‹ä¸€æ­¥å»ºè®®**:
1. ç«‹å³éƒ¨ç½²åº”æ€¥æ¢å¤è„šæœ¬
2. æµ‹è¯•å½“å‰ç³»ç»Ÿçš„æ¢å¤èƒ½åŠ›
3. åˆ¶å®šè¯¦ç»†çš„è¿ç§»è®¡åˆ’
4. é€æ­¥å®æ–½æ¶æ„æ”¹è¿›

éœ€è¦æˆ‘è¯¦ç»†å±•å¼€ä»»ä½•ä¸€ä¸ªéƒ¨åˆ†å—?
