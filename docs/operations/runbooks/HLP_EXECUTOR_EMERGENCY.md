# HLP Executor ç·Šæ€¥æ‡‰è®Šæ‰‹å†Š | HLP Executor Emergency Runbook

**æ–‡ä»¶ç‰ˆæœ¬ | Document Version**: 1.0.0  
**æœ€å¾Œæ›´æ–° | Last Updated**: 2025-12-07  
**è² è²¬åœ˜éšŠ | Responsible Team**: SRE / Incident Response  
**ç·Šæ€¥è¯çµ¡ | Emergency Contact**: PagerDuty Service ID: P1234

---

## ğŸ“‹ æ–‡ä»¶ç›®çš„ | Document Purpose

æœ¬æ–‡ä»¶å®šç¾© HLP Executor çš„ç·Šæ€¥æ‡‰è®Šç¨‹åºï¼ŒåŒ…å« P1/P2 ç´šåˆ¥äº‹ä»¶çš„ç—‡ç‹€è­˜åˆ¥ã€è¨ºæ–·æ­¥é©Ÿã€æ¢å¾©æªæ–½å’Œå‡ç´šè·¯å¾‘ã€‚

This document defines emergency response procedures for HLP Executor, including symptom identification, diagnostic steps, recovery actions, and escalation paths for P1/P2 incidents.

---

## ğŸš¨ ç·Šæ€¥ç­‰ç´šå®šç¾© | Emergency Level Definitions

| ç­‰ç´š | åç¨± | å®šç¾© | éŸ¿æ‡‰æ™‚é–“ | æ¢å¾©ç›®æ¨™ (RTO) |
|------|------|------|----------|----------------|
| **P1** | Critical | æœå‹™å®Œå…¨ä¸­æ–· | < 5 åˆ†é˜ | < 30 ç§’ |
| **P2** | High | æœå‹™åŠŸèƒ½å—æ | < 15 åˆ†é˜ | < 5 åˆ†é˜ |
| **P3** | Medium | æœå‹™æ€§èƒ½ä¸‹é™ | < 1 å°æ™‚ | < 30 åˆ†é˜ |
| **P4** | Low | è¼•å¾®å•é¡Œ | < 4 å°æ™‚ | < 2 å°æ™‚ |

---

## ğŸ”´ P1: executor-core-down (æ‰€æœ‰å‰¯æœ¬ä¸å¥åº· | All Replicas Unhealthy)

### âš ï¸ åš´é‡æ€§æ¨™è­˜ | Severity Indicators

```
ğŸš¨ CRITICAL - P1 INCIDENT
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
æœå‹™ç‹€æ…‹ | Service Status: DOWN
å½±éŸ¿ç¯„åœ | Impact: 100% (æ‰€æœ‰ HLP åŸ·è¡Œåœæ­¢)
æª¢æ¸¬æ™‚é–“ | Detected: <TIMESTAMP>
éŸ¿æ‡‰åœ˜éšŠ | Response Team: On-Call SRE
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

### ğŸ¯ ç—‡ç‹€è­˜åˆ¥ | Symptom Identification

#### è‡ªå‹•æª¢æ¸¬ | Automatic Detection
```yaml
alerting_rules:
  - alert: HLPExecutorAllReplicasDown
    expr: |
      sum(up{job="hlp-executor-core"}) == 0
    for: 1m
    severity: P1
    annotations:
      summary: "All HLP Executor replicas are down"
      description: "All {{ $labels.namespace }}/{{ $labels.deployment }} replicas are unhealthy"
```

#### æ˜é¡¯ç—‡ç‹€ | Observable Symptoms
- âŒ æ‰€æœ‰ `/healthz` ç«¯é»è¿”å› 503 æˆ–ç„¡å›æ‡‰ | All `/healthz` endpoints return 503 or no response
- âŒ Prometheus é¡¯ç¤º 0 å€‹å¥åº·å‰¯æœ¬ | Prometheus shows 0 healthy replicas
- âŒ kubectl é¡¯ç¤ºæ‰€æœ‰ Pod è™•æ–¼ CrashLoopBackOffã€Error æˆ– Pending ç‹€æ…‹
- âŒ ç”¨æˆ¶å ±å‘Šç„¡æ³•æäº¤æ–°çš„ HLP åŸ·è¡Œ | Users report inability to submit new HLP executions
- âŒ ç›£æ§å„€è¡¨æ¿é¡¯ç¤ºæœå‹™å®Œå…¨é›¢ç·š | Monitoring dashboard shows service completely offline

#### æ¥­å‹™å½±éŸ¿ | Business Impact
- ğŸš« æ‰€æœ‰æ–°çš„ HLP åŸ·è¡Œè«‹æ±‚è¢«æ‹’çµ• | All new HLP execution requests rejected
- ğŸš« é€²è¡Œä¸­çš„åŸ·è¡Œå¯èƒ½ä¸­æ–· | In-progress executions may be interrupted
- ğŸš« ç‹€æ…‹åŒæ­¥åœæ­¢ | State synchronization stopped
- ğŸ“‰ SLO é•å: Availability < 99.9% | SLO violation: Availability < 99.9%

### ğŸ” è¨ºæ–·æ­¥é©Ÿ | Diagnostic Steps

#### ç¬¬ä¸€æ­¥ï¼šå¿«é€Ÿç‹€æ…‹æª¢æŸ¥ (< 30 ç§’)
```bash
# 1. Check pod status
kubectl get pods -n unmanned-island-system -l app=hlp-executor-core

# 2. Quick event check
kubectl get events -n unmanned-island-system --sort-by='.lastTimestamp' | grep hlp-executor | tail -10

# 3. Check deployment status
kubectl describe deployment hlp-executor-core -n unmanned-island-system | tail -30

# Expected output analysis:
# - All pods in CrashLoopBackOff â†’ Application crash (proceed to Step 2)
# - All pods in Pending â†’ Resource/scheduling issue (proceed to Step 3)
# - All pods in Error â†’ Configuration issue (proceed to Step 4)
```

#### ç¬¬äºŒæ­¥ï¼šæ‡‰ç”¨å±¤è¨ºæ–· (å¦‚æœ Pod CrashLoopBackOff)
```bash
# 1. Get recent logs from crashed pods
kubectl logs -n unmanned-island-system -l app=hlp-executor-core --tail=200 --all-containers

# 2. Check for common crash patterns
kubectl logs -n unmanned-island-system -l app=hlp-executor-core --tail=500 | \
  grep -E "(FATAL|panic|segfault|OOMKilled|Error:|Exception:)"

# 3. Check previous container logs
for pod in $(kubectl get pods -n unmanned-island-system -l app=hlp-executor-core -o name); do
  echo "=== Previous logs for $pod ==="
  kubectl logs -n unmanned-island-system $pod --previous --tail=100 2>/dev/null || echo "No previous logs"
done

# Common crash reasons to look for:
# - "cannot connect to database" â†’ Database connectivity issue
# - "failed to load configuration" â†’ ConfigMap/Secret issue
# - "OOMKilled" â†’ Memory limit too low
# - "certificate verification failed" â†’ TLS/certificate issue
```

#### ç¬¬ä¸‰æ­¥ï¼šè³‡æºå±¤è¨ºæ–· (å¦‚æœ Pod Pending)
```bash
# 1. Check node resources
kubectl top nodes

# 2. Check pod resource requests
kubectl describe pod -n unmanned-island-system -l app=hlp-executor-core | \
  grep -A 5 "Requests:"

# 3. Check scheduler events
kubectl get events -n unmanned-island-system --field-selector involvedObject.kind=Pod | \
  grep -E "(FailedScheduling|Insufficient)"

# 4. Check PVC binding
kubectl get pvc -n unmanned-island-system hlp-executor-state-pvc

# Common reasons:
# - Insufficient CPU/memory on nodes
# - PVC not bound
# - Affinity/anti-affinity rules blocking scheduling
# - Node selector/taint issues
```

#### ç¬¬å››æ­¥ï¼šé…ç½®å±¤è¨ºæ–· (å¦‚æœ Pod Error)
```bash
# 1. Check ConfigMap
kubectl get configmap hlp-executor-config -n unmanned-island-system -o yaml

# 2. Check Secret exists and is valid
kubectl get secret hlp-executor-secrets -n unmanned-island-system

# 3. Verify RBAC
kubectl auth can-i --list --as=system:serviceaccount:unmanned-island-system:hlp-executor-sa

# 4. Check image pull
kubectl describe pod -n unmanned-island-system -l app=hlp-executor-core | \
  grep -E "(Image|ImagePull)"

# Common issues:
# - ConfigMap missing or malformed
# - Secret missing or invalid
# - RBAC permissions insufficient
# - Image pull errors (ImagePullBackOff)
```

### ğŸ› ï¸ æ¢å¾©æªæ–½ | Recovery Actions

#### æ¢å¾©è·¯å¾‘ A: å¿«é€Ÿé‡å•Ÿ (æ‡‰ç”¨å±¤å•é¡Œ)
**ä½¿ç”¨å ´æ™¯**: æš«æ™‚æ€§æ‡‰ç”¨å´©æ½°ï¼Œé…ç½®æ­£ç¢º | Transient application crash, configuration correct

```bash
# Step 1: Force restart all pods
kubectl rollout restart deployment/hlp-executor-core -n unmanned-island-system

# Step 2: Monitor rollout progress (wait up to 60 seconds)
kubectl rollout status deployment/hlp-executor-core -n unmanned-island-system --timeout=60s

# Step 3: Verify health
kubectl get pods -n unmanned-island-system -l app=hlp-executor-core
kubectl exec -it deployment/hlp-executor-core -n unmanned-island-system -- \
  curl -f http://localhost:8080/healthz

# Step 4: Verify service is accepting requests
kubectl exec -it deployment/hlp-executor-core -n unmanned-island-system -- \
  curl -f http://localhost:8080/status

# Expected recovery time: 30-60 seconds
```

#### æ¢å¾©è·¯å¾‘ B: é…ç½®ä¿®å¾© (é…ç½®å•é¡Œ)
**ä½¿ç”¨å ´æ™¯**: ConfigMap/Secret éŒ¯èª¤æˆ–éºå¤± | ConfigMap/Secret errors or missing

```bash
# Step 1: Backup current configuration
kubectl get configmap hlp-executor-config -n unmanned-island-system -o yaml > /tmp/hlp-executor-config-backup.yaml

# Step 2: Restore from known-good configuration
kubectl apply -f infrastructure/kubernetes/config/hlp-executor-config.yaml

# Step 3: Verify configuration is valid
kubectl get configmap hlp-executor-config -n unmanned-island-system -o yaml | \
  python3 -m yaml.tool  # Syntax check

# Step 4: Restart pods to pick up new configuration
kubectl rollout restart deployment/hlp-executor-core -n unmanned-island-system

# Step 5: Monitor recovery
kubectl logs -n unmanned-island-system -l app=hlp-executor-core -f --tail=50

# Expected recovery time: 1-2 minutes
```

#### æ¢å¾©è·¯å¾‘ C: è³‡æºèª¿æ•´ (è³‡æºä¸è¶³)
**ä½¿ç”¨å ´æ™¯**: ç¯€é»è³‡æºä¸è¶³ï¼ŒPod ç„¡æ³•èª¿åº¦ | Insufficient node resources, pods cannot be scheduled

```bash
# Step 1: Reduce resource requests temporarily (emergency only!)
kubectl patch deployment hlp-executor-core -n unmanned-island-system -p '
{
  "spec": {
    "template": {
      "spec": {
        "containers": [
          {
            "name": "executor",
            "resources": {
              "requests": {
                "cpu": "250m",
                "memory": "256Mi"
              }
            }
          }
        ]
      }
    }
  }
}'

# Step 2: Scale down replicas temporarily if needed
kubectl scale deployment hlp-executor-core -n unmanned-island-system --replicas=1

# Step 3: Wait for pod to schedule
kubectl wait --for=condition=Ready pod -l app=hlp-executor-core -n unmanned-island-system --timeout=120s

# Step 4: Verify service is functional
kubectl exec -it deployment/hlp-executor-core -n unmanned-island-system -- \
  curl -f http://localhost:8080/healthz

# âš ï¸ IMPORTANT: Scale back up once stable
kubectl scale deployment hlp-executor-core -n unmanned-island-system --replicas=3

# Expected recovery time: 2-3 minutes
```

#### æ¢å¾©è·¯å¾‘ D: ç·Šæ€¥å›æ»¾ (æ–°ç‰ˆæœ¬å•é¡Œ)
**ä½¿ç”¨å ´æ™¯**: æœ€è¿‘éƒ¨ç½²çš„ç‰ˆæœ¬å°è‡´æ•…éšœ | Recent deployment caused failure

```bash
# Step 1: Check rollout history
kubectl rollout history deployment/hlp-executor-core -n unmanned-island-system

# Step 2: Rollback to previous version
kubectl rollout undo deployment/hlp-executor-core -n unmanned-island-system

# Step 3: Monitor rollback progress
kubectl rollout status deployment/hlp-executor-core -n unmanned-island-system

# Step 4: Verify health after rollback
kubectl get pods -n unmanned-island-system -l app=hlp-executor-core
kubectl logs -n unmanned-island-system -l app=hlp-executor-core --tail=100

# Step 5: Notify team about version issue
# Post in Slack #incidents channel with version details

# Expected recovery time: 1-2 minutes
```

### ğŸ“ å‡ç´šè·¯å¾‘ | Escalation Path

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   P1 å‡ç´šè·¯å¾‘ | P1 Escalation Path       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

T+0:     Alert triggered
         â†“
T+1min:  On-Call SRE notified via PagerDuty
         â†“
T+5min:  If not acknowledged â†’ Escalate to Platform Lead
         â†“
T+15min: If not resolved â†’ Escalate to CTO
         â†“
T+30min: If not resolved â†’ Engage vendor support (if applicable)
```

#### å‡ç´šè§¸ç™¼æ¢ä»¶ | Escalation Triggers
- â±ï¸ **5 åˆ†é˜**: On-Call SRE æœªéŸ¿æ‡‰ | On-Call SRE not responding
- â±ï¸ **15 åˆ†é˜**: æ¢å¾©æªæ–½ç„¡æ•ˆ | Recovery actions ineffective
- â±ï¸ **30 åˆ†é˜**: éœ€è¦é¡å¤–è³‡æºæˆ–æˆæ¬Š | Additional resources or authorization needed

---

## ğŸŸ  P2: state-corruption-detected (ç‹€æ…‹æ©Ÿç•°å¸¸ | State Machine Inconsistent)

### âš ï¸ åš´é‡æ€§æ¨™è­˜ | Severity Indicators

```
âš ï¸  HIGH PRIORITY - P2 INCIDENT
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
æœå‹™ç‹€æ…‹ | Service Status: DEGRADED
å½±éŸ¿ç¯„åœ | Impact: éƒ¨åˆ†åŸ·è¡Œå¯èƒ½å¤±æ•—æˆ–å¡ä½
æª¢æ¸¬æ™‚é–“ | Detected: <TIMESTAMP>
éŸ¿æ‡‰åœ˜éšŠ | Response Team: On-Call SRE
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

### ğŸ¯ ç—‡ç‹€è­˜åˆ¥ | Symptom Identification

#### è‡ªå‹•æª¢æ¸¬ | Automatic Detection
```yaml
alerting_rules:
  - alert: HLPExecutorStateCorruptionDetected
    expr: |
      rate(hlp_executor_state_corruption_total[5m]) > 0
    for: 2m
    severity: P2
    annotations:
      summary: "HLP Executor state corruption detected"
      description: "{{ $value }} corruptions detected in the last 5 minutes"
```

#### æ˜é¡¯ç—‡ç‹€ | Observable Symptoms
- âš ï¸ åŸ·è¡Œå¡åœ¨ç›¸åŒéšæ®µè¶…éé æœŸæ™‚é–“ | Executions stuck in same phase beyond expected time
- âš ï¸ ç‹€æ…‹è½‰æ›é©—è­‰å¤±æ•— | State transition validation failures
- âš ï¸ Checkpoint ç„¡æ³•æ¢å¾©æˆ–é©—è­‰å¤±æ•— | Checkpoints cannot be restored or validation fails
- âš ï¸ æ—¥èªŒä¸­å‡ºç¾ "state_machine_error" æˆ– "invalid_state_transition" | Logs show "state_machine_error" or "invalid_state_transition"
- âš ï¸ Prometheus é¡¯ç¤ºç•°å¸¸çš„ç‹€æ…‹è½‰æ›å»¶é² | Prometheus shows abnormal state transition latency

#### æ¥­å‹™å½±éŸ¿ | Business Impact
- âš ï¸ éƒ¨åˆ† HLP åŸ·è¡Œå¯èƒ½é€²å…¥ä¸ä¸€è‡´ç‹€æ…‹ | Some HLP executions may enter inconsistent state
- âš ï¸ å›æ»¾åŠŸèƒ½å¯èƒ½å—æ | Rollback functionality may be impaired
- âš ï¸ åŸ·è¡Œæ™‚é–“å¢åŠ  | Execution time increased
- ğŸ“Š SLO å½±éŸ¿: State transition latency > P90 50ms | SLO impact: State transition latency > P90 50ms

### ğŸ” è¨ºæ–·æ­¥é©Ÿ | Diagnostic Steps

#### ç¬¬ä¸€æ­¥ï¼šè­˜åˆ¥å—å½±éŸ¿çš„åŸ·è¡Œ (< 1 åˆ†é˜)
```bash
# 1. Query for corrupted state metrics
kubectl exec -it deployment/hlp-executor-core -n unmanned-island-system -- \
  curl -s http://localhost:8080/metrics | grep -E "state_corruption|invalid_state"

# 2. Check execution status via admin API
kubectl exec -it deployment/hlp-executor-core -n unmanned-island-system -- \
  curl http://localhost:8081/admin/executions?status=STUCK | jq

# 3. Check recent logs for state errors
kubectl logs -n unmanned-island-system -l app=hlp-executor-core --tail=500 | \
  grep -i -E "(state.*corrupt|invalid.*state|checkpoint.*fail)" | tail -20

# 4. List executions with long phase duration
kubectl exec -it deployment/hlp-executor-core -n unmanned-island-system -- \
  python3 -m tools.list_stuck_executions --threshold-minutes 10
```

#### ç¬¬äºŒæ­¥ï¼šé©—è­‰ Checkpoint å®Œæ•´æ€§
```bash
# 1. Run checkpoint validation
kubectl exec -it deployment/hlp-executor-core -n unmanned-island-system -- \
  python3 -m core.safety_mechanisms.checkpoint_manager validate --recent 20

# 2. Check for corrupted checkpoint files
kubectl exec -it deployment/hlp-executor-core -n unmanned-island-system -- \
  find /var/lib/hlp-executor/state/checkpoints -type f -exec file {} \; | \
  grep -v "data"

# 3. Verify checkpoint metadata
kubectl exec -it deployment/hlp-executor-core -n unmanned-island-system -- \
  python3 -m core.safety_mechanisms.checkpoint_manager inspect --checkpoint-id <ID>
```

#### ç¬¬ä¸‰æ­¥ï¼šåˆ†æç‹€æ…‹æ©Ÿæ—¥èªŒ
```bash
# 1. Extract state transition logs
kubectl logs -n unmanned-island-system -l app=hlp-executor-core --tail=1000 | \
  grep "state_transition" > /tmp/state_transitions.log

# 2. Analyze for invalid transitions
python3 << 'EOF'
import json
with open('/tmp/state_transitions.log') as f:
    for line in f:
        try:
            log = json.loads(line)
            if log.get('valid') == False:
                print(f"Invalid transition: {log['from_state']} -> {log['to_state']}")
                print(f"  Execution ID: {log.get('execution_id')}")
                print(f"  Reason: {log.get('reason')}")
        except:
            pass
EOF

# 3. Check for concurrent state updates (race conditions)
kubectl logs -n unmanned-island-system -l app=hlp-executor-core --tail=1000 | \
  grep -E "(concurrent_update|race_condition|lock_timeout)"
```

### ğŸ› ï¸ æ¢å¾©æªæ–½ | Recovery Actions

#### æ¢å¾©è·¯å¾‘ A: å–®ä¸€åŸ·è¡Œæ¢å¾© (éš”é›¢å•é¡Œ)
**ä½¿ç”¨å ´æ™¯**: åªæœ‰å°‘æ•¸åŸ·è¡Œå—å½±éŸ¿ | Only a few executions affected

```bash
# Step 1: Identify stuck execution IDs
STUCK_EXECUTIONS=$(kubectl exec -it deployment/hlp-executor-core -n unmanned-island-system -- \
  curl -s http://localhost:8081/admin/executions?status=STUCK | jq -r '.[].execution_id')

# Step 2: Attempt to recover each execution
for exec_id in $STUCK_EXECUTIONS; do
  echo "Recovering execution: $exec_id"
  
  # Try to rollback to last known good checkpoint
  kubectl exec -it deployment/hlp-executor-core -n unmanned-island-system -- \
    python3 -m core.safety_mechanisms.partial_rollback \
    --execution-id "$exec_id" \
    --scope phase \
    --to-checkpoint latest-valid
  
  # Verify recovery
  kubectl exec -it deployment/hlp-executor-core -n unmanned-island-system -- \
    curl -s "http://localhost:8081/admin/executions/$exec_id/status" | jq
done

# Expected recovery time: 2-5 minutes per execution
```

#### æ¢å¾©è·¯å¾‘ B: é‡å»ºç‹€æ…‹ç´¢å¼• (å»£æ³›å•é¡Œ)
**ä½¿ç”¨å ´æ™¯**: å¤šå€‹åŸ·è¡Œå—å½±éŸ¿ï¼Œç‹€æ…‹ç´¢å¼•å¯èƒ½æå£ | Multiple executions affected, state index may be corrupted

```bash
# Step 1: Enable maintenance mode (new executions queued)
kubectl exec -it deployment/hlp-executor-core -n unmanned-island-system -- \
  curl -X POST http://localhost:8081/admin/maintenance-mode \
  -d '{"enabled": true, "reason": "state_index_rebuild"}'

# Step 2: Export current state for backup
kubectl exec -it deployment/hlp-executor-core -n unmanned-island-system -- \
  python3 -m core.safety_mechanisms.checkpoint_manager export-all \
  --output /var/lib/hlp-executor/state/backup/state-export-$(date +%s).tar.gz

# Step 3: Rebuild state index
kubectl exec -it deployment/hlp-executor-core -n unmanned-island-system -- \
  python3 -m tools.rebuild_state_index --verify --fix-inconsistencies

# Step 4: Verify index integrity
kubectl exec -it deployment/hlp-executor-core -n unmanned-island-system -- \
  python3 -m tools.verify_state_index --verbose

# Step 5: Disable maintenance mode
kubectl exec -it deployment/hlp-executor-core -n unmanned-island-system -- \
  curl -X POST http://localhost:8081/admin/maintenance-mode \
  -d '{"enabled": false}'

# Step 6: Resume stuck executions
kubectl exec -it deployment/hlp-executor-core -n unmanned-island-system -- \
  curl -X POST http://localhost:8081/admin/executions/resume-all

# Expected recovery time: 5-10 minutes
```

#### æ¢å¾©è·¯å¾‘ C: å®Œæ•´å›æ»¾èˆ‡é‡å•Ÿ (åš´é‡æå£)
**ä½¿ç”¨å ´æ™¯**: ç‹€æ…‹åš´é‡æå£ï¼Œç„¡æ³•åœ¨ç·šä¿®å¾© | Severe corruption, cannot be fixed online

```bash
# Step 1: Stop all new executions (circuit breaker)
kubectl exec -it deployment/hlp-executor-core -n unmanned-island-system -- \
  curl -X POST http://localhost:8081/admin/circuit-breaker/hlp_execution/open

# Step 2: Wait for in-progress executions to complete or timeout (max 5 min)
watch -n 10 'kubectl exec -it deployment/hlp-executor-core -n unmanned-island-system -- \
  curl -s http://localhost:8081/admin/executions?status=RUNNING | jq "length"'

# Step 3: Create full state snapshot before recovery
kubectl exec -it deployment/hlp-executor-core -n unmanned-island-system -- \
  python3 -m core.safety_mechanisms.checkpoint_manager snapshot \
  --type FULL \
  --name "pre-recovery-$(date +%s)"

# Step 4: Restore from last known good full snapshot
LAST_GOOD_SNAPSHOT=$(kubectl exec -it deployment/hlp-executor-core -n unmanned-island-system -- \
  python3 -m core.safety_mechanisms.checkpoint_manager list --type FULL | \
  grep "VALID" | head -1 | awk '{print $2}')

kubectl exec -it deployment/hlp-executor-core -n unmanned-island-system -- \
  python3 -m core.safety_mechanisms.checkpoint_manager restore \
  --checkpoint-id "$LAST_GOOD_SNAPSHOT" \
  --verify

# Step 5: Restart HLP Executor pods
kubectl rollout restart deployment/hlp-executor-core -n unmanned-island-system
kubectl rollout status deployment/hlp-executor-core -n unmanned-island-system

# Step 6: Re-enable executions
kubectl exec -it deployment/hlp-executor-core -n unmanned-island-system -- \
  curl -X POST http://localhost:8081/admin/circuit-breaker/hlp_execution/close

# Expected recovery time: 10-15 minutes
# Data loss: Executions since last snapshot may need to be re-submitted
```

### ğŸ“ å‡ç´šè·¯å¾‘ | Escalation Path

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   P2 å‡ç´šè·¯å¾‘ | P2 Escalation Path       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

T+0:     Alert triggered
         â†“
T+5min:  On-Call SRE notified via PagerDuty
         â†“
T+15min: If recovery not progressing â†’ Notify Platform Lead
         â†“
T+1hr:   If not resolved â†’ Escalate to CTO
         â†“
T+2hr:   If not resolved â†’ Schedule incident review
```

---

## ğŸ“Š äº‹å¾Œè™•ç† | Post-Incident Actions

### ç«‹å³è¡Œå‹• (äº‹ä»¶è§£æ±ºå¾Œ 1 å°æ™‚å…§)
- [ ] æ›´æ–°äº‹ä»¶è¿½è¹¤å·¥å–®ç‹€æ…‹ | Update incident tracking ticket status
- [ ] åœ¨ Slack #incidents é »é“ç™¼å¸ƒè§£æ±ºé€šçŸ¥ | Post resolution notice in Slack #incidents channel
- [ ] ä¿å­˜æ‰€æœ‰è¨ºæ–·æ—¥èªŒå’ŒæŒ‡æ¨™ | Preserve all diagnostic logs and metrics
- [ ] å‰µå»ºåˆæ­¥äº‹ä»¶å ±å‘Š | Create preliminary incident report

### 24 å°æ™‚å…§
- [ ] å®Œæˆè©³ç´°äº‹ä»¶å ±å‘Š (Post-Mortem) | Complete detailed incident report (Post-Mortem)
- [ ] è­˜åˆ¥æ ¹æœ¬åŸå›  | Identify root cause
- [ ] åˆ—å‡ºè¡Œå‹•é …ç›® (Action Items) | List action items
- [ ] å®‰æ’äº‹ä»¶æª¢è¨æœƒè­° | Schedule incident review meeting

### 1 é€±å…§
- [ ] å¯¦æ–½é é˜²æªæ–½ | Implement preventive measures
- [ ] æ›´æ–° Runbook (å¦‚æœæµç¨‹æœ‰æ”¹é€²) | Update Runbook (if process improved)
- [ ] æ›´æ–°ç›£æ§å‘Šè­¦è¦å‰‡ (å¦‚æœéœ€è¦) | Update monitoring/alerting rules (if needed)
- [ ] èˆ‡åœ˜éšŠåˆ†äº«ç¶“é©—æ•™è¨“ | Share lessons learned with team

---

## ğŸ“ ç·Šæ€¥è¯çµ¡æ–¹å¼ | Emergency Contacts

```yaml
emergency_contacts:
  primary_oncall:
    pagerduty: "https://unmanned-island.pagerduty.com/services/P1234-HLP-EXECUTOR"
    slack: "#sre-oncall"
    phone: "+1-555-SRE-0100"
  
  platform_lead:
    name: "Platform Engineering Lead"
    slack: "@platform-lead"
    email: "platform-lead@unmanned-island.com"
    phone: "+1-555-PLAT-101"
  
  cto:
    name: "Chief Technology Officer"
    slack: "@cto"
    email: "cto@unmanned-island.com"
    phone: "+1-555-CTO-0102"
  
  vendor_support:
    kubernetes: "https://support.kubernetes.io"
    cloud_provider: "+1-800-CLOUD-00"
```

---

## ğŸ”— ç›¸é—œè³‡æº | Related Resources

- [HLP Executor Error Handling Runbook](./HLP_EXECUTOR_ERROR_HANDLING.md)
- [HLP Executor Maintenance Guide](./HLP_EXECUTOR_MAINTENANCE.md)
- [HLP Executor SLO](../slo/HLP_EXECUTOR_SLO.md)
- [Incident Management Process](../../INCIDENT_MANAGEMENT.md)
- [PagerDuty Integration](https://unmanned-island.pagerduty.com)
- [Slack Incident Channel](https://unmanned-island.slack.com/archives/incidents)

---

**æ–‡ä»¶ç¶­è­·è€… | Document Maintainer**: SRE Team  
**å¯©æ ¸é€±æœŸ | Review Cycle**: After each P1/P2 incident  
**ç·Šæ€¥æ›´æ–°æµç¨‹ | Emergency Update Process**: Direct commit + immediate team notification
