# HLP Executor æœå‹™ç­‰ç´šç›®æ¨™ | HLP Executor Service Level Objectives (SLO)

**æ–‡ä»¶ç‰ˆæœ¬ | Document Version**: 1.0.0  
**æœ€å¾Œæ›´æ–° | Last Updated**: 2025-12-07  
**è² è²¬åœ˜éšŠ | Responsible Team**: Platform Engineering / SRE  
**å¯©æ ¸é€±æœŸ | Review Cycle**: Quarterly

---

## ğŸ“‹ æ–‡ä»¶ç›®çš„ | Document Purpose

æœ¬æ–‡ä»¶å®šç¾© HLP Executor Core
Plugin çš„æœå‹™ç­‰ç´šç›®æ¨™ (SLO)ï¼ŒåŒ…å«é—œéµæ€§èƒ½æŒ‡æ¨™ã€æ¸¬é‡æ–¹æ³•å’Œåˆè¦ç›£æ§ç­–ç•¥ã€‚

This document defines Service Level Objectives (SLO) for the HLP Executor Core
Plugin, including key performance metrics, measurement methods, and compliance
monitoring strategies.

---

## ğŸ¯ SLO æ¦‚è¦½ | SLO Overview

### SLO å±¤ç´š | SLO Tiers

HLP Executor çš„ SLO åˆ†ç‚ºä¸‰å€‹å±¤ç´šï¼Œç¢ºä¿å…¨é¢çš„æœå‹™è³ªé‡ä¿è­‰ï¼š

HLP Executor SLOs are organized into three tiers to ensure comprehensive service
quality assurance:

| å±¤ç´š       | é¡åˆ¥           | é‡è¦æ€§   | å½±éŸ¿ç¯„åœ     |
| ---------- | -------------- | -------- | ------------ |
| **Tier 1** | å¯ç”¨æ€§èˆ‡å¯é æ€§ | Critical | æœå‹™æ•´é«”é‹è¡Œ |
| **Tier 2** | æ€§èƒ½èˆ‡å»¶é²     | High     | ç”¨æˆ¶é«”é©—     |
| **Tier 3** | å®¹é‡èˆ‡æ•ˆç‡     | Medium   | è³‡æºå„ªåŒ–     |

---

## ğŸ“Š Tier 1: å¯ç”¨æ€§èˆ‡å¯é æ€§ SLO | Availability and Reliability SLO

### 1.1 æœå‹™å¯ç”¨æ€§ | Service Availability

#### ç›®æ¨™ | Objective

```yaml
slo_name: hlp_executor_availability
target: 99.9%
measurement_window: 30 days
calculation_method: uptime / total_time
```

#### å®šç¾© | Definition

æœå‹™å¯ç”¨æ€§å®šç¾©ç‚º HLP Executor èƒ½å¤ æ¥å—å’Œè™•ç†è«‹æ±‚çš„æ™‚é–“ç™¾åˆ†æ¯”ã€‚

Service availability is defined as the percentage of time the HLP Executor is
able to accept and process requests.

#### æ¸¬é‡æ–¹æ³• | Measurement Method

**Prometheus Query**:

```promql
# 30å¤©å¯ç”¨æ€§ | 30-day availability
(
  sum(up{job="hlp-executor-core"} == 1)
  /
  count(up{job="hlp-executor-core"})
) * 100

# æˆ–ä½¿ç”¨ SLI (Service Level Indicator)
100 * (
  1 - (
    sum(rate(hlp_executor_requests_total{status=~"5.."}[30d]))
    /
    sum(rate(hlp_executor_requests_total[30d]))
  )
)
```

**ç›£æ§é…ç½® | Monitoring Configuration**:

```yaml
# prometheus-rules.yml
groups:
  - name: hlp_executor_availability
    interval: 1m
    rules:
      - record: hlp_executor:availability:30d
        expr: |
          100 * (
            1 - (
              sum(rate(hlp_executor_requests_total{status=~"5.."}[30d]))
              /
              sum(rate(hlp_executor_requests_total[30d]))
            )
          )

      - alert: HLPExecutorAvailabilitySLOViolation
        expr: hlp_executor:availability:30d < 99.9
        for: 5m
        labels:
          severity: critical
          slo_tier: tier1
        annotations:
          summary: 'HLP Executor availability SLO violation'
          description: 'Availability is {{ $value }}%, below 99.9% target'
          dashboard: 'https://grafana/d/hlp-executor-slo'
```

#### æ’é™¤æƒ…æ³ | Exclusions

ä»¥ä¸‹æƒ…æ³ä¸è¨ˆå…¥å¯ç”¨æ€§è¨ˆç®—ï¼š

- è¨ˆåŠƒæ€§ç¶­è­·çª—å£ (æ¯é€±äºŒ 02:00-04:00 UTC)
- ä¸Šæ¸¸ä¾è³´å®Œå…¨æ•…éšœ (Kubernetes API Server å®Œå…¨ä¸å¯ç”¨)
- ç½é›£æ€§åŸºç¤è¨­æ–½æ•…éšœ (æ•´å€‹ region æ•…éšœ)

The following are excluded from availability calculation:

- Scheduled maintenance windows (Weekly Tuesday 02:00-04:00 UTC)
- Complete upstream dependency failures (Kubernetes API Server completely
  unavailable)
- Catastrophic infrastructure failures (Entire region down)

#### éŒ¯èª¤é ç®— | Error Budget

```yaml
error_budget:
  monthly: 43.2 minutes # (30 days * 24 hours * 60 min) * 0.1%
  daily: 1.44 minutes # 24 hours * 60 min * 0.1%
  weekly: 10.08 minutes # 7 days * 24 hours * 60 min * 0.1%

  alerting_thresholds:
    - consumed: 25%
      action: notify_team
    - consumed: 50%
      action: escalate_to_lead
    - consumed: 75%
      action: freeze_non_critical_changes
    - consumed: 90%
      action: emergency_response
```

---

### 1.2 æ¢å¾©æ™‚é–“ç›®æ¨™ | Recovery Time Objective (RTO)

#### ç›®æ¨™ | Objective

```yaml
slo_name: hlp_executor_rto
target: < 30 seconds
measurement_window: per incident
calculation_method: time_to_restore_service
severity: P1
```

#### å®šç¾© | Definition

RTO æ˜¯æŒ‡å¾æª¢æ¸¬åˆ°æœå‹™ä¸­æ–·åˆ°æœå‹™å®Œå…¨æ¢å¾©çš„æœ€å¤§å…è¨±æ™‚é–“ã€‚

RTO is the maximum acceptable time from service outage detection to full service
restoration.

#### æ¸¬é‡æ–¹æ³• | Measurement Method

**Prometheus Query**:

```promql
# å¹³å‡æ¢å¾©æ™‚é–“ | Average recovery time
avg(hlp_executor_recovery_duration_seconds)

# P95 æ¢å¾©æ™‚é–“ | P95 recovery time
histogram_quantile(0.95,
  rate(hlp_executor_recovery_duration_seconds_bucket[30d])
)
```

**ç›£æ§é…ç½® | Monitoring Configuration**:

```yaml
groups:
  - name: hlp_executor_rto
    interval: 30s
    rules:
      - alert: HLPExecutorRTOSLOViolation
        expr: hlp_executor_recovery_duration_seconds > 30
        for: 1m
        labels:
          severity: critical
          slo_tier: tier1
        annotations:
          summary: 'HLP Executor RTO SLO violation'
          description: 'Recovery took {{ $value }}s, exceeding 30s target'
```

#### RTO åˆ†å±¤ | RTO by Severity

| åš´é‡æ€§        | RTO ç›®æ¨™     | æ¸¬é‡æ–¹æ³•           |
| ------------- | ------------ | ------------------ |
| P1 - Critical | < 30 seconds | è‡ªå‹•æª¢æ¸¬åˆ°æœå‹™æ¢å¾© |
| P2 - High     | < 5 minutes  | è‡ªå‹•æª¢æ¸¬åˆ°æœå‹™æ¢å¾© |
| P3 - Medium   | < 30 minutes | æ‰‹å‹•ç¢ºèªåˆ°æœå‹™æ¢å¾© |
| P4 - Low      | < 2 hours    | æ‰‹å‹•ç¢ºèªåˆ°æœå‹™æ¢å¾© |

---

### 1.3 æ¢å¾©é»ç›®æ¨™ | Recovery Point Objective (RPO)

#### ç›®æ¨™ | Objective

```yaml
slo_name: hlp_executor_rpo
target: < 5 minutes
measurement_window: per incident
calculation_method: data_loss_window
```

#### å®šç¾© | Definition

RPO æ˜¯æŒ‡åœ¨ç½é›£æ¢å¾©å ´æ™¯ä¸­ï¼Œå¯æ¥å—çš„æœ€å¤§æ•¸æ“šéºå¤±æ™‚é–“çª—å£ã€‚

RPO is the maximum acceptable time window of data loss in disaster recovery
scenarios.

#### æ¸¬é‡æ–¹æ³• | Measurement Method

**å¯¦ç¾æ©Ÿåˆ¶ | Implementation**:

- Checkpoint é »ç‡: æ¯ 60 ç§’ | Checkpoint frequency: Every 60 seconds
- å¢é‡å¿«ç…§: æ¯ 5 åˆ†é˜ | Incremental snapshots: Every 5 minutes
- å®Œæ•´å¿«ç…§: æ¯ 1 å°æ™‚ | Full snapshots: Every 1 hour

**é©—è­‰æŸ¥è©¢ | Verification Query**:

```promql
# æœ€è¿‘ checkpoint æ™‚é–“ | Time since last checkpoint
time() - hlp_executor_last_checkpoint_timestamp_seconds < 300
```

---

## ğŸš€ Tier 2: æ€§èƒ½èˆ‡å»¶é² SLO | Performance and Latency SLO

### 2.1 DAG è§£æå»¶é² | DAG Parsing Latency

#### ç›®æ¨™ | Objective

```yaml
slo_name: hlp_executor_dag_parsing_latency
target: P95 < 120ms
measurement_window: 7 days
calculation_method: histogram_quantile
```

#### å®šç¾© | Definition

DAG è§£æå»¶é²æ˜¯æŒ‡å¾æ¥æ”¶ DAG å®šç¾©åˆ°è§£æå®Œæˆä¸¦æº–å‚™åŸ·è¡Œçš„æ™‚é–“ã€‚

DAG parsing latency is the time from receiving a DAG definition to parsing
completion and readiness for execution.

#### æ¸¬é‡æ–¹æ³• | Measurement Method

**Prometheus Query**:

```promql
# P50, P90, P95, P99 å»¶é² | P50, P90, P95, P99 latencies
histogram_quantile(0.50,
  rate(hlp_executor_dag_parsing_duration_seconds_bucket[7d])
)

histogram_quantile(0.95,
  rate(hlp_executor_dag_parsing_duration_seconds_bucket[7d])
)
```

**ç›£æ§é…ç½® | Monitoring Configuration**:

```yaml
groups:
  - name: hlp_executor_dag_parsing_latency
    interval: 1m
    rules:
      - record: hlp_executor:dag_parsing_latency:p95:7d
        expr: |
          histogram_quantile(0.95, 
            rate(hlp_executor_dag_parsing_duration_seconds_bucket[7d])
          )

      - alert: HLPExecutorDAGParsingLatencySLOViolation
        expr: hlp_executor:dag_parsing_latency:p95:7d > 0.120
        for: 10m
        labels:
          severity: warning
          slo_tier: tier2
        annotations:
          summary: 'HLP Executor DAG parsing latency SLO violation'
          description: 'P95 latency is {{ $value }}s, exceeding 120ms target'
```

#### æ€§èƒ½åŸºæº– | Performance Benchmarks

| ç™¾åˆ†ä½ | ç›®æ¨™    | ç•¶å‰   | ç‹€æ…‹    |
| ------ | ------- | ------ | ------- |
| P50    | < 50ms  | ~35ms  | âœ… é”æ¨™ |
| P90    | < 100ms | ~85ms  | âœ… é”æ¨™ |
| P95    | < 120ms | ~110ms | âœ… é”æ¨™ |
| P99    | < 200ms | ~180ms | âœ… é”æ¨™ |

---

### 2.2 ç‹€æ…‹è½‰æ›å»¶é² | State Transition Latency

#### ç›®æ¨™ | Objective

```yaml
slo_name: hlp_executor_state_transition_latency
target: P90 < 50ms
measurement_window: 7 days
calculation_method: histogram_quantile
```

#### å®šç¾© | Definition

ç‹€æ…‹è½‰æ›å»¶é²æ˜¯æŒ‡åŸ·è¡Œå¾ä¸€å€‹ç‹€æ…‹è½‰æ›åˆ°ä¸‹ä¸€å€‹ç‹€æ…‹æ‰€éœ€çš„æ™‚é–“ï¼ŒåŒ…æ‹¬é©—è­‰å’ŒæŒä¹…åŒ–ã€‚

State transition latency is the time required for an execution to transition
from one state to the next, including validation and persistence.

#### æ¸¬é‡æ–¹æ³• | Measurement Method

**Prometheus Query**:

```promql
# P90 ç‹€æ…‹è½‰æ›å»¶é² | P90 state transition latency
histogram_quantile(0.90,
  rate(hlp_executor_state_transition_duration_seconds_bucket[7d])
)

# æŒ‰ç‹€æ…‹é¡å‹åˆ†çµ„ | Grouped by state type
histogram_quantile(0.90,
  sum by (from_state, to_state) (
    rate(hlp_executor_state_transition_duration_seconds_bucket[7d])
  )
)
```

**ç›£æ§é…ç½® | Monitoring Configuration**:

```yaml
groups:
  - name: hlp_executor_state_transition_latency
    interval: 1m
    rules:
      - record: hlp_executor:state_transition_latency:p90:7d
        expr: |
          histogram_quantile(0.90, 
            rate(hlp_executor_state_transition_duration_seconds_bucket[7d])
          )

      - alert: HLPExecutorStateTransitionLatencySLOViolation
        expr: hlp_executor:state_transition_latency:p90:7d > 0.050
        for: 10m
        labels:
          severity: warning
          slo_tier: tier2
        annotations:
          summary: 'HLP Executor state transition latency SLO violation'
          description: 'P90 latency is {{ $value }}s, exceeding 50ms target'
```

#### æ€§èƒ½åŸºæº– | Performance Benchmarks

| ç‹€æ…‹è½‰æ›é¡å‹        | P90 ç›®æ¨™ | P90 ç•¶å‰ |
| ------------------- | -------- | -------- |
| PENDING â†’ RUNNING   | < 50ms   | ~30ms    |
| RUNNING â†’ COMPLETED | < 50ms   | ~40ms    |
| RUNNING â†’ FAILED    | < 50ms   | ~35ms    |
| ANY â†’ ROLLING_BACK  | < 100ms  | ~80ms    |

---

### 2.3 è«‹æ±‚è™•ç†ååé‡ | Request Processing Throughput

#### ç›®æ¨™ | Objective

```yaml
slo_name: hlp_executor_throughput
target: > 1000 requests/second
measurement_window: 5 minutes
calculation_method: rate
```

#### å®šç¾© | Definition

è«‹æ±‚è™•ç†ååé‡æ˜¯æŒ‡ HLP Executor æ¯ç§’å¯ä»¥è™•ç†çš„è«‹æ±‚æ•¸é‡ã€‚

Request processing throughput is the number of requests HLP Executor can process
per second.

#### æ¸¬é‡æ–¹æ³• | Measurement Method

**Prometheus Query**:

```promql
# ç•¶å‰ååé‡ (requests/sec) | Current throughput (requests/sec)
sum(rate(hlp_executor_requests_total[5m]))

# æŒ‰ç‹€æ…‹ç¢¼åˆ†çµ„ | Grouped by status code
sum by (status) (rate(hlp_executor_requests_total[5m]))
```

**ç›£æ§é…ç½® | Monitoring Configuration**:

```yaml
groups:
  - name: hlp_executor_throughput
    interval: 1m
    rules:
      - record: hlp_executor:throughput:5m
        expr: sum(rate(hlp_executor_requests_total[5m]))

      - alert: HLPExecutorThroughputSLOViolation
        expr: hlp_executor:throughput:5m < 1000
        for: 5m
        labels:
          severity: warning
          slo_tier: tier2
        annotations:
          summary: 'HLP Executor throughput below SLO'
          description:
            'Current throughput is {{ $value }} req/s, below 1000 req/s target'
```

---

## ğŸ’¾ Tier 3: å®¹é‡èˆ‡æ•ˆç‡ SLO | Capacity and Efficiency SLO

### 3.1 è³‡æºåˆ©ç”¨ç‡ | Resource Utilization

#### ç›®æ¨™ | Objective

```yaml
slo_name: hlp_executor_resource_utilization
targets:
  cpu_utilization: 60-80%
  memory_utilization: 70-85%
  disk_utilization: < 80%
measurement_window: 7 days
```

#### å®šç¾© | Definition

è³‡æºåˆ©ç”¨ç‡ç›®æ¨™ç¢ºä¿ç³»çµ±é‹è¡Œåœ¨æœ€ä½³æ•ˆç‡ç¯„åœå…§ï¼Œæ—¢ä¸æµªè²»è³‡æºä¹Ÿä¸éåº¦è² è¼‰ã€‚

Resource utilization targets ensure the system operates within optimal
efficiency ranges, neither wasting resources nor being overloaded.

#### æ¸¬é‡æ–¹æ³• | Measurement Method

**Prometheus Query**:

```promql
# CPU åˆ©ç”¨ç‡ | CPU utilization
avg(
  rate(container_cpu_usage_seconds_total{
    namespace="unmanned-island-system",
    pod=~"hlp-executor-core-.*"
  }[5m])
) * 100

# è¨˜æ†¶é«”åˆ©ç”¨ç‡ | Memory utilization
avg(
  container_memory_working_set_bytes{
    namespace="unmanned-island-system",
    pod=~"hlp-executor-core-.*"
  }
  /
  container_spec_memory_limit_bytes{
    namespace="unmanned-island-system",
    pod=~"hlp-executor-core-.*"
  }
) * 100

# ç£ç¢Ÿåˆ©ç”¨ç‡ | Disk utilization
(
  kubelet_volume_stats_used_bytes{
    namespace="unmanned-island-system",
    persistentvolumeclaim="hlp-executor-state-pvc"
  }
  /
  kubelet_volume_stats_capacity_bytes{
    namespace="unmanned-island-system",
    persistentvolumeclaim="hlp-executor-state-pvc"
  }
) * 100
```

**ç›£æ§é…ç½® | Monitoring Configuration**:

```yaml
groups:
  - name: hlp_executor_resource_utilization
    interval: 1m
    rules:
      - alert: HLPExecutorCPUOverUtilized
        expr: |
          avg(
            rate(container_cpu_usage_seconds_total{
              namespace="unmanned-island-system",
              pod=~"hlp-executor-core-.*"
            }[5m])
          ) * 100 > 80
        for: 15m
        labels:
          severity: warning
          slo_tier: tier3
        annotations:
          summary: 'HLP Executor CPU over-utilized'
          description:
            'CPU utilization is {{ $value }}%, exceeding 80% threshold'

      - alert: HLPExecutorCPUUnderUtilized
        expr: |
          avg(
            rate(container_cpu_usage_seconds_total{
              namespace="unmanned-island-system",
              pod=~"hlp-executor-core-.*"
            }[5m])
          ) * 100 < 40
        for: 6h
        labels:
          severity: info
          slo_tier: tier3
        annotations:
          summary: 'HLP Executor CPU under-utilized'
          description: 'CPU utilization is {{ $value }}%, consider scaling down'

      - alert: HLPExecutorDiskHighUsage
        expr: |
          (
            kubelet_volume_stats_used_bytes{
              namespace="unmanned-island-system",
              persistentvolumeclaim="hlp-executor-state-pvc"
            }
            /
            kubelet_volume_stats_capacity_bytes{
              namespace="unmanned-island-system",
              persistentvolumeclaim="hlp-executor-state-pvc"
            }
          ) * 100 > 80
        for: 10m
        labels:
          severity: warning
          slo_tier: tier3
        annotations:
          summary: 'HLP Executor disk usage high'
          description:
            'Disk utilization is {{ $value }}%, exceeding 80% threshold'
```

---

### 3.2 éŒ¯èª¤ç‡ | Error Rate

#### ç›®æ¨™ | Objective

```yaml
slo_name: hlp_executor_error_rate
target: < 1%
measurement_window: 7 days
calculation_method: errors / total_requests
```

#### å®šç¾© | Definition

éŒ¯èª¤ç‡æ˜¯æŒ‡å¤±æ•—è«‹æ±‚æ•¸é‡ä½”ç¸½è«‹æ±‚æ•¸é‡çš„ç™¾åˆ†æ¯”ã€‚

Error rate is the percentage of failed requests out of total requests.

#### æ¸¬é‡æ–¹æ³• | Measurement Method

**Prometheus Query**:

```promql
# 7å¤©éŒ¯èª¤ç‡ | 7-day error rate
(
  sum(rate(hlp_executor_requests_total{status=~"5.."}[7d]))
  /
  sum(rate(hlp_executor_requests_total[7d]))
) * 100

# æŒ‰éŒ¯èª¤é¡å‹åˆ†çµ„ | Grouped by error type
sum by (error_type) (
  rate(hlp_executor_errors_total[7d])
)
```

**ç›£æ§é…ç½® | Monitoring Configuration**:

```yaml
groups:
  - name: hlp_executor_error_rate
    interval: 1m
    rules:
      - record: hlp_executor:error_rate:7d
        expr: |
          (
            sum(rate(hlp_executor_requests_total{status=~"5.."}[7d]))
            /
            sum(rate(hlp_executor_requests_total[7d]))
          ) * 100

      - alert: HLPExecutorErrorRateSLOViolation
        expr: hlp_executor:error_rate:7d > 1
        for: 10m
        labels:
          severity: warning
          slo_tier: tier3
        annotations:
          summary: 'HLP Executor error rate SLO violation'
          description: 'Error rate is {{ $value }}%, exceeding 1% target'
```

---

## ğŸ“‹ SLO æŒ‡æ¨™å½™ç¸½è¡¨ | SLO Metrics Summary Table

| SLO åç¨±               | å±¤ç´š   | ç›®æ¨™         | æ¸¬é‡çª—å£ | å‘Šè­¦é–¾å€¼       | åš´é‡æ€§       |
| ---------------------- | ------ | ------------ | -------- | -------------- | ------------ |
| **å¯ç”¨æ€§**             | Tier 1 | > 99.9%      | 30 å¤©    | < 99.9%        | Critical     |
| **RTO**                | Tier 1 | < 30s        | æ¯æ¬¡äº‹ä»¶ | > 30s          | Critical     |
| **RPO**                | Tier 1 | < 5min       | æ¯æ¬¡äº‹ä»¶ | > 5min         | High         |
| **DAG è§£æå»¶é² (P95)** | Tier 2 | < 120ms      | 7 å¤©     | > 120ms        | Warning      |
| **ç‹€æ…‹è½‰æ›å»¶é² (P90)** | Tier 2 | < 50ms       | 7 å¤©     | > 50ms         | Warning      |
| **ååé‡**             | Tier 2 | > 1000 req/s | 5 åˆ†é˜   | < 1000 req/s   | Warning      |
| **CPU åˆ©ç”¨ç‡**         | Tier 3 | 60-80%       | 7 å¤©     | < 40% æˆ– > 80% | Warning/Info |
| **è¨˜æ†¶é«”åˆ©ç”¨ç‡**       | Tier 3 | 70-85%       | 7 å¤©     | < 50% æˆ– > 90% | Warning/Info |
| **ç£ç¢Ÿåˆ©ç”¨ç‡**         | Tier 3 | < 80%        | å³æ™‚     | > 80%          | Warning      |
| **éŒ¯èª¤ç‡**             | Tier 3 | < 1%         | 7 å¤©     | > 1%           | Warning      |

---

## ğŸ“ˆ SLO åˆè¦ç›£æ§ | SLO Compliance Monitoring

### Grafana å„€è¡¨æ¿ | Grafana Dashboard

#### ä¸»è¦é¢æ¿ | Main Panels

```yaml
dashboard:
  title: 'HLP Executor SLO Dashboard'
  uid: 'hlp-executor-slo'
  panels:
    - title: 'Availability (30-day)'
      type: gauge
      target: 99.9%
      query: hlp_executor:availability:30d

    - title: 'Error Budget Consumption'
      type: stat
      query: |
        (
          (43.2 - (43.2 * hlp_executor:availability:30d / 100))
          / 43.2
        ) * 100

    - title: 'DAG Parsing Latency Heatmap'
      type: heatmap
      query: |
        sum(rate(hlp_executor_dag_parsing_duration_seconds_bucket[5m])) by (le)

    - title: 'State Transition Latency (P50, P90, P95, P99)'
      type: graph
      queries:
        - p50: histogram_quantile(0.50, rate(...))
        - p90: histogram_quantile(0.90, rate(...))
        - p95: histogram_quantile(0.95, rate(...))
        - p99: histogram_quantile(0.99, rate(...))

    - title: 'SLO Compliance Status'
      type: table
      query: |
        # Shows compliance status for all SLOs
```

### é€±å ±ç”Ÿæˆ | Weekly Report Generation

```bash
#!/bin/bash
# Generate weekly SLO compliance report

REPORT_FILE="/tmp/hlp-executor-slo-report-$(date +%Y%W).txt"

cat > "$REPORT_FILE" <<EOF
HLP Executor SLO Compliance Report
Week: $(date +%Y-W%W)
Generated: $(date -Iseconds)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

TIER 1: AVAILABILITY AND RELIABILITY
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Availability (30-day):
$(curl -s "http://prometheus:9090/api/v1/query" \
  --data-urlencode 'query=hlp_executor:availability:30d' | \
  jq -r '.data.result[0].value[1]')%
Target: 99.9%
Status: $(if [ $(curl -s "http://prometheus:9090/api/v1/query" --data-urlencode 'query=hlp_executor:availability:30d' | jq -r '.data.result[0].value[1]' | awk '{print ($1 >= 99.9)}') -eq 1 ]; then echo "âœ… COMPLIANT"; else echo "âŒ VIOLATION"; fi)

Error Budget Remaining:
$(curl -s "http://prometheus:9090/api/v1/query" \
  --data-urlencode 'query=(43.2 - (43.2 * (100 - hlp_executor:availability:30d) / 0.1))' | \
  jq -r '.data.result[0].value[1]') minutes
Target: > 0 minutes

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

TIER 2: PERFORMANCE AND LATENCY
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

DAG Parsing Latency (P95):
$(curl -s "http://prometheus:9090/api/v1/query" \
  --data-urlencode 'query=histogram_quantile(0.95, rate(hlp_executor_dag_parsing_duration_seconds_bucket[7d]))' | \
  jq -r '.data.result[0].value[1]')s
Target: < 0.120s
Status: $(if [ $(curl -s "http://prometheus:9090/api/v1/query" --data-urlencode 'query=histogram_quantile(0.95, rate(hlp_executor_dag_parsing_duration_seconds_bucket[7d]))' | jq -r '.data.result[0].value[1]' | awk '{print ($1 < 0.120)}') -eq 1 ]; then echo "âœ… COMPLIANT"; else echo "âŒ VIOLATION"; fi)

State Transition Latency (P90):
$(curl -s "http://prometheus:9090/api/v1/query" \
  --data-urlencode 'query=histogram_quantile(0.90, rate(hlp_executor_state_transition_duration_seconds_bucket[7d]))' | \
  jq -r '.data.result[0].value[1]')s
Target: < 0.050s
Status: $(if [ $(curl -s "http://prometheus:9090/api/v1/query" --data-urlencode 'query=histogram_quantile(0.90, rate(hlp_executor_state_transition_duration_seconds_bucket[7d]))' | jq -r '.data.result[0].value[1]' | awk '{print ($1 < 0.050)}') -eq 1 ]; then echo "âœ… COMPLIANT"; else echo "âŒ VIOLATION"; fi)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

TIER 3: CAPACITY AND EFFICIENCY
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Error Rate (7-day):
$(curl -s "http://prometheus:9090/api/v1/query" \
  --data-urlencode 'query=hlp_executor:error_rate:7d' | \
  jq -r '.data.result[0].value[1]')%
Target: < 1%
Status: $(if [ $(curl -s "http://prometheus:9090/api/v1/query" --data-urlencode 'query=hlp_executor:error_rate:7d' | jq -r '.data.result[0].value[1]' | awk '{print ($1 < 1)}') -eq 1 ]; then echo "âœ… COMPLIANT"; else echo "âŒ VIOLATION"; fi)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
EOF

# Send report
cat "$REPORT_FILE" | \
  mail -s "HLP Executor Weekly SLO Report - Week $(date +%Y-W%W)" \
  platform-team@unmanned-island.com

echo "SLO report generated: $REPORT_FILE"
```

---

## ğŸ” SLO å¯©æŸ¥æµç¨‹ | SLO Review Process

### æ¯é€±å¯©æŸ¥ | Weekly Review

- **æ™‚é–“**: æ¯é€±ä¸€ 10:00 UTC
- **åƒèˆ‡è€…**: SRE Team, Platform Engineering Lead
- **è­°ç¨‹**:
  1. æª¢æŸ¥ SLO åˆè¦ç‹€æ…‹
  2. åˆ†æä»»ä½•é•è¦
  3. å¯©æŸ¥éŒ¯èª¤é ç®—æ¶ˆè€—
  4. è­˜åˆ¥è¶¨å‹¢å’Œæ¨¡å¼

### å­£åº¦å¯©æŸ¥ | Quarterly Review

- **æ™‚é–“**: æ¯å­£ç¬¬ä¸€å€‹æœˆç¬¬ä¸€é€±
- **åƒèˆ‡è€…**: å…¨é«”å·¥ç¨‹åœ˜éšŠ, ç®¡ç†å±¤
- **è­°ç¨‹**:
  1. å…¨é¢ SLO åˆè¦å›é¡§
  2. è©•ä¼° SLO æ˜¯å¦ä»ç„¶åˆé©
  3. èª¿æ•´ SLO ç›®æ¨™ (å¦‚éœ€è¦)
  4. å®¹é‡è¦åŠƒå’Œè³‡æºå„ªåŒ–

---

## ğŸ”— ç›¸é—œè³‡æº | Related Resources

- [HLP Executor Error Handling Runbook](../runbooks/HLP_EXECUTOR_ERROR_HANDLING.md)
- [HLP Executor Emergency Runbook](../runbooks/HLP_EXECUTOR_EMERGENCY.md)
- [HLP Executor Maintenance Guide](../runbooks/HLP_EXECUTOR_MAINTENANCE.md)
- [Monitoring Configuration](/config/monitoring.yaml)
- [Prometheus Rules](/config/prometheus-rules.yml)
- [Grafana Dashboard](https://grafana/d/hlp-executor-slo)

---

**æ–‡ä»¶ç¶­è­·è€… | Document Maintainer**: Platform Engineering Team  
**å¯©æ ¸é€±æœŸ | Review Cycle**: Quarterly  
**ä¸‹æ¬¡å¯©æ ¸ | Next Review**: 2026-03-07
