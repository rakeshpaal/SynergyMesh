# Performance Optimization Guide

## Quick Start

This guide shows you how to use the optimized versions of performance-critical scripts in the SynergyMesh/Synergy codebase.

---

## ðŸš€ Optimized Scripts

### 1. Repository Scanner (Python)

**Original:** `tools/docs/scan_repo_generate_index.py`  
**Optimized:** `tools/docs/scan_repo_generate_index_optimized.py`

**Key Improvements:**
- âœ… Parallel file processing (10x faster)
- âœ… LRU caching for expensive operations
- âœ… Pre-compiled regex patterns
- âœ… Efficient data structures (sets > lists)

**Usage:**

```bash
# Basic usage
python tools/docs/scan_repo_generate_index_optimized.py

# With custom output
python tools/docs/scan_repo_generate_index_optimized.py \
  --output docs/my-index.yaml

# Run with benchmark
python tools/docs/scan_repo_generate_index_optimized.py \
  --benchmark \
  --workers 20

# JSON output instead of YAML
python tools/docs/scan_repo_generate_index_optimized.py \
  --json \
  --output docs/index.json
```

**Performance Comparison:**

| Metric | Original | Optimized | Improvement |
|--------|----------|-----------|-------------|
| Time (1000 files) | ~15-20s | ~3-5s | **70-75%** |
| Throughput | 50-67 files/s | 200-333 files/s | **300%** |
| Memory | High | Low | Better |

---

### 2. Registry Updater (Node.js)

**Original:** `governance/dimensions/81-auto-comment/scripts/update-registry.js`  
**Optimized:** `governance/dimensions/81-auto-comment/scripts/update-registry-optimized.js`

**Key Improvements:**
- âœ… Async file operations (non-blocking)
- âœ… Registry caching (5s TTL)
- âœ… Atomic file writes
- âœ… Better error handling

**Usage:**

```bash
# Basic usage
node governance/dimensions/81-auto-comment/scripts/update-registry-optimized.js \
  --event-id "auto-comment-123" \
  --status "success" \
  --workflow "CI Pipeline"

# Load from event file
node governance/dimensions/81-auto-comment/scripts/update-registry-optimized.js \
  --from-file

# With all parameters
node governance/dimensions/81-auto-comment/scripts/update-registry-optimized.js \
  --event-id "auto-comment-456" \
  --status "failure" \
  --workflow "Test Suite" \
  --commit "abc123" \
  --branch "main" \
  --pr-number "42" \
  --auto-fixed "true" \
  --error-type "linting" \
  --fix-type "auto-format"
```

**Performance Comparison:**

| Metric | Original | Optimized | Improvement |
|--------|----------|-----------|-------------|
| File I/O | Synchronous | Async | **Non-blocking** |
| Caching | None | 5s TTL | **Fewer reads** |
| Write Safety | Basic | Atomic | **Data integrity** |

---

## ðŸ§ª Benchmarking Tools

### Using Benchmark Utilities

```python
from tools.performance.benchmark_utils import benchmark, compare_performance

# Benchmark a single function
result = benchmark(
    my_function,
    arg1, arg2,
    iterations=10,
    warmup=2
)
print(result)

# Compare two implementations
compare_performance(
    original_function,
    optimized_function,
    test_data=my_test_data,
    iterations=5
)
```

### Running Built-in Benchmarks

```bash
# Run scanner benchmark
python tools/docs/scan_repo_generate_index_optimized.py --benchmark

# Compare original vs optimized (create your own script)
python -c "
from pathlib import Path
import sys
sys.path.insert(0, 'tools/docs')

from scan_repo_generate_index import scan_repository
from scan_repo_generate_index_optimized import scan_repository_parallel
from tools.performance.benchmark_utils import compare_performance

repo_root = Path('.')

# This will show the performance difference
compare_performance(
    lambda: scan_repository(repo_root, ['**/*.md']),
    lambda: scan_repository_parallel(repo_root, ['**/*.md'], max_workers=10),
    iterations=3
)
"
```

---

## ðŸ“Š Performance Patterns

### Pattern 1: Parallel Processing

**When to use:** Processing multiple independent items (files, records, etc.)

**Before:**
```python
results = []
for item in items:
    result = process_item(item)
    results.append(result)
```

**After:**
```python
from concurrent.futures import ThreadPoolExecutor

with ThreadPoolExecutor(max_workers=10) as executor:
    results = list(executor.map(process_item, items))
```

---

### Pattern 2: LRU Caching

**When to use:** Expensive computations called repeatedly with same inputs

**Before:**
```python
def expensive_function(arg):
    # Expensive computation
    return result
```

**After:**
```python
from functools import lru_cache

@lru_cache(maxsize=1000)
def expensive_function(arg):
    # Expensive computation
    return result
```

---

### Pattern 3: Pre-compiled Regex

**When to use:** Using same regex pattern multiple times

**Before:**
```python
for line in lines:
    if re.match(r'pattern', line):
        process(line)
```

**After:**
```python
PATTERN = re.compile(r'pattern')

for line in lines:
    if PATTERN.match(line):
        process(line)
```

---

### Pattern 4: Efficient Data Structures

**When to use:** Membership testing, lookups

**Before:**
```python
excluded = ['node_modules', 'dist', '__pycache__']
if item in excluded:  # O(n)
    continue
```

**After:**
```python
excluded = {'node_modules', 'dist', '__pycache__'}
if item in excluded:  # O(1)
    continue
```

---

### Pattern 5: Async File Operations

**When to use:** Node.js scripts doing file I/O

**Before:**
```javascript
const content = fs.readFileSync(path, 'utf-8');
const data = JSON.parse(content);
```

**After:**
```javascript
const fs = require('fs').promises;

const content = await fs.readFile(path, 'utf-8');
const data = JSON.parse(content);
```

---

## ðŸŽ¯ Quick Wins Checklist

When reviewing code for performance, check:

- [ ] Are file operations blocking? â†’ Use async/parallel
- [ ] Are there nested loops? â†’ Can they be flattened?
- [ ] Are expensive functions called repeatedly? â†’ Add caching
- [ ] Are regex patterns compiled in loops? â†’ Pre-compile
- [ ] Are lists used for membership testing? â†’ Use sets
- [ ] Is JSON parsed multiple times? â†’ Parse once, cache
- [ ] Are large collections iterated multiple times? â†’ Combine iterations
- [ ] Are there synchronous operations in event handlers? â†’ Make async

---

## ðŸ“ˆ Measuring Impact

Always measure before and after:

```bash
# Before optimization
time python tools/docs/scan_repo_generate_index.py

# After optimization
time python tools/docs/scan_repo_generate_index_optimized.py --benchmark
```

Look for:
- **Execution time** reduction
- **Throughput** improvement
- **Memory usage** stability
- **CPU utilization** efficiency

---

## ðŸ”— Related Documentation

- [PERFORMANCE_ANALYSIS.md](./PERFORMANCE_ANALYSIS.md) - Detailed analysis
- [Python Performance Tips](https://wiki.python.org/moin/PythonSpeed/PerformanceTips)
- [Node.js Best Practices](https://github.com/goldbergyoni/nodebestpractices)

---

## ðŸ’¡ Tips

1. **Always profile first** - Don't optimize blindly
2. **Focus on hotspots** - 80/20 rule applies
3. **Maintain readability** - Don't sacrifice clarity for minor gains
4. **Test correctness** - Optimized code must produce same results
5. **Document changes** - Explain why optimizations were made

---

**Last Updated:** 2025-12-13  
**Maintainer:** Platform Team
