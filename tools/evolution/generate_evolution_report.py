#!/usr/bin/env python3
"""
generate_evolution_report.py

ç›®çš„ï¼š
  - è®€å– config/system-evolution.yaml
  - å˜—è©¦å¾æ²»ç†/æƒæè¼¸å‡ºä¸­å–å¾—æŒ‡æ¨™ï¼š
      - language_violations_total
      - semgrep_high_total
      - playbook_coverage_ratio
  - æ ¹æ“šç›®æ¨™èˆ‡æ¬Šé‡ç®—å‡º 0~100 åˆ†çš„æ¼”åŒ–å¥åº·åº¦
  - è¼¸å‡ºï¼š
      - knowledge/evolution-state.yaml   (æ©Ÿå™¨å¯è®€)
      - docs/SYSTEM_EVOLUTION_REPORT.md (äººé¡å¯è®€)

ä¾è³´ï¼š
  - PyYAML: pip install pyyaml
"""

import json
import re
from datetime import UTC, datetime
from pathlib import Path
from typing import Any

import yaml

ROOT = Path(__file__).resolve().parents[2]  # unmanned-island æ ¹ç›®éŒ„
CONFIG_PATH = ROOT / "config/system-evolution.yaml"


def load_yaml(path: Path) -> dict[str, Any]:
    """Load a YAML configuration file.

    Args:
        path: Absolute path to the YAML file that should be read.

    Returns:
        Parsed YAML content as a dictionary. An empty dictionary is returned if
        the file is empty.

    Raises:
        FileNotFoundError: If the YAML file does not exist at the given path.
    """
    if not path.exists():
        raise FileNotFoundError(f"YAML not found: {path}")
    with path.open("r", encoding="utf-8") as f:
        return yaml.safe_load(f) or {}


def safe_load_yaml(path: Path) -> dict[str, Any]:
    """Safely load YAML content if the file exists.

    Unlike :func:`load_yaml`, this helper never raises if the file is missing
    and instead returns an empty dictionary. It is intended for optional inputs
    where callers want best-effort loading.

    Args:
        path: Path to an optional YAML file.

    Returns:
        Parsed YAML content or an empty dictionary if the file is absent or
        empty.
    """
    if not path.exists():
        return {}
    with path.open("r", encoding="utf-8") as f:
        try:
            return yaml.safe_load(f) or {}
        except yaml.YAMLError:
            # Keep the pipeline resilient when YAML is malformed.
            return {}


def load_json(path: Path) -> Any:
    """Load JSON data if available.

    Args:
        path: Absolute path to the JSON document.

    Returns:
        Parsed JSON content (could be a dict, list, etc.), or an empty dictionary when the file is missing or cannot be decoded.
    """
    if not path.exists():
        return {}

    try:
        with path.open("r", encoding="utf-8") as f:
            return json.load(f)
    except json.JSONDecodeError:
        # Keep the pipeline resilient when scanning outputs are malformed.
        return {}


def count_language_violations(report_path: Path) -> int:
    """
    Count language governance violations in a markdown report.

    The function assumes each violation is represented on its own line in the
    following format: ``- **path/to/file.ts** â€” reason...``.

    Args:
        report_path: Path to the language governance report markdown file.

    Returns:
        Total number of violations detected in the report. Returns ``0`` when
        the file cannot be found.
    """
    if not report_path.exists():
        return 0

    pattern = re.compile(r"^- \*\*(.+?)\*\* â€”")
    count = 0
    with report_path.open("r", encoding="utf-8") as f:
        for line in f:
            if pattern.match(line.strip()):
                count += 1
    return count


def count_semgrep_high(semgrep_path: Path) -> int:
    """Count Semgrep findings with high severity.

    Args:
        semgrep_path: Path to the Semgrep JSON report generated by the scan.

    Returns:
        Number of findings labeled as HIGH or ERROR severity. Returns ``0`` if
        the report file does not exist or is empty.
    """
    if not semgrep_path.exists():
        return 0

    data = load_json(semgrep_path)
    results = data.get("results", [])
    if not isinstance(results, list):
        return 0
    high = 0
    for r in results:
        severity = (
            r.get("extra", {}).get("severity", "") or ""
        ).upper()
        if severity == "ERROR" or severity == "HIGH":
            high += 1
    return high


def compute_playbook_coverage(cluster_heatmap_path: Path, playbooks_root: Path) -> float:
    """
    æ¦‚å¿µï¼š
      - å¾ cluster-heatmap.json æŠ½å‡ºæ‰€æœ‰ clusters åç¨±ï¼ˆæ‰å¹³çµæ§‹ï¼Œå¦‚ "core/", "services/" ç­‰ï¼‰
      - æª¢æŸ¥ 03_refactor åº•ä¸‹æ˜¯å¦æœ‰å°æ‡‰ *_refactor.md
      - å›å‚³ covered / total æ¯”ä¾‹

    è‹¥ cluster_heatmap / playbooks_root ä»»ä¸€ä¸å­˜åœ¨ â†’ å›å‚³ 0.0ï¼ˆä»£è¡¨ç›®å‰é‚„æ²’æœ‰é€™å±¤æ²»ç†ï¼‰

    Args:
        cluster_heatmap_path: Path to the cluster heatmap JSON file produced by
            the hotspot analysis.
        playbooks_root: Directory containing refactor playbooks organized by
            cluster domain.

    Returns:
        Coverage ratio between clusters with at least one refactor playbook and
        the total number of clusters.
    """
    if (not cluster_heatmap_path.exists()) or (not playbooks_root.exists()):
        return 0.0

    data = load_json(cluster_heatmap_path)
    if not isinstance(data, dict) or not data:
        return 0.0

    # å¯¦éš›æ ¼å¼æ˜¯æ‰å¹³å­—å…¸ï¼š
    # { "core/": {...}, "services/": {...}, ... }
    clusters = list(data.keys())

    if not clusters:
        return 0.0

    # æª¢æŸ¥å°æ‡‰çš„ playbook æª”æ˜¯å¦å­˜åœ¨ï¼š
    # ç´„å®šï¼šcluster 'core/' â†’ playbook æ‡‰åœ¨ docs/refactor_playbooks/03_refactor/core/*_refactor.md
    covered = 0
    for cluster_key in clusters:
        # ç§»é™¤å°¾éš¨æ–œç·šä»¥ç²å¾—ç›®éŒ„åç¨±
        domain = cluster_key.rstrip("/")
        playbook_dir = playbooks_root / domain

        # å¯¬é¬†åŒ¹é…ï¼šæ‰¾åº•ä¸‹ä»»ä½• *_refactor.md å³ç®—æœ‰ playbookï¼ˆä½ ä¹‹å¾Œå¯ä»¥æ”¹å¾—æ›´åš´æ ¼ï¼‰
        if playbook_dir.exists():
            candidates = list(playbook_dir.glob("*_refactor.md"))
            if candidates:
                covered += 1

    return covered / len(clusters)


def score_metric(value: float, target: float, direction: str) -> float:
    """
    æ ¹æ“šæ–¹å‘èˆ‡ç›®æ¨™ï¼Œè¨ˆç®— 0~100 åˆ†ï¼š
      - lower_is_better: value <= target â†’ 100ï¼›è¶…éå‰‡æŒ‰æ¯”ä¾‹ä¸‹é™ï¼ˆç°¡åŒ–ç‰ˆæœ¬ï¼‰
      - higher_is_better: value >= target â†’ 100ï¼›ä½æ–¼å‰‡æŒ‰æ¯”ä¾‹ä¸‹é™

    Args:
        value: Observed metric value.
        target: Desired target for the metric.
        direction: Whether a higher or lower value is preferred. Accepts
            ``"lower_is_better"`` or ``"higher_is_better"``.

    Returns:
        Normalized score between 0 and 100 representing progress toward the
        target.
    """
    if direction == "lower_is_better":
        if value <= target:
            return 100.0
        # ç°¡å–®å£“ç¸®ï¼šç•¶ value æ˜¯ target çš„ 2 å€ â†’ 50 åˆ†ï¼›3 å€ â†’ ~33 åˆ†
        ratio = target / max(value, 1e-6)
        return max(0.0, min(100.0, ratio * 100.0))
    elif direction == "higher_is_better":
        if value >= target:
            return 100.0
        ratio = value / max(target, 1e-6)
        return max(0.0, min(100.0, ratio * 100.0))
    else:
        return 0.0


def main():
    """Generate the system evolution report and machine-readable state file.

    The pipeline performs four steps:

    1. Load configuration and metric sources from ``config/system-evolution.yaml``.
    2. Collect raw metrics such as language governance violations and Semgrep
       findings.
    3. Calculate weighted objective scores and persist an aggregate state to
       ``knowledge/evolution-state.yaml``.
    4. Render a human-friendly report at ``docs/SYSTEM_EVOLUTION_REPORT.md``
       summarizing metrics, objectives, and suggested next actions.
    """
    if not CONFIG_PATH.exists():
        raise SystemExit(f"Config not found: {CONFIG_PATH}")

    config = load_yaml(CONFIG_PATH)

    metrics_sources = config.get("metrics_sources", {})
    outputs = config.get("outputs", {})

    lang_report_path = ROOT / metrics_sources.get("language_governance_report", "")
    semgrep_path = ROOT / metrics_sources.get("semgrep_report", "")
    cluster_heatmap_path = ROOT / metrics_sources.get("cluster_heatmap", "")
    playbooks_root = ROOT / metrics_sources.get("refactor_playbooks_root", "")

    # 1) æ”¶é›†åŸå§‹æŒ‡æ¨™
    language_violations_total = count_language_violations(lang_report_path)
    semgrep_high_total = count_semgrep_high(semgrep_path)
    playbook_coverage_ratio = compute_playbook_coverage(cluster_heatmap_path, playbooks_root)

    metrics = {
        "language_violations_total": language_violations_total,
        "semgrep_high_total": semgrep_high_total,
        "playbook_coverage_ratio": playbook_coverage_ratio,
    }

    # 2) æ ¹æ“š config.objectives è¨ˆç®—å„ç›®æ¨™åˆ†æ•¸
    objectives = config.get("objectives", [])
    scored_objectives = []
    total_weight = 0.0
    weighted_sum = 0.0

    for obj in objectives:
        oid = obj.get("id")
        metric_name = obj.get("metric")
        target = obj.get("target", 0.0)
        direction = obj.get("direction", "lower_is_better")
        weight = float(obj.get("weight", 0.0))

        value = float(metrics.get(metric_name, 0.0))
        score = score_metric(value, float(target), direction)

        scored_objectives.append(
            {
                "id": oid,
                "name": obj.get("name", ""),
                "metric": metric_name,
                "value": value,
                "target": target,
                "direction": direction,
                "weight": weight,
                "score": round(score, 2),
            }
        )

        total_weight += weight
        weighted_sum += score * weight

    overall_score = 0.0
    if total_weight > 0:
        overall_score = weighted_sum / total_weight

    # 3) æº–å‚™ evolution-state.yamlï¼ˆæ©Ÿå™¨å¯è®€ï¼‰
    state = {
        "generated_at": datetime.now(UTC).isoformat().replace("+00:00", "Z"),
        "metrics": metrics,
        "objectives": scored_objectives,
        "overall_score": round(overall_score, 2),
        "config_version": config.get("version", "0.0.0"),
    }

    state_path = ROOT / outputs.get("state_yaml", "knowledge/evolution-state.yaml")
    state_path.parent.mkdir(parents=True, exist_ok=True)
    with state_path.open("w", encoding="utf-8") as f:
        yaml.safe_dump(state, f, sort_keys=False, allow_unicode=True)

    # 4) æº–å‚™ SYSTEM_EVOLUTION_REPORT.mdï¼ˆäººé¡å¯è®€ï¼‰
    report_path = ROOT / outputs.get("report_markdown", "docs/SYSTEM_EVOLUTION_REPORT.md")
    report_path.parent.mkdir(parents=True, exist_ok=True)

    lines = []
    lines.append("# ğŸ§¬ System Evolution Report\n")
    lines.append(f"- ç”Ÿæˆæ™‚é–“ï¼š{state['generated_at']}")
    lines.append(f"- Config ç‰ˆæœ¬ï¼š{state['config_version']}")
    lines.append(f"- ç¸½é«”æ¼”åŒ–å¥åº·åº¦ï¼š**{state['overall_score']}/100**\n")

    lines.append("## æŒ‡æ¨™æ¦‚è¦½\n")
    for k, v in metrics.items():
        lines.append(f"- `{k}` = `{v}`")
    lines.append("")

    lines.append("## ç›®æ¨™èˆ‡å¾—åˆ†\n")
    for obj in scored_objectives:
        lines.append(f"### {obj['name']} (`{obj['id']}`)")
        lines.append(f"- æŒ‡æ¨™ï¼š`{obj['metric']}`")
        lines.append(f"- ç›®å‰å€¼ï¼š`{obj['value']}`ï¼Œç›®æ¨™ï¼š`{obj['target']}`ï¼ˆ{obj['direction']}ï¼‰")
        lines.append(f"- æ¬Šé‡ï¼š{obj['weight']}")
        lines.append(f"- å¾—åˆ†ï¼š**{obj['score']}/100**\n")

    lines.append("## ä¸‹ä¸€æ­¥å»ºè­°ï¼ˆé«˜éšï¼‰\n")
    lines.append("> ä»¥ä¸‹æ˜¯æ ¹æ“šåˆ†æ•¸ç²—ç•¥çµ¦å‡ºçš„å„ªå…ˆç´šå»ºè­°ï¼Œä½ å¯ä»¥å†äº¤çµ¦ AI åšæ›´ç´°çš„ Refactor Playbookã€‚\n")

    for obj in scored_objectives:
        suggestion = ""
        if obj["id"] == "language-governance":
            suggestion = "å„ªå…ˆé‡å°é•è¦æœ€å¤šçš„ clusterï¼ˆä¾ language-governance-report æ’åºï¼‰ï¼Œæ›´æ–°å°æ‡‰çš„ 03_refactor åŠ‡æœ¬ä¸¦æ’å…¥ P0 ä»»å‹™ã€‚"
        elif obj["id"] == "security":
            suggestion = "åˆ—å‡ºå…¨éƒ¨ Semgrep HIGH å•é¡Œï¼Œå°æ‡‰åˆ° services/core çš„ clusterï¼Œå»ºç«‹æˆ–æ›´æ–°é€™äº›å€åŸŸçš„å®‰å…¨é‡æ§‹ Playbookã€‚"
        elif obj["id"] == "refactor-playbook-coverage":
            suggestion = "æ‰¾å‡º cluster-heatmap ä¸­æ²’æœ‰å°æ‡‰ 03_refactor Playbook çš„ clusterï¼Œç‚ºå…¶å»ºç«‹æœ€å°å¯ç”¨çš„é‡æ§‹åŠ‡æœ¬ã€‚"
        else:
            suggestion = "æ ¹æ“šæ­¤ç›®æ¨™çš„ç•¶å‰å¾—åˆ†èˆ‡æ¬Šé‡ï¼Œå®‰æ’é©ç•¶çš„ Refactor è¿­ä»£ã€‚"

        lines.append(f"- `{obj['id']}`ï¼ˆ{obj['name']}ï¼‰ï¼šç›®å‰å¾—åˆ† {obj['score']}/100 â†’ {suggestion}")

    lines.append("")
    lines.append("---")
    lines.append("æœ¬å ±å‘Šç”± `tools/evolution/generate_evolution_report.py` è‡ªå‹•ç”Ÿæˆã€‚")

    with report_path.open("w", encoding="utf-8") as f:
        f.write("\n".join(lines))

    print(f"[System Evolution] ç‹€æ…‹å·²æ›´æ–°ï¼š{state_path}")
    print(f"[System Evolution] å ±å‘Šå·²ç”Ÿæˆï¼š{report_path}")
    print(f"[System Evolution] ç¸½é«”æ¼”åŒ–å¥åº·åº¦ï¼š{state['overall_score']}/100")


if __name__ == "__main__":
    main()
