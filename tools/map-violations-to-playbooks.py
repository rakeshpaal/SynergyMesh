#!/usr/bin/env python3
"""
Map Language Governance Violations to Refactor Playbooks
å°‡èªè¨€æ²»ç†é•è¦æ˜ å°„åˆ°é‡æ§‹åŠ‡æœ¬

Maps language governance violations to corresponding refactor playbooks
for display in CI/CD workflows and dashboards.
"""

import argparse
import json
from collections import defaultdict
from pathlib import Path

import yaml


def load_index(index_path: Path) -> dict:
    """Load the refactor playbook index.

    Args:
        index_path: Path to ``index.yaml`` that describes available clusters and
            their associated playbooks.

    Returns:
        Parsed index content as a dictionary. Returns an empty dictionary when
        the index file cannot be found or decoded.
    """
    try:
        with open(index_path) as f:
            return yaml.safe_load(f) or {}
    except (FileNotFoundError, yaml.YAMLError):
        return {}


def load_hotspot_data(hotspot_path: Path) -> list:
    """Load violation hotspot data from JSON.

    Args:
        hotspot_path: Path to ``hotspot.json`` generated by the governance
            scanning workflow.

    Returns:
        List of violation records. Returns an empty list if the file is missing
        or invalid.
    """
    try:
        with open(hotspot_path) as f:
            return json.load(f)
    except (FileNotFoundError, json.JSONDecodeError):
        return []


def map_file_to_cluster(file_path: str, clusters: list) -> dict | None:
    """
    Find which cluster a file belongs to based on directory prefix.
    
    Examples:
        core/legacy_module/old_api.php -> core/architecture-stability
        services/gateway/router.lua -> services/gateway
        automation/autonomous/flight_controller.lua -> automation/autonomous
    """
    for cluster in clusters:
        cluster_id = cluster['cluster_id']
        domain = cluster['domain']
        
        # Match file path to cluster domain
        if file_path.startswith(domain + '/'):
            return cluster
    
    return None


def generate_summary(hotspot_data: list, index: dict, repo_root: Path) -> str:
    """Generate markdown summary linking violations to playbooks.

    Args:
        hotspot_data: List of violation records sourced from the hotspot report.
        index: Parsed index data that contains cluster metadata and playbook
            mappings.
        repo_root: Repository root used to build relative links.

    Returns:
        Markdown-formatted string that groups violations by cluster, shows
        severity breakdowns, and links to relevant refactor playbooks.
    """
    clusters_data = index.get('clusters', []) if isinstance(index, dict) else []
    
    summary = ["# èªè¨€æ²»ç†é•è¦èˆ‡é‡æ§‹åŠ‡æœ¬å°æ‡‰\n"]
    summary.append("> Language Governance Violations Mapped to Refactor Playbooks\n")
    summary.append("---\n\n")
    
    # Group violations by cluster
    cluster_violations = defaultdict(lambda: {'cluster': None, 'violations': []})
    
    for violation in hotspot_data:
        file_path = violation.get('file', '')
        cluster = map_file_to_cluster(file_path, clusters_data)
        
        if cluster:
            cluster_id = cluster['cluster_id']
            if cluster_violations[cluster_id]['cluster'] is None:
                cluster_violations[cluster_id]['cluster'] = cluster
            cluster_violations[cluster_id]['violations'].append(violation)
    
    # Generate summary for each cluster
    if not cluster_violations:
        summary.append("âœ… **æ²’æœ‰ç™¼ç¾èªè¨€æ²»ç†é•è¦** (No violations found)\n")
        return ''.join(summary)
    
    summary.append("## ğŸ“Š ç¸½è¦½ (Overview)\n\n")
    summary.append(f"- **Total Clusters Affected**: {len(cluster_violations)}\n")
    summary.append(f"- **Total Violations**: {sum(len(data['violations']) for data in cluster_violations.values())}\n")
    summary.append("\n---\n\n")
    
    for cluster_id, data in sorted(cluster_violations.items()):
        cluster = data['cluster']
        violations = data['violations']
        
        # Severity breakdown
        severity_counts = defaultdict(int)
        for v in violations:
            severity_counts[v.get('severity', 'UNKNOWN')] += 1
        
        summary.append(f"## ğŸ“ {cluster_id}\n\n")
        
        # Link to refactor playbook
        refactor_file = cluster.get('refactor_file', '')
        if refactor_file:
            playbook_link = f"docs/refactor_playbooks/03_refactor/{refactor_file}"
            summary.append(f"**ğŸ”— é‡æ§‹åŠ‡æœ¬ (Refactor Playbook)**: [{refactor_file}]({playbook_link})\n\n")
        
        # Severity breakdown
        summary.append("**åš´é‡æ€§åˆ†ä½ˆ (Severity Breakdown)**:\n")
        for severity in ['CRITICAL', 'HIGH', 'MEDIUM', 'LOW']:
            count = severity_counts.get(severity, 0)
            if count > 0:
                emoji = {'CRITICAL': 'ğŸ”´', 'HIGH': 'ğŸŸ ', 'MEDIUM': 'ğŸŸ¡', 'LOW': 'ğŸŸ¢'}.get(severity, 'âšª')
                summary.append(f"- {emoji} {severity}: {count}\n")
        summary.append("\n")
        
        # Violation list (show top 5)
        summary.append("**é•è¦æ¸…å–® (Violations)**:\n\n")
        for i, v in enumerate(violations[:5], 1):
            file_path = v.get('file', 'unknown')
            score = v.get('score', 0)
            reason = v.get('reason', 'No reason provided')
            severity = v.get('severity', 'UNKNOWN')
            
            emoji = {'CRITICAL': 'ğŸ”´', 'HIGH': 'ğŸŸ ', 'MEDIUM': 'ğŸŸ¡', 'LOW': 'ğŸŸ¢'}.get(severity, 'âšª')
            summary.append(f"{i}. {emoji} **`{file_path}`** (score: {score})\n")
            summary.append(f"   - {reason}\n")
        
        if len(violations) > 5:
            summary.append(f"\n_...ä»¥åŠ {len(violations) - 5} å€‹å…¶ä»–é•è¦ (and {len(violations) - 5} more violations)_\n")
        
        summary.append("\n---\n\n")
    
    # Add footer with next steps
    summary.append("## ğŸš€ ä¸‹ä¸€æ­¥ (Next Steps)\n\n")
    summary.append("1. æŸ¥çœ‹å°æ‡‰çš„é‡æ§‹åŠ‡æœ¬ (Review corresponding refactor playbooks)\n")
    summary.append("2. åŸ·è¡Œ P0 å„ªå…ˆç´šä»»å‹™ (Execute P0 priority tasks)\n")
    summary.append("3. ä½¿ç”¨ Auto-Fix Bot è‡ªå‹•ä¿®å¾©é©åˆçš„é …ç›® (Use Auto-Fix Bot for eligible items)\n")
    summary.append("4. äººå·¥å¯©æŸ¥éœ€è¦å¯©æŸ¥çš„è®Šæ›´ (Manual review for changes requiring human oversight)\n\n")
    
    return ''.join(summary)


def main():
    parser = argparse.ArgumentParser(
        description='Map language governance violations to refactor playbooks'
    )
    parser.add_argument(
        '--hotspot',
        type=str,
        default='apps/web/public/data/hotspot.json',
        help='Path to hotspot.json file (relative to repo root)'
    )
    parser.add_argument(
        '--index',
        type=str,
        default='docs/refactor_playbooks/03_refactor/index.yaml',
        help='Path to index.yaml file (relative to repo root)'
    )
    parser.add_argument(
        '--output',
        type=str,
        default='governance-summary.md',
        help='Output markdown file path'
    )
    parser.add_argument(
        '--repo-root',
        type=str,
        default='.',
        help='Repository root directory'
    )
    
    args = parser.parse_args()
    
    repo_root = Path(args.repo_root).resolve()
    hotspot_path = repo_root / args.hotspot
    index_path = repo_root / args.index
    output_path = repo_root / args.output
    
    # Load data
    print(f"ğŸ“‚ Loading hotspot data from: {hotspot_path}")
    hotspot_data = load_hotspot_data(hotspot_path)
    print(f"   Found {len(hotspot_data)} violations")
    
    print(f"ğŸ“‚ Loading index from: {index_path}")
    index = load_index(index_path)
    print(f"   Found {len(index.get('clusters', []))} clusters")
    
    # Generate summary
    print("ğŸ”„ Generating summary...")
    summary = generate_summary(hotspot_data, index, repo_root)
    
    # Write output
    print(f"ğŸ’¾ Writing output to: {output_path}")
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(summary)
    
    print(f"âœ… Done! Summary written to {output_path}")


if __name__ == '__main__':
    main()
