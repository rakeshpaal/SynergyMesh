#!/usr/bin/env python3
"""
Master Orchestrator - ä¸»æ§å¼•æ“å•Ÿå‹•å™¨

æ ¹ç›®éŒ„ç´šåˆ¥çš„å…¨è‡ªå‹•åŒ–å¼•æ“èª¿åº¦ä¸­å¿ƒã€‚
100% æ©Ÿå™¨è‡ªä¸»æ“ä½œï¼Œè² è²¬ï¼š

1. å¼•æ“ç”Ÿå‘½é€±æœŸç®¡ç†
2. å¼•æ“è‡ªå‹•ç™¼ç¾èˆ‡è¨»å†Š
3. ä»»å‹™èª¿åº¦èˆ‡åˆ†ç™¼
4. ç®¡é“ç·¨æ’
5. å¥åº·ç›£æ§èˆ‡è‡ªæˆ‘ä¿®å¾©
6. äº‹ä»¶ç¸½ç·šå”èª¿

Project Structure Context / å°ˆæ¡ˆçµæ§‹å®šä½
========================================

æœ¬æ¨¡çµ„ä½æ–¼ Unmanned Island System çš„ä¸‰å¤§å­ç³»çµ±æ¶æ§‹ä¸­ï¼š

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ğŸï¸ Unmanned Island System                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  ğŸ”· SynergyMesh Core        âš–ï¸ Structural Governance       â”‚
â”‚     (core/)                    (governance/, config/)       â”‚
â”‚     â€¢ AI decision engine       â€¢ Schema namespaces          â”‚
â”‚     â€¢ Service registries       â€¢ Ten-stage pipeline         â”‚
â”‚     â€¢ Safety mechanisms        â€¢ SLSA provenance            â”‚
â”‚                                                             â”‚
â”‚  ğŸš Autonomous/Drone Stack  âŸµ ğŸ¯ THIS MODULE               â”‚
â”‚     (automation/)                 (tools/automation/)       â”‚
â”‚     â€¢ Five-skeleton framework    â€¢ Engine discovery         â”‚
â”‚     â€¢ Drone control              â€¢ & registration           â”‚
â”‚     â€¢ Self-driving integration   â€¢ Lifecycle management     â”‚
â”‚                                   â€¢ Task orchestration      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Architecture Role / æ¶æ§‹è§’è‰²
----------------------------
- **Layer**: Automation & Orchestration (è‡ªå‹•åŒ–èˆ‡ç·¨æ’å±¤)
- **Subsystem**: Autonomous Framework Support (è‡ªä¸»æ¡†æ¶æ”¯æ´)
- **Responsibilities**:
  * Discover and register automation engines from `automation/` subsystems
  * Coordinate with intelligent automation (`automation/intelligent/`)
  * Support autonomous framework skeletons (`automation/autonomous/`)
  * Interface with governance policies (`governance/policies/`)

Configuration Sources / é…ç½®ä¾†æº
--------------------------------
- Primary: `synergymesh.yaml` (root-level truth source)
- Governance: `config/system-manifest.yaml`, `config/unified-config-index.yaml`
- Engine configs: `tools/automation/engines/*/engine.yaml`
- State persistence: `.automation_state/`

Related Documentation / ç›¸é—œæ–‡æª”
--------------------------------
- System Overview: README.md (ä¸‰ç³»çµ±è¦–åœ–)
- Architecture Boundaries: docs/architecture/repo-map.md
- Automation Layer: automation/README.md
- Governance Integration: governance/README.md

Usage:
    # å•Ÿå‹•ä¸»æ§
    python master_orchestrator.py start

    # å•Ÿå‹•æ‰€æœ‰å¼•æ“
    python master_orchestrator.py start-all

    # æŸ¥çœ‹ç‹€æ…‹
    python master_orchestrator.py status

Version: 1.0.0
"""

import asyncio
import json
import yaml
import sys
import signal
import importlib
import importlib.util
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Type, Set, Callable, Union
from dataclasses import dataclass, field, asdict
from enum import Enum, auto
import logging
import argparse

from engine_base import (
    BaseEngine, EngineConfig, EngineState, EngineType,
    ExecutionMode, Priority, EngineEvent, TaskResult, HealthStatus
)

# ============================================================================
# å¸¸æ•¸å®šç¾©
# ============================================================================

BASE_PATH = Path(__file__).parent.parent.parent
CONFIG_PATH = BASE_PATH / "config" / "automation"
ENGINES_PATH = BASE_PATH / "tools" / "automation" / "engines"
STATE_PATH = BASE_PATH / ".automation_state"

# ============================================================================
# é…ç½®è³‡æ–™çµæ§‹
# ============================================================================

@dataclass
class OrchestratorConfig:
    """ä¸»æ§é…ç½®"""
    name: str = "SynergyMesh-Orchestrator"
    version: str = "1.0.0"

    # è‡ªå‹•åŒ–è¨­å®š
    auto_discover: bool = True              # è‡ªå‹•ç™¼ç¾å¼•æ“
    auto_start_engines: bool = True         # è‡ªå‹•å•Ÿå‹•å¼•æ“
    auto_recover: bool = True               # è‡ªå‹•æ¢å¾©
    auto_scale: bool = False                # è‡ªå‹•æ“´ç¸®

    # åŸ·è¡Œè¨­å®š
    max_concurrent_engines: int = 50        # æœ€å¤§ä¸¦è¡Œå¼•æ“æ•¸
    health_check_interval: float = 30.0     # å¥åº·æª¢æŸ¥é–“éš”
    garbage_collect_interval: float = 300.0 # åƒåœ¾å›æ”¶é–“éš”

    # è·¯å¾‘é…ç½®
    engines_paths: List[str] = field(default_factory=lambda: [
        "tools/automation/engines",
        "tools/refactor",
    ])
    config_path: str = "config/automation"
    state_path: str = ".automation_state"

    # äº‹ä»¶è¨­å®š
    event_queue_size: int = 10000
    event_retention_hours: int = 24

@dataclass
class PipelineConfig:
    """ç®¡é“é…ç½®"""
    pipeline_id: str
    name: str
    description: str = ""
    stages: List[Dict[str, Any]] = field(default_factory=list)
    triggers: List[Dict[str, Any]] = field(default_factory=list)
    enabled: bool = True

@dataclass
class EngineRegistration:
    """å¼•æ“è¨»å†Šè³‡è¨Š"""
    engine_id: str
    engine_name: str
    engine_class: str
    engine_type: EngineType
    module_path: str
    config: EngineConfig
    instance: Optional[BaseEngine] = None
    registered_at: str = ""
    last_health_check: str = ""
    healthy: bool = False

# ============================================================================
# äº‹ä»¶ç¸½ç·š
# ============================================================================

class EventBus:
    """
    äº‹ä»¶ç¸½ç·š - å¼•æ“é–“é€šä¿¡ä¸­å¿ƒ
    """

    def __init__(self, max_size: int = 10000):
        self._queue: asyncio.Queue = asyncio.Queue(maxsize=max_size)
        self._subscribers: Dict[str, List[Callable]] = {}
        self._history: List[EngineEvent] = []
        self._max_history = 1000
        self._running = False
        self._logger = logging.getLogger("event_bus")

    async def start(self):
        """å•Ÿå‹•äº‹ä»¶ç¸½ç·š"""
        self._running = True
        asyncio.create_task(self._dispatch_loop())
        self._logger.info("äº‹ä»¶ç¸½ç·šå·²å•Ÿå‹•")

    async def stop(self):
        """åœæ­¢äº‹ä»¶ç¸½ç·š"""
        self._running = False

    async def publish(self, event: EngineEvent):
        """ç™¼å¸ƒäº‹ä»¶"""
        await self._queue.put(event)

        # è¨˜éŒ„æ­·å²
        self._history.append(event)
        if len(self._history) > self._max_history:
            self._history = self._history[-self._max_history:]

    def subscribe(self, event_type: str, handler: Callable):
        """è¨‚é–±äº‹ä»¶"""
        if event_type not in self._subscribers:
            self._subscribers[event_type] = []
        self._subscribers[event_type].append(handler)

    def unsubscribe(self, event_type: str, handler: Callable):
        """å–æ¶ˆè¨‚é–±"""
        if event_type in self._subscribers:
            self._subscribers[event_type].remove(handler)

    async def _dispatch_loop(self):
        """äº‹ä»¶åˆ†ç™¼å¾ªç’°"""
        while self._running:
            try:
                event = await asyncio.wait_for(self._queue.get(), timeout=1.0)
                await self._dispatch(event)
            except asyncio.TimeoutError:
                continue
            except Exception as e:
                self._logger.error(f"äº‹ä»¶åˆ†ç™¼éŒ¯èª¤: {e}")

    async def _dispatch(self, event: EngineEvent):
        """åˆ†ç™¼å–®ä¸€äº‹ä»¶"""
        handlers = self._subscribers.get(event.event_type, [])
        handlers.extend(self._subscribers.get("*", []))  # å…¨å±€è¨‚é–±è€…

        for handler in handlers:
            try:
                if asyncio.iscoroutinefunction(handler):
                    await handler(event)
                else:
                    handler(event)
            except Exception as e:
                self._logger.error(f"äº‹ä»¶è™•ç†éŒ¯èª¤: {e}")

    def get_history(self, event_type: str = None, limit: int = 100) -> List[EngineEvent]:
        """ç²å–äº‹ä»¶æ­·å²"""
        events = self._history
        if event_type:
            events = [e for e in events if e.event_type == event_type]
        return events[-limit:]

# ============================================================================
# å¼•æ“è¨»å†Šä¸­å¿ƒ
# ============================================================================

class EngineRegistry:
    """
    å¼•æ“è¨»å†Šä¸­å¿ƒ - ç®¡ç†æ‰€æœ‰å¼•æ“çš„è¨»å†Šèˆ‡ç™¼ç¾
    
    Engine Registry - Central Hub for Engine Discovery & Lifecycle Management
    
    Architecture Context / æ¶æ§‹å®šä½
    ==============================
    
    The EngineRegistry serves as the **service registry component** within the 
    Unmanned Island System's automation orchestration layer, bridging multiple
    subsystems:
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                    Master Orchestrator                           â”‚
    â”‚                    (tools/automation/)                           â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚                                                                  â”‚
    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
    â”‚   â”‚  EngineRegistry     â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”‚  Discovery System   â”‚      â”‚
    â”‚   â”‚  (This Class)       â”‚         â”‚  â€¢ Python modules   â”‚      â”‚
    â”‚   â”‚                     â”‚         â”‚  â€¢ YAML configs     â”‚      â”‚
    â”‚   â”‚  â€¢ Registration     â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
    â”‚   â”‚  â€¢ Lifecycle        â”‚                                      â”‚
    â”‚   â”‚  â€¢ Type filtering   â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
    â”‚   â”‚  â€¢ Health tracking  â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”‚  Engine Instances   â”‚      â”‚
    â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚  automation/*       â”‚      â”‚
    â”‚            â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
    â”‚            â”‚                                                    â”‚
    â”‚            â–¼                                                    â”‚
    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                      â”‚
    â”‚   â”‚  MasterOrchestrator â”‚  Coordinates with:                   â”‚
    â”‚   â”‚  â€¢ Task dispatch    â”‚  â€¢ automation/intelligent/           â”‚
    â”‚   â”‚  â€¢ Health monitor   â”‚  â€¢ automation/autonomous/            â”‚
    â”‚   â”‚  â€¢ Event bus        â”‚  â€¢ automation/hyperautomation/       â”‚
    â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    Integration Points / æ•´åˆæ¥å£
    -----------------------------
    
    1. **Discovery Integration** (ç™¼ç¾æ•´åˆ):
       - Scans `automation/` for BaseEngine subclasses
       - Loads engine.yaml configs from engine directories
       - Interfaces with governance schemas in `config/`
    
    2. **SynergyMesh Core Integration** (æ ¸å¿ƒæ•´åˆ):
       - Provides engine metadata to AI decision engine (`core/`)
       - Supports virtual expert coordination
       - Reports health status for monitoring
    
    3. **Governance Integration** (æ²»ç†æ•´åˆ):
       - Validates engine configs against governance schemas
       - Ensures SLSA provenance for discovered engines
       - Enforces policy constraints from `governance/policies/`
    
    4. **Autonomous Framework Support** (è‡ªä¸»æ¡†æ¶æ”¯æ´):
       - Registers five-skeleton engines (`automation/autonomous/`)
       - Coordinates drone control engines
       - Manages ROS/C++ bridge engines
    
    Key Responsibilities / æ ¸å¿ƒè·è²¬
    -------------------------------
    
    - **Engine Discovery**: Automatic detection of engines via filesystem scan
    - **Registration Management**: Maintain engine inventory with metadata
    - **Type Classification**: Support filtering by EngineType enum
    - **Health Tracking**: Monitor engine lifecycle states
    - **Query Interface**: Provide lookup by ID, type, state, or tags
    
    Configuration Sources / é…ç½®ä¾†æº
    --------------------------------
    
    - Discovery paths: Defined in MasterOrchestrator initialization
    - Engine configs: `tools/automation/engines/*/engine.yaml`
    - Governance schemas: `config/system-manifest.yaml`
    - State persistence: `.automation_state/registry.json`
    
    Thread Safety / ç·šç¨‹å®‰å…¨
    -----------------------
    
    âš ï¸ This class is NOT thread-safe by design. It's intended for use within
    the asyncio event loop of the MasterOrchestrator. For concurrent access,
    wrap operations in asyncio locks or use separate registry instances.
    
    See Also / åƒè€ƒæ–‡æª”
    -------------------
    
    - `automation/README.md` - Automation layer overview
    - `docs/architecture/repo-map.md` - System boundaries
    - `engine_base.py` - BaseEngine interface definition
    - `config/system-manifest.yaml` - Module registration schema
    """

    def __init__(self):
        self._engines: Dict[str, EngineRegistration] = {}
        self._engine_classes: Dict[str, Type[BaseEngine]] = {}
        self._logger = logging.getLogger("engine_registry")

    def register_class(self, name: str, engine_class: Type[BaseEngine]):
        """è¨»å†Šå¼•æ“é¡"""
        self._engine_classes[name] = engine_class
        self._logger.info(f"å¼•æ“é¡å·²è¨»å†Š: {name}")

    def register_engine(self, registration: EngineRegistration):
        """è¨»å†Šå¼•æ“å¯¦ä¾‹"""
        registration.registered_at = datetime.now().isoformat()
        self._engines[registration.engine_id] = registration
        self._logger.info(f"å¼•æ“å·²è¨»å†Š: {registration.engine_name} ({registration.engine_id})")

    def unregister_engine(self, engine_id: str):
        """å–æ¶ˆè¨»å†Šå¼•æ“"""
        if engine_id in self._engines:
            del self._engines[engine_id]
            self._logger.info(f"å¼•æ“å·²å–æ¶ˆè¨»å†Š: {engine_id}")

    def get_engine(self, engine_id: str) -> Optional[EngineRegistration]:
        """ç²å–å¼•æ“"""
        return self._engines.get(engine_id)

    def get_all_engines(self) -> List[EngineRegistration]:
        """ç²å–æ‰€æœ‰å¼•æ“"""
        return list(self._engines.values())

    def get_engines_by_type(self, engine_type: EngineType) -> List[EngineRegistration]:
        """æŒ‰é¡å‹ç²å–å¼•æ“"""
        return [e for e in self._engines.values() if e.engine_type == engine_type]

    def get_healthy_engines(self) -> List[EngineRegistration]:
        """ç²å–å¥åº·çš„å¼•æ“"""
        return [e for e in self._engines.values() if e.healthy]

    def get_engine_class(self, name: str) -> Optional[Type[BaseEngine]]:
        """ç²å–å¼•æ“é¡"""
        return self._engine_classes.get(name)

    def discover_engines(self, search_paths: List[Path]) -> List[Dict[str, Any]]:
        """
        Automatically discover and collect engine metadata from specified directories.

        This method implements a dual-strategy engine discovery system that scans
        filesystem paths for both Python modules containing BaseEngine subclasses
        and YAML configuration files defining engine specifications.

        Discovery Strategies:
        ---------------------
        1. **Python Module Introspection**:
           - Recursively scans for all `*.py` files in search paths
           - Excludes files starting with underscore (private modules)
           - Dynamically loads modules and inspects for BaseEngine subclasses
           - Extracts engine metadata (class name, module path, engine type)

        2. **YAML Configuration Discovery**:
           - Recursively searches for `engine.yaml` configuration files
           - Loads and parses YAML structure
           - Augments config with file path for reference
           - Supports declarative engine definitions

        Parameters:
        -----------
        search_paths : List[Path]
            List of directory paths to search for engines. Non-existent paths
            are silently skipped without raising errors.

        Returns:
        --------
        List[Dict[str, Any]]
            List of discovered engine metadata dictionaries. Each dictionary
            contains engine configuration and registration information.

            For Python module discoveries, each dict contains:
            - `class_name` (str): Name of the BaseEngine subclass
            - `module_path` (str): Absolute path to the Python module file
            - `engine_type` (str): Engine type value from ENGINE_TYPE attribute
                                   or defaults to `EngineType.EXECUTION` (the enum value; if a string is returned, it is extracted via `.value`)

            For YAML config discoveries, each dict contains:
            - All fields defined in the YAML file
            - `config_path` (str): Absolute path to the configuration file

        Behavior:
        ---------
        - **Non-blocking**: Discovery failures are logged at DEBUG level and
          do not halt the overall discovery process.
          Note: Because failures are logged at DEBUG level, they may not be visible in production environments unless debug logging is enabled. This can make troubleshooting discovery issues more difficult.
        - **Recursive**: Searches entire directory trees using rglob patterns
        - **Safe**: Catches and handles module loading exceptions gracefully
        - **Deduplication**: Caller is responsible for handling duplicate
          discoveries (same engine found via both strategies)

        File Exclusions:
        ----------------
        - Python files starting with `_` (e.g., `__init__.py`, `_private.py`)
        - Directories without read permissions (silently skipped)

        Module Loading:
        ---------------
        - Uses `importlib.util.spec_from_file_location` for dynamic loading
        - Modules are loaded in isolated namespace to prevent conflicts
        - Only inspects module-level class definitions
        - Does not instantiate engines during discovery phase

        Error Handling:
        ---------------
        - Invalid Python syntax: Logged and skipped
        - Import errors: Logged and skipped
        - YAML parse errors: Logged and skipped
        - File permission errors: Silently skipped

        Example Usage:
        --------------
        >>> registry = EngineRegistry()
        >>> search_paths = [
        ...     Path("tools/automation/engines"),
        ...     Path("tools/refactor")
        ... ]
        >>> engines = registry.discover_engines(search_paths)
        >>> print(f"Discovered {len(engines)} engines")
        Discovered 5 engines
        >>> for engine in engines:
        ...     print(f"  - {engine.get('class_name')} from {engine.get('module_path')}")
          - ValidationEngine from /app/tools/automation/engines/validation.py
          - GenerationEngine from /app/tools/automation/engines/generation.py

        Performance Considerations:
        ---------------------------
        - Discovery time scales with number of files in search paths
        - Module loading incurs one-time import cost per Python file
        - Recommended to cache results and re-discover only on file changes
        - Consider using file system watchers for production deployments

        Thread Safety:
        --------------
        This method is NOT thread-safe. Callers must ensure external
        synchronization if called from multiple threads concurrently.

        See Also:
        ---------
        - `_inspect_module()`: Internal method for Python module introspection
        - `register_engine()`: Register discovered engines for use
        - `EngineConfig`: Expected configuration structure for engines
        """
        discovered = []

        for search_path in search_paths:
            if not search_path.exists():
                continue

            # æœå°‹ Python æ¨¡çµ„
            for py_file in search_path.rglob("*.py"):
                if py_file.name.startswith('_'):
                    continue

                try:
                    engine_info = self._inspect_module(py_file)
                    if engine_info:
                        discovered.extend(engine_info)
                except Exception as e:
                    self._logger.debug(f"æª¢æŸ¥æ¨¡çµ„å¤±æ•— {py_file}: {e}")

            # æœå°‹é…ç½®æª”
            for config_file in search_path.rglob("engine.yaml"):
                try:
                    with open(config_file, 'r', encoding='utf-8') as f:
                        config = yaml.safe_load(f)
                    if config:
                        config['config_path'] = str(config_file)
                        discovered.append(config)
                except Exception as e:
                    self._logger.debug(f"è®€å–é…ç½®å¤±æ•— {config_file}: {e}")

        return discovered

    def _inspect_module(self, module_path: Path) -> List[Dict[str, Any]]:
        """
        INTERNAL: Inspect a Python module file to discover BaseEngine subclasses.

        This is a private/internal method. It dynamically loads a Python module and uses
        runtime introspection to identify all classes that inherit from BaseEngine, extracting
        metadata for registration.

        Do NOT call this method directly. Use the public `discover_engines()` method instead,
        which handles engine discovery and registration in a safe and supported manner.

        Parameters
        ----------
        module_path : Path
            Path to the Python module file (.py) to inspect.

        Returns
        -------
        List[Dict[str, Any]]
            List of metadata dictionaries for each discovered engine class, or an empty list.
        """
        Engine Class Criteria:
        ----------------------
        A class is considered a valid engine if ALL of these conditions are met:
        - Is a Python class (type instance)
        - Is a subclass of BaseEngine
        - Is NOT the BaseEngine class itself (no self-inheritance)
        - Class name does not start with underscore (public classes only)

        Metadata Extraction:
        --------------------
        - **class_name**: Directly from the class `__name__` attribute
        - **module_path**: Converted to string for JSON serialization
        - **engine_type**: String value extracted from the ENGINE_TYPE class 
                           attribute if present, otherwise defaults to the 
                           string value of EngineType.EXECUTION

        Error Handling:
        ---------------
        All exceptions during module loading and introspection are silently
        caught and ignored. **No exceptions are logged at all.**

        .. warning::
           This may make debugging difficult, as any errors (e.g., syntax errors,
           missing dependencies, or other failures) will be completely silent.
           Unlike ``discover_engines``, which logs exceptions at DEBUG level,
           this method does not log any errors during discovery.

        This ensures that:
        - Syntax errors in modules don't crash discovery
        - Missing dependencies don't halt the process
        - Malformed modules are gracefully skipped

        Common failure scenarios:
        - ImportError: Module has missing dependencies
        - SyntaxError: Module contains invalid Python syntax
        - AttributeError: Module has unexpected structure
        - FileNotFoundError: Module path is invalid (should not occur with proper caller)

        Security Considerations:
        ------------------------
        - **Code Execution**: This method executes arbitrary Python code from files
        - **Trust Boundary**: Only use with trusted module paths from controlled
          search directories
        - **Isolation**: Each module is loaded in a fresh namespace to prevent
          cross-contamination
        - **No Sandbox**: This method does NOT provide security sandboxing

        Performance Notes:
        ------------------
        - Module loading has O(n) complexity where n = file size
        - Class introspection is O(m) where m = number of module attributes
        - Each module is loaded only once per discovery cycle
        - Consider caching results for frequently inspected modules

        Example Discovered Metadata:
        ----------------------------
        >>> engines = registry._inspect_module(Path("engines/validator.py"))
        >>> print(engines)
        [
            {
                'class_name': 'ValidationEngine',
                'module_path': '/app/tools/automation/engines/validator.py',
                'engine_type': 'validation'
            },
            {
                'class_name': 'SyntaxValidationEngine',
                'module_path': '/app/tools/automation/engines/validator.py',
                'engine_type': 'validation'
            }
        ]

        See Also:
        ---------
        - `discover_engines()`: Public method that calls this for module discovery
        - `BaseEngine`: The base class that all engines must inherit from
        - `EngineType`: Enum defining valid engine type values
        """
        engines = []

        try:
            spec = importlib.util.spec_from_file_location(
                module_path.stem, module_path
            )
            if spec is None or spec.loader is None:
                return engines

            module = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(module)

            # å°‹æ‰¾ BaseEngine å­é¡
            for name, obj in vars(module).items():
                if (isinstance(obj, type) and
                    issubclass(obj, BaseEngine) and
                    obj is not BaseEngine and
                    not name.startswith('_')):

                    # ç²å–å¼•æ“è³‡è¨Š
                    engines.append({
                        "class_name": name,
                        "module_path": str(module_path),
                        "engine_type": getattr(obj, 'ENGINE_TYPE', EngineType.EXECUTION).value,
                    })

        except Exception as e:
            pass

        return engines

# ============================================================================
# å¼•æ“èª¿åº¦å™¨
# ============================================================================

class EngineScheduler:
    """
    å¼•æ“èª¿åº¦å™¨ - ä»»å‹™èª¿åº¦èˆ‡åˆ†ç™¼
    """

    def __init__(self, registry: EngineRegistry, event_bus: EventBus):
        self._registry = registry
        self._event_bus = event_bus
        self._task_queue: asyncio.PriorityQueue = asyncio.PriorityQueue()
        self._running = False
        self._logger = logging.getLogger("engine_scheduler")

    async def start(self):
        """å•Ÿå‹•èª¿åº¦å™¨"""
        self._running = True
        asyncio.create_task(self._schedule_loop())
        self._logger.info("èª¿åº¦å™¨å·²å•Ÿå‹•")

    async def stop(self):
        """åœæ­¢èª¿åº¦å™¨"""
        self._running = False

    async def schedule_task(self, task: Dict[str, Any], priority: Priority = Priority.NORMAL):
        """èª¿åº¦ä»»å‹™"""
        await self._task_queue.put((priority.value, task))

    async def _schedule_loop(self):
        """èª¿åº¦å¾ªç’°"""
        while self._running:
            try:
                _, task = await asyncio.wait_for(self._task_queue.get(), timeout=1.0)
                await self._dispatch_task(task)
            except asyncio.TimeoutError:
                continue
            except Exception as e:
                self._logger.error(f"èª¿åº¦éŒ¯èª¤: {e}")

    async def _dispatch_task(self, task: Dict[str, Any]):
        """åˆ†ç™¼ä»»å‹™"""
        target_engine_id = task.get("target_engine_id")
        target_engine_type = task.get("target_engine_type")

        # æ‰¾åˆ°åˆé©çš„å¼•æ“
        if target_engine_id:
            reg = self._registry.get_engine(target_engine_id)
            if reg and reg.instance and reg.healthy:
                await reg.instance.submit_task(task)
                return

        elif target_engine_type:
            engines = self._registry.get_engines_by_type(EngineType(target_engine_type))
            healthy_engines = [e for e in engines if e.healthy and e.instance]
            if healthy_engines:
                # è² è¼‰å‡è¡¡ (ç°¡å–®è¼ªè©¢)
                engine = healthy_engines[0]
                await engine.instance.submit_task(task)
                return

        self._logger.warning(f"æ‰¾ä¸åˆ°åˆé©çš„å¼•æ“åŸ·è¡Œä»»å‹™: {task.get('task_id')}")

# ============================================================================
# ç®¡é“åŸ·è¡Œå™¨
# ============================================================================

class PipelineExecutor:
    """
    ç®¡é“åŸ·è¡Œå™¨ - ç·¨æ’å¤šå¼•æ“å·¥ä½œæµ
    """

    def __init__(self, registry: EngineRegistry, scheduler: EngineScheduler):
        self._registry = registry
        self._scheduler = scheduler
        self._pipelines: Dict[str, PipelineConfig] = {}
        self._running_pipelines: Dict[str, Dict] = {}
        self._logger = logging.getLogger("pipeline_executor")

    def register_pipeline(self, config: PipelineConfig):
        """è¨»å†Šç®¡é“"""
        self._pipelines[config.pipeline_id] = config
        self._logger.info(f"ç®¡é“å·²è¨»å†Š: {config.name}")

    async def execute_pipeline(self, pipeline_id: str, input_data: Dict = None) -> Dict[str, Any]:
        """åŸ·è¡Œç®¡é“"""
        pipeline = self._pipelines.get(pipeline_id)
        if not pipeline:
            return {"success": False, "error": f"ç®¡é“ä¸å­˜åœ¨: {pipeline_id}"}

        if not pipeline.enabled:
            return {"success": False, "error": "ç®¡é“å·²åœç”¨"}

        execution_id = f"{pipeline_id}_{datetime.now().strftime('%Y%m%d%H%M%S')}"
        self._running_pipelines[execution_id] = {
            "pipeline_id": pipeline_id,
            "started_at": datetime.now().isoformat(),
            "current_stage": 0,
            "status": "running",
        }

        results = []
        current_data = input_data or {}

        try:
            for i, stage in enumerate(pipeline.stages):
                self._running_pipelines[execution_id]["current_stage"] = i

                stage_result = await self._execute_stage(stage, current_data)
                results.append(stage_result)

                if not stage_result.get("success"):
                    self._running_pipelines[execution_id]["status"] = "failed"
                    return {
                        "success": False,
                        "error": f"éšæ®µ {i} å¤±æ•—",
                        "results": results,
                    }

                # å‚³éæ•¸æ“šåˆ°ä¸‹ä¸€éšæ®µ
                current_data = stage_result.get("output", current_data)

            self._running_pipelines[execution_id]["status"] = "completed"
            return {
                "success": True,
                "execution_id": execution_id,
                "results": results,
            }

        except Exception as e:
            self._running_pipelines[execution_id]["status"] = "error"
            return {
                "success": False,
                "error": str(e),
                "results": results,
            }

    async def _execute_stage(self, stage: Dict[str, Any], input_data: Dict) -> Dict[str, Any]:
        """åŸ·è¡Œå–®ä¸€éšæ®µ"""
        engine_id = stage.get("engine_id")
        engine_type = stage.get("engine_type")
        operation = stage.get("operation")

        # æ‰¾åˆ°å¼•æ“
        engine = None
        if engine_id:
            reg = self._registry.get_engine(engine_id)
            if reg and reg.instance:
                engine = reg.instance
        elif engine_type:
            engines = self._registry.get_engines_by_type(EngineType(engine_type))
            healthy = [e for e in engines if e.healthy and e.instance]
            if healthy:
                engine = healthy[0].instance

        if not engine:
            return {"success": False, "error": "æ‰¾ä¸åˆ°å¼•æ“"}

        # åŸ·è¡Œä»»å‹™
        task = {
            "operation": operation,
            "input": input_data,
            **stage.get("params", {}),
        }

        result = await engine.execute_now(task)
        return {
            "success": result.success,
            "output": result.result,
            "error": result.error,
            "duration_ms": result.duration_ms,
        }

# ============================================================================
# å¥åº·ç›£æ§å™¨
# ============================================================================

class HealthMonitor:
    """
    å¥åº·ç›£æ§å™¨ - ç›£æ§æ‰€æœ‰å¼•æ“å¥åº·ç‹€æ…‹
    """

    def __init__(self, registry: EngineRegistry, event_bus: EventBus):
        self._registry = registry
        self._event_bus = event_bus
        self._running = False
        self._check_interval = 30.0
        self._logger = logging.getLogger("health_monitor")

    async def start(self, interval: float = 30.0):
        """å•Ÿå‹•ç›£æ§"""
        self._running = True
        self._check_interval = interval
        asyncio.create_task(self._monitor_loop())
        self._logger.info("å¥åº·ç›£æ§å·²å•Ÿå‹•")

    async def stop(self):
        """åœæ­¢ç›£æ§"""
        self._running = False

    async def _monitor_loop(self):
        """ç›£æ§å¾ªç’°"""
        while self._running:
            try:
                await self._check_all_engines()
                await asyncio.sleep(self._check_interval)
            except Exception as e:
                self._logger.error(f"ç›£æ§éŒ¯èª¤: {e}")

    async def _check_all_engines(self):
        """æª¢æŸ¥æ‰€æœ‰å¼•æ“"""
        for reg in self._registry.get_all_engines():
            try:
                if reg.instance:
                    health = reg.instance.get_health()
                    reg.healthy = health.healthy
                    reg.last_health_check = datetime.now().isoformat()

                    if not health.healthy:
                        await self._handle_unhealthy(reg, health)
                else:
                    reg.healthy = False

            except Exception as e:
                self._logger.error(f"æª¢æŸ¥å¼•æ“ {reg.engine_id} å¤±æ•—: {e}")
                reg.healthy = False

    async def _handle_unhealthy(self, reg: EngineRegistration, health: HealthStatus):
        """è™•ç†ä¸å¥åº·çš„å¼•æ“"""
        self._logger.warning(f"å¼•æ“ä¸å¥åº·: {reg.engine_name} - {health.state.name}")

        event = EngineEvent.create("engine.unhealthy", reg.engine_id, {
            "health": asdict(health),
        })
        await self._event_bus.publish(event)

        # è‡ªå‹•æ¢å¾©å˜—è©¦
        if reg.instance and reg.config.auto_recover:
            if health.state == EngineState.ERROR:
                self._logger.info(f"å˜—è©¦æ¢å¾©å¼•æ“: {reg.engine_name}")
                await reg.instance._recover()

    def get_system_health(self) -> Dict[str, Any]:
        """ç²å–ç³»çµ±å¥åº·æ¦‚è¦½"""
        engines = self._registry.get_all_engines()
        healthy = [e for e in engines if e.healthy]

        return {
            "total_engines": len(engines),
            "healthy_engines": len(healthy),
            "unhealthy_engines": len(engines) - len(healthy),
            "health_ratio": len(healthy) / len(engines) if engines else 1.0,
            "engines": [
                {
                    "id": e.engine_id,
                    "name": e.engine_name,
                    "healthy": e.healthy,
                    "state": e.instance.state.name if e.instance else "N/A",
                }
                for e in engines
            ],
        }

# ============================================================================
# ä¸»æ§å”èª¿å™¨
# ============================================================================

class MasterOrchestrator:
    """
    ä¸»æ§å”èª¿å™¨ - æ ¹ç›®éŒ„ç´šåˆ¥çš„è‡ªå‹•åŒ–å¼•æ“å•Ÿå‹•å™¨

    è·è²¬ï¼š
    1. å¼•æ“è‡ªå‹•ç™¼ç¾èˆ‡è¨»å†Š
    2. å¼•æ“ç”Ÿå‘½é€±æœŸç®¡ç†
    3. ä»»å‹™èª¿åº¦èˆ‡åˆ†ç™¼
    4. ç®¡é“ç·¨æ’åŸ·è¡Œ
    5. å¥åº·ç›£æ§èˆ‡è‡ªæˆ‘ä¿®å¾©
    6. äº‹ä»¶å”èª¿èˆ‡æ—¥èªŒ
    """

    def __init__(self, config: Optional[OrchestratorConfig] = None):
        self.config = config or OrchestratorConfig()

        # æ ¸å¿ƒçµ„ä»¶
        self.event_bus = EventBus(max_size=self.config.event_queue_size)
        self.registry = EngineRegistry()
        self.scheduler = EngineScheduler(self.registry, self.event_bus)
        self.pipeline_executor = PipelineExecutor(self.registry, self.scheduler)
        self.health_monitor = HealthMonitor(self.registry, self.event_bus)

        # ç‹€æ…‹
        self._running = False
        self._start_time: Optional[datetime] = None

        # æ—¥èªŒ
        self._logger = logging.getLogger("master_orchestrator")
        self._setup_logging()

    def _setup_logging(self):
        """è¨­ç½®æ—¥èªŒ"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s [%(name)s] %(levelname)s: %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S',
        )

    # ========================================================================
    # ç”Ÿå‘½é€±æœŸ
    # ========================================================================

    async def start(self) -> bool:
        """å•Ÿå‹•ä¸»æ§"""
        self._logger.info("=" * 60)
        self._logger.info("SynergyMesh è‡ªå‹•åŒ–ä¸»æ§å•Ÿå‹•ä¸­...")
        self._logger.info("=" * 60)

        try:
            # å•Ÿå‹•äº‹ä»¶ç¸½ç·š
            await self.event_bus.start()

            # å•Ÿå‹•èª¿åº¦å™¨
            await self.scheduler.start()

            # å•Ÿå‹•å¥åº·ç›£æ§
            await self.health_monitor.start(self.config.health_check_interval)

            # è‡ªå‹•ç™¼ç¾å¼•æ“
            if self.config.auto_discover:
                await self._discover_and_register_engines()

            # è‡ªå‹•å•Ÿå‹•å¼•æ“
            if self.config.auto_start_engines:
                await self._start_all_engines()

            # è¼‰å…¥ç®¡é“é…ç½®
            await self._load_pipelines()

            self._running = True
            self._start_time = datetime.now()

            self._logger.info("=" * 60)
            self._logger.info("ä¸»æ§å•Ÿå‹•å®Œæˆ")
            self._logger.info(f"  å·²è¨»å†Šå¼•æ“: {len(self.registry.get_all_engines())}")
            self._logger.info(f"  å·²è¼‰å…¥ç®¡é“: {len(self.pipeline_executor._pipelines)}")
            self._logger.info("=" * 60)

            # è¨­ç½®ä¿¡è™Ÿè™•ç†
            self._setup_signal_handlers()

            return True

        except Exception as e:
            self._logger.error(f"å•Ÿå‹•å¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
            return False

    async def stop(self):
        """åœæ­¢ä¸»æ§"""
        self._logger.info("æ­£åœ¨åœæ­¢ä¸»æ§...")

        # åœæ­¢æ‰€æœ‰å¼•æ“
        await self._stop_all_engines()

        # åœæ­¢çµ„ä»¶
        await self.health_monitor.stop()
        await self.scheduler.stop()
        await self.event_bus.stop()

        self._running = False
        self._logger.info("ä¸»æ§å·²åœæ­¢")

    async def run_forever(self):
        """æŒçºŒé‹è¡Œ"""
        while self._running:
            await asyncio.sleep(1)

    def _setup_signal_handlers(self):
        """è¨­ç½®ä¿¡è™Ÿè™•ç†"""
        def handle_signal(sig, frame):
            self._logger.info(f"æ”¶åˆ°ä¿¡è™Ÿ {sig}ï¼Œæº–å‚™åœæ­¢...")
            asyncio.create_task(self.stop())

        signal.signal(signal.SIGINT, handle_signal)
        signal.signal(signal.SIGTERM, handle_signal)

    # ========================================================================
    # å¼•æ“ç®¡ç†
    # ========================================================================

    async def _discover_and_register_engines(self):
        """ç™¼ç¾ä¸¦è¨»å†Šå¼•æ“"""
        self._logger.info("ç™¼ç¾å¼•æ“ä¸­...")

        search_paths = [BASE_PATH / p for p in self.config.engines_paths]
        discovered = self.registry.discover_engines(search_paths)

        self._logger.info(f"ç™¼ç¾ {len(discovered)} å€‹å¼•æ“")

        for engine_info in discovered:
            try:
                await self._register_engine_from_info(engine_info)
            except Exception as e:
                self._logger.error(f"è¨»å†Šå¼•æ“å¤±æ•—: {e}")

    async def _register_engine_from_info(self, info: Dict[str, Any]):
        """å¾è³‡è¨Šè¨»å†Šå¼•æ“"""
        module_path = info.get("module_path")
        class_name = info.get("class_name")

        if not module_path or not class_name:
            return

        try:
            # å‹•æ…‹è¼‰å…¥æ¨¡çµ„
            spec = importlib.util.spec_from_file_location(
                Path(module_path).stem, module_path
            )
            module = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(module)

            # ç²å–å¼•æ“é¡
            engine_class = getattr(module, class_name)

            # å»ºç«‹é…ç½®
            config = EngineConfig(
                engine_name=class_name,
                engine_type=EngineType(info.get("engine_type", "execution")),
                execution_mode=ExecutionMode.AUTONOMOUS,
            )

            # å»ºç«‹å¯¦ä¾‹
            instance = engine_class(config)

            # è¨»å†Š
            registration = EngineRegistration(
                engine_id=config.engine_id,
                engine_name=class_name,
                engine_class=class_name,
                engine_type=config.engine_type,
                module_path=module_path,
                config=config,
                instance=instance,
            )

            self.registry.register_engine(registration)

        except Exception as e:
            self._logger.error(f"è¼‰å…¥å¼•æ“ {class_name} å¤±æ•—: {e}")

    async def _start_all_engines(self):
        """å•Ÿå‹•æ‰€æœ‰å¼•æ“"""
        self._logger.info("å•Ÿå‹•æ‰€æœ‰å¼•æ“...")

        for reg in self.registry.get_all_engines():
            if reg.instance:
                try:
                    success = await reg.instance.start()
                    if success:
                        reg.healthy = True
                        self._logger.info(f"  âœ“ {reg.engine_name}")
                    else:
                        self._logger.warning(f"  âœ— {reg.engine_name} å•Ÿå‹•å¤±æ•—")
                except Exception as e:
                    self._logger.error(f"  âœ— {reg.engine_name}: {e}")

    async def _stop_all_engines(self):
        """åœæ­¢æ‰€æœ‰å¼•æ“"""
        self._logger.info("åœæ­¢æ‰€æœ‰å¼•æ“...")

        for reg in self.registry.get_all_engines():
            if reg.instance:
                try:
                    await reg.instance.stop()
                    self._logger.info(f"  âœ“ {reg.engine_name} å·²åœæ­¢")
                except Exception as e:
                    self._logger.error(f"  âœ— {reg.engine_name}: {e}")

    async def start_engine(self, engine_id: str) -> bool:
        """å•Ÿå‹•æŒ‡å®šå¼•æ“"""
        reg = self.registry.get_engine(engine_id)
        if not reg or not reg.instance:
            return False
        return await reg.instance.start()

    async def stop_engine(self, engine_id: str) -> bool:
        """åœæ­¢æŒ‡å®šå¼•æ“"""
        reg = self.registry.get_engine(engine_id)
        if not reg or not reg.instance:
            return False
        return await reg.instance.stop()

    # ========================================================================
    # ç®¡é“ç®¡ç†
    # ========================================================================

    async def _load_pipelines(self):
        """è¼‰å…¥ç®¡é“é…ç½®"""
        config_path = BASE_PATH / self.config.config_path / "pipelines"
        if not config_path.exists():
            return

        for pipeline_file in config_path.glob("*.yaml"):
            try:
                with open(pipeline_file, 'r', encoding='utf-8') as f:
                    data = yaml.safe_load(f)

                pipeline = PipelineConfig(
                    pipeline_id=data.get("pipeline_id", pipeline_file.stem),
                    name=data.get("name", pipeline_file.stem),
                    description=data.get("description", ""),
                    stages=data.get("stages", []),
                    triggers=data.get("triggers", []),
                    enabled=data.get("enabled", True),
                )

                self.pipeline_executor.register_pipeline(pipeline)

            except Exception as e:
                self._logger.error(f"è¼‰å…¥ç®¡é“å¤±æ•— {pipeline_file}: {e}")

    async def execute_pipeline(self, pipeline_id: str, input_data: Dict = None) -> Dict:
        """åŸ·è¡Œç®¡é“"""
        return await self.pipeline_executor.execute_pipeline(pipeline_id, input_data)

    # ========================================================================
    # ä»»å‹™èª¿åº¦
    # ========================================================================

    async def submit_task(self, task: Dict[str, Any], priority: Priority = Priority.NORMAL):
        """æäº¤ä»»å‹™"""
        await self.scheduler.schedule_task(task, priority)

    async def execute_task(self, engine_id: str, task: Dict[str, Any]) -> TaskResult:
        """ç›´æ¥åŸ·è¡Œä»»å‹™"""
        reg = self.registry.get_engine(engine_id)
        if not reg or not reg.instance:
            return TaskResult(
                task_id=task.get("task_id", ""),
                success=False,
                error="å¼•æ“ä¸å­˜åœ¨æˆ–æœªå•Ÿå‹•",
            )
        return await reg.instance.execute_now(task)

    # ========================================================================
    # ç‹€æ…‹æŸ¥è©¢
    # ========================================================================

    def get_status(self) -> Dict[str, Any]:
        """ç²å–ç³»çµ±ç‹€æ…‹"""
        uptime = datetime.now() - self._start_time if self._start_time else timedelta(0)

        return {
            "name": self.config.name,
            "version": self.config.version,
            "running": self._running,
            "uptime_seconds": uptime.total_seconds(),
            "started_at": self._start_time.isoformat() if self._start_time else None,
            "health": self.health_monitor.get_system_health(),
            "engines": [
                {
                    "id": e.engine_id,
                    "name": e.engine_name,
                    "type": e.engine_type.value,
                    "healthy": e.healthy,
                    "state": e.instance.state.name if e.instance else "N/A",
                }
                for e in self.registry.get_all_engines()
            ],
            "pipelines": list(self.pipeline_executor._pipelines.keys()),
        }

# ============================================================================
# CLI å…¥å£
# ============================================================================

async def main():
    parser = argparse.ArgumentParser(
        description="SynergyMesh Master Orchestrator - ä¸»æ§å¼•æ“å•Ÿå‹•å™¨"
    )

    subparsers = parser.add_subparsers(dest="command", help="å¯ç”¨å‘½ä»¤")

    # start å‘½ä»¤
    start_parser = subparsers.add_parser("start", help="å•Ÿå‹•ä¸»æ§")
    start_parser.add_argument("--config", "-c", help="é…ç½®æª”æ¡ˆ")

    # start-all å‘½ä»¤
    start_all_parser = subparsers.add_parser("start-all", help="å•Ÿå‹•æ‰€æœ‰å¼•æ“")

    # stop å‘½ä»¤
    stop_parser = subparsers.add_parser("stop", help="åœæ­¢ä¸»æ§")

    # status å‘½ä»¤
    status_parser = subparsers.add_parser("status", help="æŸ¥çœ‹ç‹€æ…‹")

    # list å‘½ä»¤
    list_parser = subparsers.add_parser("list", help="åˆ—å‡ºå¼•æ“")

    # execute å‘½ä»¤
    execute_parser = subparsers.add_parser("execute", help="åŸ·è¡Œç®¡é“")
    execute_parser.add_argument("--pipeline", "-p", required=True, help="ç®¡é“ ID")
    execute_parser.add_argument("--input", "-i", help="è¼¸å…¥æ•¸æ“š (JSON)")

    args = parser.parse_args()

    if not args.command:
        parser.print_help()
        return

    orchestrator = MasterOrchestrator()

    if args.command == "start":
        success = await orchestrator.start()
        if success:
            await orchestrator.run_forever()

    elif args.command == "start-all":
        await orchestrator.start()
        status = orchestrator.get_status()
        print(yaml.dump(status, allow_unicode=True, default_flow_style=False))
        await orchestrator.run_forever()

    elif args.command == "status":
        await orchestrator.start()
        status = orchestrator.get_status()
        print(yaml.dump(status, allow_unicode=True, default_flow_style=False))
        await orchestrator.stop()

    elif args.command == "list":
        await orchestrator.start()
        for engine in orchestrator.registry.get_all_engines():
            print(f"- {engine.engine_name} ({engine.engine_id}): {engine.engine_type.value}")
        await orchestrator.stop()

    elif args.command == "execute":
        await orchestrator.start()
        input_data = json.loads(args.input) if args.input else {}
        result = await orchestrator.execute_pipeline(args.pipeline, input_data)
        print(yaml.dump(result, allow_unicode=True, default_flow_style=False))
        await orchestrator.stop()

if __name__ == "__main__":
    asyncio.run(main())
