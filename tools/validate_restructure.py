#!/usr/bin/env python3
"""
MachineNativeOps ç›®éŒ„é‡æ§‹é©—è­‰å·¥å…·

é€™å€‹è…³æœ¬é©—è­‰ç›®éŒ„é‡æ§‹çš„å®Œæ•´æ€§å’Œæ­£ç¢ºæ€§ï¼ŒåŒ…æ‹¬ï¼š
1. æª¢æŸ¥ç›®éŒ„çµæ§‹
2. é©—è­‰æ–‡ä»¶å®Œæ•´æ€§
3. æª¢æŸ¥å°å…¥è·¯å¾‘
4. é©—è­‰é…ç½®æ–‡ä»¶
5. ç”Ÿæˆé©—è­‰å ±å‘Š

ä½¿ç”¨æ–¹æ³•ï¼š
python tools/validate_restructure.py [--detailed] [--fix-imports]
"""

import os
import sys
import json
import ast
import argparse
import logging
from pathlib import Path
from typing import Dict, List, Set, Tuple, Optional
from datetime import datetime
import re

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class RestructureValidator:
    """ç›®éŒ„é‡æ§‹é©—è­‰å™¨"""
    
    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root).resolve()
        self.issues = []
        self.warnings = []
        self.fix_imports = False
        self.detailed = False
        
        # é æœŸçš„ç›®éŒ„çµæ§‹
        self.expected_structure = {
            "src": {
                "core": {
                    "plugins": [
                        "ai_constitution", "ci_error_handler", "cloud_agent_delegation",
                        "drone_system", "execution_architecture", "execution_engine",
                        "main_system", "mcp_servers_enhanced", "mind_matrix",
                        "monitoring_system", "tech_stack", "training_system",
                        "virtual_experts", "yaml_module_system"
                    ],
                    "safety": [
                        "anomaly_detector", "autonomous_trust_engine", "checkpoint_manager",
                        "circuit_breaker", "emergency_stop", "escalation_ladder",
                        "hallucination_detector", "partial_rollback", "retry_policies",
                        "rollback_system", "safety_net"
                    ],
                    "services": [
                        "agent_registry", "capability_coordinator", "health_monitor",
                        "lifecycle_manager", "message_bus", "resource_manager",
                        "service_discovery", "state_manager", "task_scheduler"
                    ]
                },
                "platform": {
                    "agents": [
                        "ai_agent", "automation_agent", "ci_agent", "cloud_agent",
                        "data_agent", "devops_agent", "monitoring_agent", "security_agent"
                    ],
                    "automation": [
                        "pipeline_engine", "workflow_orchestrator", "task_scheduler",
                        "resource_optimizer", "auto_scaler", "health_checker"
                    ],
                    "integrations": [
                        "github", "gitlab", "jenkins", "docker", "kubernetes",
                        "aws", "azure", "gcp", "slack", "teams"
                    ]
                },
                "services": {
                    "api": [
                        "rest_api", "graphql_api", "websocket_api", "grpc_api"
                    ],
                    "data": [
                        "database", "cache", "message_queue", "file_storage",
                        "search_engine", "data_pipeline"
                    ],
                    "monitoring": [
                        "metrics", "logging", "tracing", "alerting", "dashboard"
                    ]
                },
                "shared": {
                    "types": [
                        "common_types", "api_types", "domain_types", "event_types"
                    ],
                    "utils": [
                        "helpers", "validators", "formatters", "parsers",
                        "converters", "calculators"
                    ],
                    "constants": [
                        "app_constants", "api_constants", "domain_constants",
                        "error_codes", "status_codes"
                    ]
                },
                "web": {
                    "admin": [
                        "dashboard", "user_management", "system_config",
                        "monitoring", "analytics"
                    ],
                    "client": [
                        "user_interface", "components", "pages", "services"
                    ],
                    "api": [
                        "routes", "controllers", "middleware", "handlers"
                    ]
                }
            },
            "config": {
                "ci-cd": [
                    "auto-fix-bot", "ci-agent", "ci-config", "ci-error-handler",
                    "drone-config"
                ],
                "deployment": [
                    "docker-compose", "dockerfile", "nginx", "deployment-pipelines"
                ],
                "monitoring": [
                    "prometheus", "grafana", "alerting", "dashboards"
                ],
                "environments": [
                    "env-files", "environment-configs", "secrets"
                ],
                "security": [
                    "security-policies", "safety-mechanisms", "access-control"
                ],
                "build-tools": [
                    "eslint", "jest", "postcss", "tailwind", "vite",
                    "drizzle", "typescript", "build-scripts"
                ],
                "governance": [
                    "system-manifest", "module-mapping", "architecture-specs",
                    "recovery-system", "evolution-configs"
                ]
            }
        }
        
        # èˆŠè·¯å¾‘åˆ°æ–°è·¯å¾‘çš„æ˜ å°„
        self.path_mappings = {
            "src/core/modules": "src/core/plugins",
            "src/core/safety_mechanisms": "src/core/safety",
            "src/apps/web": "src/web/admin",
            "src/apps/cli": "src/platform/cli",
            "src/apps/api": "src/services/api"
        }
    
    def validate_directory_structure(self) -> Dict:
        """é©—è­‰ç›®éŒ„çµæ§‹"""
        logger.info("ğŸ” é©—è­‰ç›®éŒ„çµæ§‹...")
        
        result = {
            "valid": True,
            "missing_directories": [],
            "unexpected_directories": [],
            "details": {}
        }
        
        for main_dir, subdirs in self.expected_structure.items():
            main_path = self.project_root / main_dir
            
            if not main_path.exists():
                result["missing_directories"].append(str(main_path))
                result["valid"] = False
                continue
            
            result["details"][main_dir] = {}
            
            for subdir, categories in subdirs.items():
                subdir_path = main_path / subdir
                
                if not subdir_path.exists():
                    result["missing_directories"].append(str(subdir_path))
                    result["valid"] = False
                    result["details"][main_dir][subdir] = "missing"
                    continue
                
                result["details"][main_dir][subdir] = "exists"
                
                # æª¢æŸ¥å­ç›®éŒ„
                if isinstance(categories, dict):
                    for category in categories.keys():
                        category_path = subdir_path / category
                        if not category_path.exists():
                            result["missing_directories"].append(str(category_path))
                            result["valid"] = False
                elif isinstance(categories, list):
                    # å°æ–¼åˆ—è¡¨ï¼Œæª¢æŸ¥æ˜¯å¦æœ‰ç›¸æ‡‰çš„æ–‡ä»¶æˆ–ç›®éŒ„
                    pass
        
        if result["missing_directories"]:
            logger.warning(f"âš ï¸ ç¼ºå°‘ç›®éŒ„: {len(result['missing_directories'])} å€‹")
            for missing in result["missing_directories"]:
                logger.warning(f"  - {missing}")
        
        return result
    
    def validate_file_integrity(self) -> Dict:
        """é©—è­‰æ–‡ä»¶å®Œæ•´æ€§"""
        logger.info("ğŸ“ é©—è­‰æ–‡ä»¶å®Œæ•´æ€§...")
        
        result = {
            "valid": True,
            "missing_files": [],
            "empty_files": [],
            "total_files": 0
        }
        
        # æª¢æŸ¥é—œéµæ–‡ä»¶
        critical_files = [
            "src/core/plugins/plugin_system.py",
            "src/core/safety/autonomous_trust_engine.py",
            "src/core/safety/hallucination_detector.py",
            "src/services/index.ts",
            "src/services/routes.ts",
            "src/shared/types/naming-policy.schema.yaml"
        ]
        
        for file_path in critical_files:
            full_path = self.project_root / file_path
            if not full_path.exists():
                result["missing_files"].append(file_path)
                result["valid"] = False
            elif full_path.stat().st_size == 0:
                result["empty_files"].append(file_path)
                self.warnings.append(f"æ–‡ä»¶ç‚ºç©º: {file_path}")
        
        # çµ±è¨ˆæ–‡ä»¶æ•¸é‡
        for root_dir in ["src", "config"]:
            root_path = self.project_root / root_dir
            if root_path.exists():
                for file_path in root_path.rglob("*"):
                    if file_path.is_file() and not file_path.name.startswith('.'):
                        result["total_files"] += 1
        
        logger.info(f"ğŸ“Š ç¸½æ–‡ä»¶æ•¸: {result['total_files']}")
        
        if result["missing_files"]:
            logger.error(f"âŒ ç¼ºå°‘é—œéµæ–‡ä»¶: {len(result['missing_files'])} å€‹")
            for missing in result["missing_files"]:
                logger.error(f"  - {missing}")
        
        return result
    
    def validate_import_paths(self) -> Dict:
        """é©—è­‰ Python å°å…¥è·¯å¾‘"""
        logger.info("ğŸ”— é©—è­‰å°å…¥è·¯å¾‘...")
        
        result = {
            "valid": True,
            "broken_imports": [],
            "fixed_imports": [],
            "files_checked": 0
        }
        
        # æƒææ‰€æœ‰ Python æ–‡ä»¶
        for py_file in self.project_root.rglob("*.py"):
            if py_file.name.startswith('.') or '__pycache__' in str(py_file):
                continue
            
            result["files_checked"] += 1
            try:
                self._check_python_imports(py_file, result)
            except Exception as e:
                logger.warning(f"âš ï¸ ç„¡æ³•åˆ†ææ–‡ä»¶ {py_file}: {e}")
        
        logger.info(f"ğŸ“Š æª¢æŸ¥äº† {result['files_checked']} å€‹ Python æ–‡ä»¶")
        
        if result["broken_imports"]:
            logger.error(f"âŒ ç™¼ç¾ {len(result['broken_imports'])} å€‹æå£çš„å°å…¥")
            for broken in result["broken_imports"]:
                logger.error(f"  - {broken}")
        
        if result["fixed_imports"]:
            logger.info(f"âœ… ä¿®å¾©äº† {len(result['fixed_imports'])} å€‹å°å…¥")
        
        return result
    
    def _check_python_imports(self, file_path: Path, result: Dict):
        """æª¢æŸ¥å–®å€‹ Python æ–‡ä»¶çš„å°å…¥"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            tree = ast.parse(content)
            
            for node in ast.walk(tree):
                if isinstance(node, ast.Import):
                    for alias in node.names:
                        self._validate_import(alias.name, file_path, result)
                elif isinstance(node, ast.ImportFrom):
                    if node.module:
                        self._validate_import(node.module, file_path, result)
        
        except SyntaxError as e:
            self.issues.append(f"èªæ³•éŒ¯èª¤åœ¨ {file_path}: {e}")
            result["valid"] = False
    
    def _validate_import(self, module_name: str, file_path: Path, result: Dict):
        """é©—è­‰å–®å€‹å°å…¥"""
        # æª¢æŸ¥æ˜¯å¦æ˜¯èˆŠçš„è·¯å¾‘
        for old_path, new_path in self.path_mappings.items():
            if module_name.startswith(old_path.replace('/', '.')):
                # ç™¼ç¾èˆŠè·¯å¾‘å°å…¥
                broken_import = f"{file_path}: {module_name}"
                result["broken_imports"].append(broken_import)
                result["valid"] = False
                
                # å˜—è©¦ä¿®å¾©
                if self.fix_imports:
                    new_module = module_name.replace(old_path.replace('/', '.'), new_path.replace('/', '.'))
                    self._fix_import_in_file(file_path, module_name, new_module)
                    result["fixed_imports"].append(f"{file_path}: {module_name} -> {new_module}")
    
    def _fix_import_in_file(self, file_path: Path, old_import: str, new_import: str):
        """ä¿®å¾©æ–‡ä»¶ä¸­çš„å°å…¥"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æ›¿æ›å°å…¥èªå¥
            content = content.replace(old_import, new_import)
            
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content)
                
        except Exception as e:
            logger.error(f"âŒ ç„¡æ³•ä¿®å¾©å°å…¥åœ¨ {file_path}: {e}")
    
    def validate_config_files(self) -> Dict:
        """é©—è­‰é…ç½®æ–‡ä»¶"""
        logger.info("âš™ï¸ é©—è­‰é…ç½®æ–‡ä»¶...")
        
        result = {
            "valid": True,
            "invalid_configs": [],
            "missing_configs": []
        }
        
        # æª¢æŸ¥é—œéµé…ç½®æ–‡ä»¶
        config_checks = [
            {
                "path": "config/governance/system-manifest.yaml",
                "required_keys": ["name", "version", "modules"]
            },
            {
                "path": "config/governance/system-module-map.yaml",
                "required_keys": ["modules", "dependencies"]
            },
            {
                "path": "package.json",
                "required_keys": ["name", "version", "scripts"]
            }
        ]
        
        for check in config_checks:
            config_path = self.project_root / check["path"]
            
            if not config_path.exists():
                result["missing_configs"].append(check["path"])
                result["valid"] = False
                continue
            
            try:
                with open(config_path, 'r', encoding='utf-8') as f:
                    if config_path.suffix in ['.yaml', '.yml']:
                        config = yaml.safe_load(f)
                    elif config_path.suffix == '.json':
                        config = json.load(f)
                    else:
                        continue
                
                for key in check["required_keys"]:
                    if key not in config:
                        result["invalid_configs"].append(f"{check['path']}: ç¼ºå°‘éµ '{key}'")
                        result["valid"] = False
                        
            except Exception as e:
                result["invalid_configs"].append(f"{check['path']}: è§£æéŒ¯èª¤ - {e}")
                result["valid"] = False
        
        return result
    
    def validate_web_structure(self) -> Dict:
        """é©—è­‰ Web æ‡‰ç”¨çµæ§‹"""
        logger.info("ğŸŒ é©—è­‰ Web æ‡‰ç”¨çµæ§‹...")
        
        result = {
            "valid": True,
            "missing_components": [],
            "structure_issues": []
        }
        
        # æª¢æŸ¥ Web æ‡‰ç”¨çµæ§‹
        web_apps = ["admin", "client"]
        
        for app in web_apps:
            app_path = self.project_root / "src" / "web" / app
            
            if not app_path.exists():
                result["missing_components"].append(f"src/web/{app}")
                result["valid"] = False
                continue
            
            # æª¢æŸ¥é—œéµæ–‡ä»¶
            key_files = ["package.json", "src/App.tsx", "src/main.tsx"]
            for file_name in key_files:
                file_path = app_path / file_name
                if not file_path.exists():
                    result["missing_components"].append(f"src/web/{app}/{file_name}")
                    result["valid"] = False
        
        return result
    
    def generate_validation_report(self) -> str:
        """ç”Ÿæˆé©—è­‰å ±å‘Š"""
        logger.info("ğŸ“Š ç”Ÿæˆé©—è­‰å ±å‘Š...")
        
        report = {
            "timestamp": datetime.now().isoformat(),
            "project_root": str(self.project_root),
            "validation_results": {
                "directory_structure": self.validate_directory_structure(),
                "file_integrity": self.validate_file_integrity(),
                "import_paths": self.validate_import_paths(),
                "config_files": self.validate_config_files(),
                "web_structure": self.validate_web_structure()
            },
            "issues": self.issues,
            "warnings": self.warnings,
            "summary": {}
        }
        
        # ç”Ÿæˆæ‘˜è¦
        total_issues = len(self.issues) + len(self.warnings)
        report["summary"] = {
            "total_issues": total_issues,
            "critical_issues": len(self.issues),
            "warnings": len(self.warnings),
            "overall_valid": all(
                result["valid"] 
                for result in report["validation_results"].values()
            )
        }
        
        # ä¿å­˜å ±å‘Š
        report_file = self.project_root / "validation_report.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ“‹ é©—è­‰å ±å‘Šå·²ä¿å­˜åˆ°: {report_file}")
        
        # ç”Ÿæˆæ‘˜è¦
        summary = self._generate_validation_summary(report)
        logger.info(f"\nğŸ“‹ é©—è­‰æ‘˜è¦:\n{summary}")
        
        return summary
    
    def _generate_validation_summary(self, report: Dict) -> str:
        """ç”Ÿæˆé©—è­‰æ‘˜è¦"""
        summary = []
        summary.append(f"é©—è­‰æ™‚é–“: {report['timestamp']}")
        summary.append(f"é …ç›®æ ¹ç›®éŒ„: {report['project_root']}")
        summary.append(f"ç¸½å•é¡Œæ•¸: {report['summary']['total_issues']}")
        summary.append(f"åš´é‡å•é¡Œ: {report['summary']['critical_issues']}")
        summary.append(f"è­¦å‘Š: {report['summary']['warnings']}")
        summary.append(f"æ•´é«”ç‹€æ…‹: {'âœ… é€šé' if report['summary']['overall_valid'] else 'âŒ å¤±æ•—'}")
        
        if report["issues"]:
            summary.append("\nåš´é‡å•é¡Œ:")
            for issue in report["issues"][:10]:  # åªé¡¯ç¤ºå‰10å€‹
                summary.append(f"  - {issue}")
        
        if report["warnings"]:
            summary.append("\nè­¦å‘Š:")
            for warning in report["warnings"][:10]:  # åªé¡¯ç¤ºå‰10å€‹
                summary.append(f"  - {warning}")
        
        return "\n".join(summary)
    
    def run_validation(self, detailed: bool = False, fix_imports: bool = False) -> bool:
        """é‹è¡Œå®Œæ•´é©—è­‰"""
        self.detailed = detailed
        self.fix_imports = fix_imports
        
        logger.info("ğŸ” é–‹å§‹ç›®éŒ„é‡æ§‹é©—è­‰...")
        
        try:
            # åŸ·è¡Œæ‰€æœ‰é©—è­‰
            self.generate_validation_report()
            
            # åˆ¤æ–·æ•´é«”çµæœ
            total_issues = len(self.issues) + len(self.warnings)
            
            if total_issues == 0:
                logger.info("âœ… é©—è­‰é€šé - æ²’æœ‰ç™¼ç¾å•é¡Œ!")
                return True
            elif len(self.issues) == 0:
                logger.info(f"âš ï¸ é©—è­‰é€šéä½†æœ‰ {len(self.warnings)} å€‹è­¦å‘Š")
                return True
            else:
                logger.error(f"âŒ é©—è­‰å¤±æ•— - ç™¼ç¾ {len(self.issues)} å€‹åš´é‡å•é¡Œ")
                return False
                
        except Exception as e:
            logger.error(f"âŒ é©—è­‰éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
            return False

def main():
    """ä¸»å‡½æ•¸"""
    parser = argparse.ArgumentParser(description="MachineNativeOps ç›®éŒ„é‡æ§‹é©—è­‰å·¥å…·")
    parser.add_argument("--detailed", action="store_true", help="è©³ç´°è¼¸å‡ºæ¨¡å¼")
    parser.add_argument("--fix-imports", action="store_true", help="è‡ªå‹•ä¿®å¾©å°å…¥è·¯å¾‘")
    parser.add_argument("--project-root", default=".", help="é …ç›®æ ¹ç›®éŒ„è·¯å¾‘")
    
    args = parser.parse_args()
    
    # å‰µå»ºé©—è­‰å™¨
    validator = RestructureValidator(args.project_root)
    
    # åŸ·è¡Œé©—è­‰
    success = validator.run_validation(args.detailed, args.fix_imports)
    
    # é€€å‡º
    sys.exit(0 if success else 1)

if __name__ == "__main__":
    main()
