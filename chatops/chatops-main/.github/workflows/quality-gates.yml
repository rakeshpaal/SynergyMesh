# .github/workflows/quality-gates.yml
# Phase-3: Dynamic Quality Gates for Multi-Agent AI Production Environment
name: Dynamic Quality Gates

on:
  pull_request:
    types: [opened, synchronize]
    paths:
      - 'proto/**'
      - 'services/**'
      - 'scripts/**'
      - 'tests/**'
      - 'policies/**'
      - 'deployments/**'
      - '.github/workflows/**'
  push:
    branches: [main, develop]
    paths:
      - 'proto/**'
      - 'services/**'
      - 'scripts/**'
      - 'tests/**'
      - 'policies/**'
      - 'deployments/**'
      - '.github/workflows/**'

permissions:
  contents: read
  actions: read
  checks: write
  pull-requests: write
  security-events: write

env:
  PYTHON_VERSION: '3.9'
  NODE_VERSION: '18'

jobs:
  quality-assessment:
    runs-on: ubuntu-latest
    outputs:
      trace-id: ${{ steps.trace.outputs.trace_id }}
      quality-score: ${{ steps.assessment.outputs.score }}
      gate-status: ${{ steps.gates.outputs.status }}
      policy-verdict: ${{ steps.policy.outputs.verdict }}

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Generate Trace Id
        id: trace
        run: |
          TRACE_ID="trace-$(date +%s)-${GITHUB_RUN_ID}-${GITHUB_RUN_ATTEMPT}"
          echo "trace_id=$TRACE_ID" >> $GITHUB_OUTPUT
          echo "::notice title=Trace ID::$TRACE_ID"

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Setup Quality Tools
        run: |
          python -m pip install --upgrade pip
          pip install pylint black pytest pytest-cov bandit pyyaml
          npm i -g eslint prettier typescript @typescript-eslint/parser @typescript-eslint/eslint-plugin || true

      - name: Intelligent Review (Multi-Agent Data Source)
        run: |
          mkdir -p artifacts
          python scripts/quality/intelligent_review.py || true

      - name: Code Quality Assessment
        id: assessment
        shell: bash
        run: |
          set -euo pipefail

          # Initialize scores
          PYLINT_SCORE="0"
          TEST_COVERAGE="0"
          SECURITY_ISSUES="0"
          TS_SCORE="100"

          # Python analysis (engine-python)
          if [ -d "services/engine-python"] && [ -n "$(find services/engine-python -name '*.py' 2>/dev/null)"]; then
            echo "Analyzing Python code..."
            PYLINT_SCORE=$(pylint services/engine-python --output-format=text 2>/dev/null | grep "rated at" | grep -o "[0-9.]*" | head -1 || echo "0")

            # Test coverage (if pytest available and tests exist)
            if [ -d "services/engine-python/tests"]; then
              TEST_COVERAGE=$(pytest -q --cov=services/engine-python --cov-report=term-missing 2>/dev/null | grep "TOTAL" | awk '{print $4}' | sed 's/%//' || echo "0")
            fi

            # Security scan
            SECURITY_ISSUES=$(bandit -r services/engine-python -f json 2>/dev/null | python3 -c "import sys,json; d=json.load(sys.stdin); print(d.get('metrics',{}).get('_totals',{}).get('SEVERITY.HIGH',0))" || echo "0")
          fi

          # TypeScript analysis (gateway-ts)
          if [ -d "services/gateway-ts"] && [ -n "$(find services/gateway-ts -name '*.ts' 2>/dev/null)"]; then
            echo "Analyzing TypeScript code..."
            if command -v eslint &> /dev/null; then
              eslint services/gateway-ts --ext .ts,.tsx 2>/dev/null || TS_SCORE="60"
            fi
          fi

          # Read intelligent review score if available
          INTELLIGENT_SCORE="100"
          if [ -f "artifacts/intelligent-review.report.json"]; then
            INTELLIGENT_SCORE=$(python3 -c "import json; d=json.load(open('artifacts/intelligent-review.report.json')); print(d.get('summary',{}).get('quality_score',100))" || echo "100")
          fi

          # Calculate weighted quality score (0-100)
          QUALITY_SCORE=$(python3 -c "
          import sys

          def to_float(value, default):
              try:
                  if value is None or value == '':
                      return float(default)
                  return float(value)
              except Exception:
                  return float(default)

          pylint_raw, coverage_raw, security_raw, ts_raw, intelligent_raw = (sys.argv[1:6] + ['0', '0', '0', '0', '100'])[:5]

          pylint = to_float(pylint_raw, 0) * 10  # pylint 0-10 -> 0-100
          coverage = to_float(coverage_raw, 0)  # 0-100
          security = max(0, 100 - to_float(security_raw, 0) * 20)  # HIGH issues reduce score
          ts = to_float(ts_raw, 0)  # 0-100
          intelligent = to_float(intelligent_raw, 100)  # 0-100

          # Weighted average
          score = (pylint * 0.15) + (coverage * 0.25) + (security * 0.30) + (ts * 0.10) + (intelligent * 0.20)
          print(f'{score:.1f}')
          " "$PYLINT_SCORE" "$TEST_COVERAGE" "$SECURITY_ISSUES" "$TS_SCORE" "$INTELLIGENT_SCORE")

          {
            echo "score=${QUALITY_SCORE}"
            echo "pylint-score=${PYLINT_SCORE}"
            echo "coverage=${TEST_COVERAGE}"
            echo "security-issues=${SECURITY_ISSUES}"
            echo "ts-score=${TS_SCORE}"
            echo "intelligent-score=${INTELLIGENT_SCORE}"
          } >> "$GITHUB_OUTPUT"

          echo "::notice title=Quality Score::$QUALITY_SCORE/100"

      - name: Apply Quality Gates
        id: gates
        shell: bash
        run: |
          set -euo pipefail

          SCORE="${{ steps.assessment.outputs.score }}"
          BRANCH_NAME="${GITHUB_HEAD_REF:-${GITHUB_REF#refs/heads/}}"

          # Dynamic thresholds based on branch
          case "$BRANCH_NAME" in
            "main")
              THRESHOLD=85
              ;;
            "develop")
              THRESHOLD=75
              ;;
            *)
              THRESHOLD=70
              ;;
          esac

          echo "threshold=$THRESHOLD" >> $GITHUB_OUTPUT

          # Determine gate status
          STATUS=$(python3 -c "
          score = float('$SCORE')
          threshold = float('$THRESHOLD')
          if score >= threshold:
              print('pass')
          elif score >= threshold - 10:
              print('need-approval')
          else:
              print('block')
          ")

          echo "status=$STATUS" >> $GITHUB_OUTPUT
          echo "::notice title=Gate Status::$STATUS (threshold: $THRESHOLD)"

      - name: Policy Agent (Verdict)
        id: policy
        shell: bash
        run: |
          GATE_STATUS="${{ steps.gates.outputs.status }}"
          SECURITY_ISSUES="${{ steps.assessment.outputs.security-issues }}"

          # Policy Agent decision logic
          if [ "$SECURITY_ISSUES" != "0"] && [ "$SECURITY_ISSUES" != ""]; then
            echo "verdict=block" >> $GITHUB_OUTPUT
            echo "reason=security-issues-detected" >> $GITHUB_OUTPUT
          elif [ "$GATE_STATUS" = "pass"]; then
            echo "verdict=pass" >> $GITHUB_OUTPUT
            echo "reason=quality-threshold-met" >> $GITHUB_OUTPUT
          elif [ "$GATE_STATUS" = "need-approval"]; then
            echo "verdict=need-approval" >> $GITHUB_OUTPUT
            echo "reason=below-threshold-requires-review" >> $GITHUB_OUTPUT
          else
            echo "verdict=block" >> $GITHUB_OUTPUT
            echo "reason=quality-threshold-not-met" >> $GITHUB_OUTPUT
          fi

      - name: Audit (Observability Agent)
        shell: bash
        run: |
          mkdir -p artifacts/audit

          cat > artifacts/audit/quality-gates.audit.jsonl <<EOF
          {"trace_id":"${{ steps.trace.outputs.trace_id }}","event":"quality_gates","score":"${{ steps.assessment.outputs.score }}","threshold":"${{ steps.gates.outputs.threshold }}","gate_status":"${{ steps.gates.outputs.status }}","policy_verdict":"${{ steps.policy.outputs.verdict }}","policy_reason":"${{ steps.policy.outputs.reason }}","security_issues":"${{ steps.assessment.outputs.security-issues }}","ref":"${GITHUB_REF}","sha":"${GITHUB_SHA}","timestamp":"$(date -u +%Y-%m-%dT%H:%M:%SZ)"}
          EOF

      - name: Upload Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: quality-gates-artifacts-${{ steps.trace.outputs.trace_id }}
          path: |
            artifacts/intelligent-review.report.json
            artifacts/audit/
          retention-days: 90

      - name: Gate Enforcement
        if: steps.policy.outputs.verdict == 'block'
        run: |
          echo "::error title=Quality Gate Blocked::Policy verdict is 'block'. Reason: ${{ steps.policy.outputs.reason }}"
          echo ""
          echo "Quality Score: ${{ steps.assessment.outputs.score }}"
          echo "Threshold: ${{ steps.gates.outputs.threshold }}"
          echo "Security Issues: ${{ steps.assessment.outputs.security-issues }}"
          echo ""
          echo "Please fix the issues and re-run the workflow."
          exit 1

      - name: Summary
        if: always()
        run: |
          echo "## Quality Gates Assessment" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Multi-Agent AI Output" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Agent | Output | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|-------|--------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| CI Agent | Trace ID | \`${{ steps.trace.outputs.trace_id }}\` |" >> $GITHUB_STEP_SUMMARY
          echo "| CI Agent | Quality Score | \`${{ steps.assessment.outputs.score }}/100\` |" >> $GITHUB_STEP_SUMMARY
          echo "| Security Agent | Security Issues | \`${{ steps.assessment.outputs.security-issues }}\` |" >> $GITHUB_STEP_SUMMARY
          echo "| Policy Agent | Gate Status | \`${{ steps.gates.outputs.status }}\` |" >> $GITHUB_STEP_SUMMARY
          echo "| Policy Agent | Verdict | \`${{ steps.policy.outputs.verdict }}\` |" >> $GITHUB_STEP_SUMMARY
          echo "| Policy Agent | Reason | \`${{ steps.policy.outputs.reason }}\` |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Score Breakdown" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Metric | Score | Weight |" >> $GITHUB_STEP_SUMMARY
          echo "|--------|-------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Pylint | \`${{ steps.assessment.outputs.pylint-score }}\` | 15% |" >> $GITHUB_STEP_SUMMARY
          echo "| Coverage | \`${{ steps.assessment.outputs.coverage }}%\` | 25% |" >> $GITHUB_STEP_SUMMARY
          echo "| Security | \`${{ steps.assessment.outputs.security-issues }} issues\` | 30% |" >> $GITHUB_STEP_SUMMARY
          echo "| TypeScript | \`${{ steps.assessment.outputs.ts-score }}\` | 10% |" >> $GITHUB_STEP_SUMMARY
          echo "| Intelligent Review | \`${{ steps.assessment.outputs.intelligent-score }}\` | 20% |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Threshold" >> $GITHUB_STEP_SUMMARY
          echo "- Branch: \`${GITHUB_HEAD_REF:-${GITHUB_REF#refs/heads/}}\`" >> $GITHUB_STEP_SUMMARY
          echo "- Required: \`${{ steps.gates.outputs.threshold }}/100\`" >> $GITHUB_STEP_SUMMARY
          echo "- Actual: \`${{ steps.assessment.outputs.score }}/100\`" >> $GITHUB_STEP_SUMMARY
